{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sequence Models and Long-Short Term Memory Networks\n",
    "===================================================\n",
    "\n",
    "At this point, we have seen various feed-forward networks. That is,\n",
    "there is no state maintained by the network at all. This might not be\n",
    "the behavior we want. Sequence models are central to NLP: they are\n",
    "models where there is some sort of dependence through time between your\n",
    "inputs. The classical example of a sequence model is the Hidden Markov\n",
    "Model for part-of-speech tagging. Another example is the conditional\n",
    "random field.\n",
    "\n",
    "A recurrent neural network is a network that maintains some kind of\n",
    "state. For example, its output could be used as part of the next input,\n",
    "so that information can propogate along as the network passes over the\n",
    "sequence. In the case of an LSTM, for each element in the sequence,\n",
    "there is a corresponding *hidden state* $h_t$, which in principle\n",
    "can contain information from arbitrary points earlier in the sequence.\n",
    "We can use the hidden state to predict words in a language model,\n",
    "part-of-speech tags, and a myriad of other things.\n",
    "\n",
    "\n",
    "LSTM's in Pytorch\n",
    "~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Before getting to the example, note a few things. Pytorch's LSTM expects\n",
    "all of its inputs to be 3D tensors. The semantics of the axes of these\n",
    "tensors is important. The first axis is the sequence itself, the second\n",
    "indexes instances in the mini-batch, and the third indexes elements of\n",
    "the input. We haven't discussed mini-batching, so lets just ignore that\n",
    "and assume we will always have just 1 dimension on the second axis. If\n",
    "we want to run the sequence model over the sentence \"The cow jumped\",\n",
    "our input should look like\n",
    "\n",
    "\\begin{align}\\begin{bmatrix}\n",
    "   \\overbrace{q_\\text{The}}^\\text{row vector} \\\\\n",
    "   q_\\text{cow} \\\\\n",
    "   q_\\text{jumped}\n",
    "   \\end{bmatrix}\\end{align}\n",
    "\n",
    "Except remember there is an additional 2nd dimension with size 1.\n",
    "\n",
    "In addition, you could go through the sequence one at a time, in which\n",
    "case the 1st axis will have size 1 also.\n",
    "\n",
    "Let's see a quick example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc1dc0b77f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "tensor([[[-0.5525,  0.6355, -0.3968]]])\n",
      "out\n",
      "tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward>), tensor([[[-1.0766,  0.0972, -0.5498]]], grad_fn=<StackBackward>))\n",
      "\n",
      "input\n",
      "tensor([[[-0.6571, -1.6428,  0.9803]]])\n",
      "out\n",
      "tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward>), tensor([[[-1.1552,  0.1214, -0.2974]]], grad_fn=<StackBackward>))\n",
      "\n",
      "input\n",
      "tensor([[[-0.0421, -0.8206,  0.3133]]])\n",
      "out\n",
      "tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward>), tensor([[[-1.0727,  0.1104, -0.2179]]], grad_fn=<StackBackward>))\n",
      "\n",
      "input\n",
      "tensor([[[-1.1352,  0.3773, -0.2824]]])\n",
      "out\n",
      "tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward>), tensor([[[-1.0530,  0.1836, -0.1731]]], grad_fn=<StackBackward>))\n",
      "\n",
      "input\n",
      "tensor([[[-2.5667, -1.4303,  0.5009]]])\n",
      "out\n",
      "tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward>), tensor([[[-1.1298,  0.4467,  0.0254]]], grad_fn=<StackBackward>))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    print(\"input\")\n",
    "    print(i.view(1, 1, -1))\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print(\"out\")\n",
    "    print(out)\n",
    "    print(\"hidden\")\n",
    "    print(hidden)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "tensor([[[-0.5525,  0.6355, -0.3968]],\n",
      "\n",
      "        [[-0.6571, -1.6428,  0.9803]],\n",
      "\n",
      "        [[-0.0421, -0.8206,  0.3133]],\n",
      "\n",
      "        [[-1.1352,  0.3773, -0.2824]],\n",
      "\n",
      "        [[-2.5667, -1.4303,  0.5009]]])\n",
      "hidden\n",
      "(tensor([[[-0.1473,  0.6272,  1.0935]]]), tensor([[[ 0.0939,  1.2381, -1.3459]]]))\n",
      "out\n",
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward>)\n",
      "hidden\n",
      "(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "print(\"inputs\")\n",
    "print(inputs)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "print(\"hidden\")\n",
    "print(hidden)\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(\"out\")\n",
    "print(out)\n",
    "print(\"hidden\")\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: An LSTM for Part-of-Speech Tagging\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "In this section, we will use an LSTM to get part of speech tags. We will\n",
    "not use Viterbi or Forward-Backward or anything like that, but as a\n",
    "(challenging) exercise to the reader, think about how Viterbi could be\n",
    "used after you have seen what is going on.\n",
    "\n",
    "The model is as follows: let our input sentence be\n",
    "$w_1, \\dots, w_M$, where $w_i \\in V$, our vocab. Also, let\n",
    "$T$ be our tag set, and $y_i$ the tag of word $w_i$.\n",
    "Denote our prediction of the tag of word $w_i$ by\n",
    "$\\hat{y}_i$.\n",
    "\n",
    "This is a structure prediction, model, where our output is a sequence\n",
    "$\\hat{y}_1, \\dots, \\hat{y}_M$, where $\\hat{y}_i \\in T$.\n",
    "\n",
    "To do the prediction, pass an LSTM over the sentence. Denote the hidden\n",
    "state at timestep $i$ as $h_i$. Also, assign each tag a\n",
    "unique index (like how we had word\\_to\\_ix in the word embeddings\n",
    "section). Then our prediction rule for $\\hat{y}_i$ is\n",
    "\n",
    "\\begin{align}\\hat{y}_i = \\text{argmax}_j \\  (\\log \\text{Softmax}(Ah_i + b))_j\\end{align}\n",
    "\n",
    "That is, take the log softmax of the affine map of the hidden state,\n",
    "and the predicted tag is the tag that has the maximum value in this\n",
    "vector. Note this implies immediately that the dimensionality of the\n",
    "target space of $A$ is $|T|$.\n",
    "\n",
    "\n",
    "Prepare data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1389, -1.2024, -0.9693],\n",
       "        [-1.1065, -1.2200, -0.9834],\n",
       "        [-1.1286, -1.2093, -0.9726],\n",
       "        [-1.1190, -1.1960, -0.9916],\n",
       "        [-1.0137, -1.2642, -1.0366]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "model(prepare_sequence(training_data[0][0], word_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "tensor([1, 2, 2, 2, 2])\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3852, -0.9624, -1.0003],\n",
      "        [-1.3570, -1.1749, -0.8354],\n",
      "        [-1.3794, -1.2678, -0.7618],\n",
      "        [-1.3699, -1.1893, -0.8177],\n",
      "        [-1.3667, -1.2508, -0.7792]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3119, -0.8830, -1.1484],\n",
      "        [-1.3291, -0.8888, -1.1266],\n",
      "        [-1.3248, -0.8542, -1.1760],\n",
      "        [-1.4569, -0.7795, -1.1764]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2082, -0.8134, -1.3551],\n",
      "        [-1.3897, -0.5448, -1.7668],\n",
      "        [-1.4812, -0.6465, -1.3912],\n",
      "        [-1.1817, -0.7930, -1.4239],\n",
      "        [-1.3026, -0.5666, -1.8280]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3622, -0.5466, -1.8019],\n",
      "        [-1.3389, -0.7804, -1.2742],\n",
      "        [-1.0988, -0.7921, -1.5424],\n",
      "        [-1.4604, -0.5128, -1.7775]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0154, -0.8470, -1.5653],\n",
      "        [-1.4203, -0.4096, -2.3596],\n",
      "        [-1.4357, -0.7716, -1.2047],\n",
      "        [-0.9130, -0.9150, -1.6186],\n",
      "        [-1.3874, -0.3916, -2.5995]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5827, -0.3571, -2.3552],\n",
      "        [-1.2900, -1.0746, -0.9589],\n",
      "        [-0.7839, -0.9441, -1.8687],\n",
      "        [-1.5276, -0.4001, -2.1831]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-0.7437, -1.0221, -1.8028],\n",
      "        [-1.5699, -0.3219, -2.7006],\n",
      "        [-1.2964, -1.4387, -0.7149],\n",
      "        [-0.5979, -1.1366, -2.0468],\n",
      "        [-1.6381, -0.2632, -3.2958]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9743, -0.2135, -2.9294],\n",
      "        [-1.2157, -1.5620, -0.7056],\n",
      "        [-0.4634, -1.2738, -2.3957],\n",
      "        [-1.7615, -0.2576, -2.8947]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-0.3879, -1.4889, -2.3447],\n",
      "        [-1.7511, -0.2539, -2.9822],\n",
      "        [-1.4280, -2.3117, -0.4138],\n",
      "        [-0.3252, -1.6415, -2.4776],\n",
      "        [-2.0261, -0.1666, -3.8348]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.5072, -0.1209, -3.4289],\n",
      "        [-1.3236, -2.1507, -0.4822],\n",
      "        [-0.2132, -1.9193, -3.0936],\n",
      "        [-2.2248, -0.1395, -3.8114]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-0.1605, -2.2273, -3.2067],\n",
      "        [-2.1140, -0.1703, -3.3300],\n",
      "        [-1.9873, -3.2213, -0.1948],\n",
      "        [-0.1218, -2.5794, -3.2480],\n",
      "        [-3.0292, -0.0618, -4.4596]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.1446, -0.0683, -3.7731],\n",
      "        [-1.7575, -2.9956, -0.2516],\n",
      "        [-0.0740, -2.9224, -4.0438],\n",
      "        [-2.9025, -0.0659, -4.7220]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-0.0620, -3.1173, -4.1474],\n",
      "        [-2.7235, -0.0864, -4.0691],\n",
      "        [-2.7044, -4.0729, -0.0877],\n",
      "        [-0.0355, -3.7586, -4.4611],\n",
      "        [-4.0496, -0.0245, -4.9882]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.7586, -0.0390, -4.2053],\n",
      "        [-2.6929, -4.2254, -0.0859],\n",
      "        [-0.0257, -3.9686, -5.0330],\n",
      "        [-3.6084, -0.0318, -5.4662]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-0.0241, -4.0647, -5.0146],\n",
      "        [-3.3980, -0.0419, -4.8761],\n",
      "        [-3.5024, -4.8594, -0.0386],\n",
      "        [-0.0129, -4.7363, -5.5154],\n",
      "        [-4.7850, -0.0125, -5.5107]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-4.2867, -0.0223, -4.7872],\n",
      "        [-3.7668, -5.4637, -0.0277],\n",
      "        [-0.0104, -4.8727, -5.9276],\n",
      "        [-4.2581, -0.0165, -6.1294]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0464e-02, -4.9288e+00, -5.7526e+00],\n",
      "        [-3.9939e+00, -2.2937e-02, -5.4612e+00],\n",
      "        [-4.3244e+00, -5.6285e+00, -1.6979e-02],\n",
      "        [-5.9321e-03, -5.5270e+00, -6.2469e+00],\n",
      "        [-5.3553e+00, -6.8100e-03, -6.1831e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-4.7360e+00, -1.3378e-02, -5.4002e+00],\n",
      "        [-4.6001e+00, -6.4025e+00, -1.1777e-02],\n",
      "        [-4.8879e-03, -5.6208e+00, -6.6813e+00],\n",
      "        [-4.8513e+00, -9.0280e-03, -6.7518e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.2811e-03, -5.6422e+00, -6.3642e+00],\n",
      "        [-4.5149e+00, -1.3717e-02, -5.9227e+00],\n",
      "        [-5.0099e+00, -6.2956e+00, -8.5521e-03],\n",
      "        [-3.2071e-03, -6.1784e+00, -6.7872e+00],\n",
      "        [-5.8110e+00, -3.9943e-03, -6.9158e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.1238e+00, -8.5852e-03, -5.9540e+00],\n",
      "        [-5.2160e+00, -7.1027e+00, -6.2714e-03],\n",
      "        [-2.6605e-03, -6.2299e+00, -7.2827e+00],\n",
      "        [-5.3828e+00, -5.2913e-03, -7.2898e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.0476e-03, -6.2124e+00, -6.8700e+00],\n",
      "        [-4.9711e+00, -8.7630e-03, -6.3262e+00],\n",
      "        [-5.5506e+00, -6.8527e+00, -4.9542e-03],\n",
      "        [-1.9440e-03, -6.7183e+00, -7.2176e+00],\n",
      "        [-6.1797e+00, -2.5653e-03, -7.6191e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.4627e+00, -5.8948e-03, -6.4160e+00],\n",
      "        [-5.6937e+00, -7.6513e+00, -3.8500e-03],\n",
      "        [-1.6236e-03, -6.7297e+00, -7.7578e+00],\n",
      "        [-5.8492e+00, -3.3271e-03, -7.7305e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9556e-03, -6.6683e+00, -7.2888e+00],\n",
      "        [-5.3658e+00, -5.9430e-03, -6.6834e+00],\n",
      "        [-5.9823e+00, -7.3205e+00, -3.1900e-03],\n",
      "        [-1.2854e-03, -7.1678e+00, -7.5740e+00],\n",
      "        [-6.4871e+00, -1.7918e-03, -8.2277e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.7590e+00, -4.2875e-03, -6.7908e+00],\n",
      "        [-6.0783e+00, -8.0959e+00, -2.6001e-03],\n",
      "        [-1.0829e-03, -7.1441e+00, -8.1359e+00],\n",
      "        [-6.2527e+00, -2.2340e-03, -8.0910e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3625e-03, -7.0370e+00, -7.6357e+00],\n",
      "        [-5.7030e+00, -4.2622e-03, -6.9940e+00],\n",
      "        [-6.3331e+00, -7.7167e+00, -2.2244e-03],\n",
      "        [-9.1058e-04, -7.5432e+00, -7.8738e+00],\n",
      "        [-6.7515e+00, -1.3333e-03, -8.7194e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.0170e+00, -3.2716e-03, -7.0950e+00],\n",
      "        [-6.3944e+00, -8.4623e+00, -1.8840e-03],\n",
      "        [-7.7504e-04, -7.4900e+00, -8.4399e+00],\n",
      "        [-6.5995e+00, -1.5891e-03, -8.3913e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0129e-03, -7.3384e+00, -7.9230e+00],\n",
      "        [-5.9890e+00, -3.2146e-03, -7.2597e+00],\n",
      "        [-6.6213e+00, -8.0538e+00, -1.6509e-03],\n",
      "        [-6.8260e-04, -7.8574e+00, -8.1272e+00],\n",
      "        [-6.9832e+00, -1.0391e-03, -9.1036e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.2403e+00, -2.5990e-03, -7.3443e+00],\n",
      "        [-6.6565e+00, -8.7667e+00, -1.4425e-03],\n",
      "        [-5.8705e-04, -7.7795e+00, -8.6870e+00],\n",
      "        [-6.8966e+00, -1.1879e-03, -8.6451e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9290e-04, -7.5868e+00, -8.1613e+00],\n",
      "        [-6.2307e+00, -2.5327e-03, -7.4848e+00],\n",
      "        [-6.8598e+00, -8.3412e+00, -1.2884e-03],\n",
      "        [-5.3582e-04, -8.1207e+00, -8.3415e+00],\n",
      "        [-7.1874e+00, -8.3912e-04, -9.4005e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.4328e+00, -2.1361e-03, -7.5505e+00],\n",
      "        [-6.8751e+00, -9.0204e+00, -1.1547e-03],\n",
      "        [-4.6612e-04, -8.0221e+00, -8.8896e+00],\n",
      "        [-7.1508e+00, -9.2642e-04, -8.8616e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.4722e-04, -7.7926e+00, -8.3594e+00],\n",
      "        [-6.4348e+00, -2.0713e-03, -7.6748e+00],\n",
      "        [-7.0579e+00, -8.5864e+00, -1.0478e-03],\n",
      "        [-4.3728e-04, -8.3417e+00, -8.5227e+00],\n",
      "        [-7.3672e+00, -6.9749e-04, -9.6306e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.5983e+00, -1.8071e-03, -7.7225e+00],\n",
      "        [-7.0579e+00, -9.2324e+00, -9.5882e-04],\n",
      "        [-3.8438e-04, -8.2254e+00, -9.0568e+00],\n",
      "        [-7.3683e+00, -7.4895e-04, -9.0470e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.4654e-04, -7.9638e+00, -8.5244e+00],\n",
      "        [-6.6073e+00, -1.7476e-03, -7.8348e+00],\n",
      "        [-7.2229e+00, -8.7954e+00, -8.8152e-04],\n",
      "        [-3.6877e-04, -8.5273e+00, -8.6758e+00],\n",
      "        [-7.5250e+00, -5.9456e-04, -9.8102e+00]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.7404e+00, -1.5667e-03, -7.8667e+00],\n",
      "        [-7.2110e+00, -9.4097e+00, -8.2066e-04],\n",
      "        [-3.2741e-04, -8.3957e+00, -9.1957e+00],\n",
      "        [-7.5544e+00, -6.2446e-04, -9.2060e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-4.7470e-04, -8.1065e+00, -8.6621e+00],\n",
      "        [-6.7534e+00, -1.5138e-03, -7.9696e+00],\n",
      "        [-7.3606e+00, -8.9736e+00, -7.6289e-04],\n",
      "        [-3.1931e-04, -8.6832e+00, -8.8052e+00],\n",
      "        [-7.6632e+00, -5.1759e-04, -9.9520e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.8623e+00, -1.3870e-03, -7.9881e+00],\n",
      "        [-7.3393e+00, -9.5580e+00, -7.2036e-04],\n",
      "        [-2.8618e-04, -8.5383e+00, -9.3116e+00],\n",
      "        [-7.7139e+00, -5.3427e-04, -9.3425e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-4.2191e-04, -8.2258e+00, -8.7773e+00],\n",
      "        [-6.8774e+00, -1.3403e-03, -8.0835e+00],\n",
      "        [-7.4756e+00, -9.1255e+00, -6.7581e-04],\n",
      "        [-2.8308e-04, -8.8144e+00, -8.9144e+00],\n",
      "        [-7.7837e+00, -4.5909e-04, -1.0065e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.9670e+00, -1.2496e-03, -8.0908e+00],\n",
      "        [-7.4470e+00, -9.6823e+00, -6.4579e-04],\n",
      "        [-2.5579e-04, -8.6577e+00, -9.4087e+00],\n",
      "        [-7.8507e+00, -4.6755e-04, -9.4598e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.8235e-04, -8.3255e+00, -8.8739e+00],\n",
      "        [-6.9829e+00, -1.2086e-03, -8.1797e+00],\n",
      "        [-7.5719e+00, -9.2549e+00, -6.1052e-04],\n",
      "        [-2.5567e-04, -8.9248e+00, -9.0067e+00],\n",
      "        [-7.8888e+00, -4.1381e-04, -1.0157e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.0570e+00, -1.1428e-03, -8.1778e+00],\n",
      "        [-7.5376e+00, -9.7865e+00, -5.8908e-04],\n",
      "        [-2.3291e-04, -8.7576e+00, -9.4904e+00],\n",
      "        [-7.9683e+00, -4.1679e-04, -9.5607e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.5196e-04, -8.4090e+00, -8.9551e+00],\n",
      "        [-7.0729e+00, -1.1068e-03, -8.2612e+00],\n",
      "        [-7.6525e+00, -9.3652e+00, -5.6060e-04],\n",
      "        [-2.3458e-04, -9.0178e+00, -9.0848e+00],\n",
      "        [-7.9803e+00, -3.7818e-04, -1.0231e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.1345e+00, -1.0585e-03, -8.2518e+00],\n",
      "        [-7.6138e+00, -9.8740e+00, -5.4523e-04],\n",
      "        [-2.1527e-04, -8.8413e+00, -9.5593e+00],\n",
      "        [-8.0697e+00, -3.7758e-04, -9.6476e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.2837e-04, -8.4791e+00, -9.0234e+00],\n",
      "        [-7.1499e+00, -1.0265e-03, -8.3305e+00],\n",
      "        [-7.7203e+00, -9.4593e+00, -5.2188e-04],\n",
      "        [-2.1813e-04, -9.0962e+00, -9.1509e+00],\n",
      "        [-8.0601e+00, -3.4982e-04, -1.0293e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2015e+00, -9.9085e-04, -8.3150e+00],\n",
      "        [-7.6780e+00, -9.9475e+00, -5.1092e-04],\n",
      "        [-2.0132e-04, -8.9113e+00, -9.6177e+00],\n",
      "        [-8.1574e+00, -3.4660e-04, -9.7228e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-3.0978e-04, -8.5380e+00, -9.0811e+00],\n",
      "        [-7.2161e+00, -9.6239e-04, -8.3895e+00],\n",
      "        [-7.7772e+00, -9.5397e+00, -4.9126e-04],\n",
      "        [-2.0526e-04, -9.1624e+00, -9.2070e+00],\n",
      "        [-8.1298e+00, -3.2682e-04, -1.0344e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2595e+00, -9.3571e-04, -8.3691e+00],\n",
      "        [-7.7323e+00, -1.0009e+01, -4.8352e-04],\n",
      "        [-1.9048e-04, -8.9701e+00, -9.6674e+00],\n",
      "        [-8.2335e+00, -3.2181e-04, -9.7879e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.9476e-04, -8.5876e+00, -9.1300e+00],\n",
      "        [-7.2733e+00, -9.1034e-04, -8.4400e+00],\n",
      "        [-7.8253e+00, -9.6085e+00, -4.6683e-04],\n",
      "        [-1.9489e-04, -9.2185e+00, -9.2548e+00],\n",
      "        [-8.1908e+00, -3.0811e-04, -1.0387e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3101e+00, -8.9057e-04, -8.4156e+00],\n",
      "        [-7.7782e+00, -1.0062e+01, -4.6159e-04],\n",
      "        [-1.8178e-04, -9.0194e+00, -9.7099e+00],\n",
      "        [-8.2998e+00, -3.0167e-04, -9.8445e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.8272e-04, -8.6294e+00, -9.1715e+00],\n",
      "        [-7.3228e+00, -8.6759e-04, -8.4834e+00],\n",
      "        [-7.8659e+00, -9.6675e+00, -4.4705e-04],\n",
      "        [-1.8643e-04, -9.2661e+00, -9.2956e+00],\n",
      "        [-8.2445e+00, -2.9238e-04, -1.0423e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3543e+00, -8.5294e-04, -8.4557e+00],\n",
      "        [-7.8173e+00, -1.0106e+01, -4.4360e-04],\n",
      "        [-1.7463e-04, -9.0608e+00, -9.7463e+00],\n",
      "        [-8.3580e+00, -2.8511e-04, -9.8940e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.7295e-04, -8.6649e+00, -9.2069e+00],\n",
      "        [-7.3660e+00, -8.3197e-04, -8.5208e+00],\n",
      "        [-7.9004e+00, -9.7182e+00, -4.3085e-04],\n",
      "        [-1.7951e-04, -9.3065e+00, -9.3305e+00],\n",
      "        [-8.2919e+00, -2.7939e-04, -1.0455e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3931e+00, -8.2113e-04, -8.4906e+00],\n",
      "        [-7.8506e+00, -1.0143e+01, -4.2894e-04],\n",
      "        [-1.6891e-04, -9.0957e+00, -9.7778e+00],\n",
      "        [-8.4092e+00, -2.7128e-04, -9.9375e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.6485e-04, -8.6950e+00, -9.2372e+00],\n",
      "        [-7.4039e+00, -8.0220e-04, -8.5533e+00],\n",
      "        [-7.9298e+00, -9.7620e+00, -4.1750e-04],\n",
      "        [-1.7379e-04, -9.3411e+00, -9.3606e+00],\n",
      "        [-8.3339e+00, -2.6830e-04, -1.0482e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4275e+00, -7.9421e-04, -8.5210e+00],\n",
      "        [-7.8792e+00, -1.0175e+01, -4.1667e-04],\n",
      "        [-1.6414e-04, -9.1251e+00, -9.8051e+00],\n",
      "        [-8.4546e+00, -2.5948e-04, -9.9760e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.5805e-04, -8.7207e+00, -9.2634e+00],\n",
      "        [-7.4373e+00, -7.7670e-04, -8.5816e+00],\n",
      "        [-7.9550e+00, -9.8000e+00, -4.0642e-04],\n",
      "        [-1.6902e-04, -9.3708e+00, -9.3866e+00],\n",
      "        [-8.3715e+00, -2.5877e-04, -1.0505e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4581e+00, -7.7099e-04, -8.5478e+00],\n",
      "        [-7.9039e+00, -1.0202e+01, -4.0642e-04],\n",
      "        [-1.6009e-04, -9.1501e+00, -9.8289e+00],\n",
      "        [-8.4951e+00, -2.4947e-04, -1.0010e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.5233e-04, -8.7427e+00, -9.2861e+00],\n",
      "        [-7.4670e+00, -7.5491e-04, -8.6065e+00],\n",
      "        [-7.9767e+00, -9.8330e+00, -3.9713e-04],\n",
      "        [-1.6509e-04, -9.3963e+00, -9.4092e+00],\n",
      "        [-8.4053e+00, -2.5055e-04, -1.0526e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4856e+00, -7.5086e-04, -8.5715e+00],\n",
      "        [-7.9252e+00, -1.0226e+01, -3.9784e-04],\n",
      "        [-1.5675e-04, -9.1713e+00, -9.8499e+00],\n",
      "        [-8.5315e+00, -2.4077e-04, -1.0041e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.4757e-04, -8.7617e+00, -9.3059e+00],\n",
      "        [-7.4936e+00, -7.3585e-04, -8.6286e+00],\n",
      "        [-7.9956e+00, -9.8619e+00, -3.8914e-04],\n",
      "        [-1.6152e-04, -9.4185e+00, -9.4291e+00],\n",
      "        [-8.4359e+00, -2.4328e-04, -1.0544e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5104e+00, -7.3311e-04, -8.5927e+00],\n",
      "        [-7.9439e+00, -1.0246e+01, -3.9033e-04],\n",
      "        [-1.5389e-04, -9.1895e+00, -9.8685e+00],\n",
      "        [-8.5645e+00, -2.3327e-04, -1.0068e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.4340e-04, -8.7782e+00, -9.3233e+00],\n",
      "        [-7.5176e+00, -7.1917e-04, -8.6483e+00],\n",
      "        [-8.0121e+00, -9.8874e+00, -3.8235e-04],\n",
      "        [-1.5854e-04, -9.4378e+00, -9.4466e+00],\n",
      "        [-8.4639e+00, -2.3684e-04, -1.0561e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5330e+00, -7.1738e-04, -8.6117e+00],\n",
      "        [-7.9604e+00, -1.0264e+01, -3.8402e-04],\n",
      "        [-1.5138e-04, -9.2051e+00, -9.8851e+00],\n",
      "        [-8.5945e+00, -2.2647e-04, -1.0094e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.3982e-04, -8.7927e+00, -9.3387e+00],\n",
      "        [-7.5395e+00, -7.0428e-04, -8.6660e+00],\n",
      "        [-8.0266e+00, -9.9100e+00, -3.7639e-04],\n",
      "        [-1.5603e-04, -9.4548e+00, -9.4623e+00],\n",
      "        [-8.4896e+00, -2.3112e-04, -1.0576e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5537e+00, -7.0321e-04, -8.6290e+00],\n",
      "        [-7.9750e+00, -1.0279e+01, -3.7842e-04],\n",
      "        [-1.4936e-04, -9.2186e+00, -9.9001e+00],\n",
      "        [-8.6222e+00, -2.2051e-04, -1.0117e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.3672e-04, -8.8054e+00, -9.3525e+00],\n",
      "        [-7.5596e+00, -6.9094e-04, -8.6820e+00],\n",
      "        [-8.0396e+00, -9.9301e+00, -3.7115e-04],\n",
      "        [-1.5377e-04, -9.4699e+00, -9.4763e+00],\n",
      "        [-8.5135e+00, -2.2588e-04, -1.0590e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5729e+00, -6.9046e-04, -8.6448e+00],\n",
      "        [-7.9881e+00, -1.0293e+01, -3.7341e-04],\n",
      "        [-1.4745e-04, -9.2304e+00, -9.9138e+00],\n",
      "        [-8.6478e+00, -2.1515e-04, -1.0138e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.3398e-04, -8.8167e+00, -9.3650e+00],\n",
      "        [-7.5781e+00, -6.7890e-04, -8.6967e+00],\n",
      "        [-8.0512e+00, -9.9482e+00, -3.6662e-04],\n",
      "        [-1.5186e-04, -9.4833e+00, -9.4890e+00],\n",
      "        [-8.5358e+00, -2.2123e-04, -1.0603e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5908e+00, -6.7879e-04, -8.6593e+00],\n",
      "        [-8.0000e+00, -1.0305e+01, -3.6900e-04],\n",
      "        [-1.4590e-04, -9.2408e+00, -9.9263e+00],\n",
      "        [-8.6717e+00, -2.1014e-04, -1.0158e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.3148e-04, -8.8269e+00, -9.3763e+00],\n",
      "        [-7.5954e+00, -6.6783e-04, -8.7103e+00],\n",
      "        [-8.0618e+00, -9.9647e+00, -3.6245e-04],\n",
      "        [-1.5007e-04, -9.4955e+00, -9.5007e+00],\n",
      "        [-8.5567e+00, -2.1682e-04, -1.0615e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6076e+00, -6.6806e-04, -8.6729e+00],\n",
      "        [-8.0108e+00, -1.0316e+01, -3.6495e-04],\n",
      "        [-1.4435e-04, -9.2500e+00, -9.9379e+00],\n",
      "        [-8.6942e+00, -2.0561e-04, -1.0177e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2921e-04, -8.8361e+00, -9.3868e+00],\n",
      "        [-7.6116e+00, -6.5770e-04, -8.7230e+00],\n",
      "        [-8.0716e+00, -9.9797e+00, -3.5864e-04],\n",
      "        [-1.4840e-04, -9.5065e+00, -9.5115e+00],\n",
      "        [-8.5766e+00, -2.1277e-04, -1.0626e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6235e+00, -6.5806e-04, -8.6856e+00],\n",
      "        [-8.0208e+00, -1.0326e+01, -3.6138e-04],\n",
      "        [-1.4316e-04, -9.2582e+00, -9.9487e+00],\n",
      "        [-8.7155e+00, -2.0144e-04, -1.0194e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2731e-04, -8.8445e+00, -9.3965e+00],\n",
      "        [-7.6270e+00, -6.4817e-04, -8.7348e+00],\n",
      "        [-8.0806e+00, -9.9935e+00, -3.5530e-04],\n",
      "        [-1.4697e-04, -9.5166e+00, -9.5215e+00],\n",
      "        [-8.5956e+00, -2.0895e-04, -1.0637e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6387e+00, -6.4865e-04, -8.6976e+00],\n",
      "        [-8.0302e+00, -1.0335e+01, -3.5804e-04],\n",
      "        [-1.4197e-04, -9.2657e+00, -9.9589e+00],\n",
      "        [-8.7358e+00, -1.9751e-04, -1.0211e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2528e-04, -8.8523e+00, -9.4056e+00],\n",
      "        [-7.6417e+00, -6.3923e-04, -8.7461e+00],\n",
      "        [-8.0890e+00, -1.0006e+01, -3.5208e-04],\n",
      "        [-1.4554e-04, -9.5260e+00, -9.5309e+00],\n",
      "        [-8.6138e+00, -2.0538e-04, -1.0647e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6532e+00, -6.3983e-04, -8.7091e+00],\n",
      "        [-8.0390e+00, -1.0344e+01, -3.5482e-04],\n",
      "        [-1.4078e-04, -9.2726e+00, -9.9686e+00],\n",
      "        [-8.7552e+00, -1.9393e-04, -1.0227e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2361e-04, -8.8596e+00, -9.4141e+00],\n",
      "        [-7.6557e+00, -6.3089e-04, -8.7568e+00],\n",
      "        [-8.0970e+00, -1.0018e+01, -3.4910e-04],\n",
      "        [-1.4423e-04, -9.5347e+00, -9.5399e+00],\n",
      "        [-8.6313e+00, -2.0192e-04, -1.0657e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6672e+00, -6.3149e-04, -8.7201e+00],\n",
      "        [-8.0474e+00, -1.0352e+01, -3.5196e-04],\n",
      "        [-1.3970e-04, -9.2790e+00, -9.9778e+00],\n",
      "        [-8.7739e+00, -1.9036e-04, -1.0242e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2194e-04, -8.8664e+00, -9.4223e+00],\n",
      "        [-7.6692e+00, -6.2303e-04, -8.7671e+00],\n",
      "        [-8.1047e+00, -1.0030e+01, -3.4624e-04],\n",
      "        [-1.4304e-04, -9.5430e+00, -9.5485e+00],\n",
      "        [-8.6483e+00, -1.9870e-04, -1.0667e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6807e+00, -6.2339e-04, -8.7306e+00],\n",
      "        [-8.0554e+00, -1.0359e+01, -3.4910e-04],\n",
      "        [-1.3887e-04, -9.2850e+00, -9.9867e+00],\n",
      "        [-8.7920e+00, -1.8702e-04, -1.0257e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.2039e-04, -8.8729e+00, -9.4302e+00],\n",
      "        [-7.6823e+00, -6.1541e-04, -8.7770e+00],\n",
      "        [-8.1120e+00, -1.0040e+01, -3.4362e-04],\n",
      "        [-1.4185e-04, -9.5508e+00, -9.5567e+00],\n",
      "        [-8.6649e+00, -1.9572e-04, -1.0677e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6939e+00, -6.1565e-04, -8.7409e+00],\n",
      "        [-8.0631e+00, -1.0366e+01, -3.4648e-04],\n",
      "        [-1.3792e-04, -9.2906e+00, -9.9952e+00],\n",
      "        [-8.8095e+00, -1.8392e-04, -1.0272e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1884e-04, -8.8791e+00, -9.4378e+00],\n",
      "        [-7.6951e+00, -6.0802e-04, -8.7867e+00],\n",
      "        [-8.1191e+00, -1.0050e+01, -3.4100e-04],\n",
      "        [-1.4078e-04, -9.5583e+00, -9.5647e+00],\n",
      "        [-8.6810e+00, -1.9262e-04, -1.0686e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7067e+00, -6.0838e-04, -8.7508e+00],\n",
      "        [-8.0706e+00, -1.0373e+01, -3.4386e-04],\n",
      "        [-1.3708e-04, -9.2960e+00, -1.0004e+01],\n",
      "        [-8.8267e+00, -1.8082e-04, -1.0286e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1741e-04, -8.8852e+00, -9.4451e+00],\n",
      "        [-7.7075e+00, -6.0087e-04, -8.7960e+00],\n",
      "        [-8.1261e+00, -1.0060e+01, -3.3850e-04],\n",
      "        [-1.3970e-04, -9.5656e+00, -9.5724e+00],\n",
      "        [-8.6969e+00, -1.8976e-04, -1.0696e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7193e+00, -6.0111e-04, -8.7606e+00],\n",
      "        [-8.0780e+00, -1.0380e+01, -3.4148e-04],\n",
      "        [-1.3613e-04, -9.3012e+00, -1.0012e+01],\n",
      "        [-8.8434e+00, -1.7796e-04, -1.0300e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1622e-04, -8.8910e+00, -9.4524e+00],\n",
      "        [-7.7197e+00, -5.9420e-04, -8.8052e+00],\n",
      "        [-8.1329e+00, -1.0070e+01, -3.3611e-04],\n",
      "        [-1.3875e-04, -9.5726e+00, -9.5800e+00],\n",
      "        [-8.7125e+00, -1.8690e-04, -1.0705e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7316e+00, -5.9432e-04, -8.7702e+00],\n",
      "        [-8.0852e+00, -1.0386e+01, -3.3897e-04],\n",
      "        [-1.3529e-04, -9.3062e+00, -1.0020e+01],\n",
      "        [-8.8599e+00, -1.7510e-04, -1.0313e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1479e-04, -8.8967e+00, -9.4594e+00],\n",
      "        [-7.7317e+00, -5.8741e-04, -8.8143e+00],\n",
      "        [-8.1396e+00, -1.0079e+01, -3.3373e-04],\n",
      "        [-1.3768e-04, -9.5794e+00, -9.5875e+00],\n",
      "        [-8.7279e+00, -1.8428e-04, -1.0714e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7438e+00, -5.8741e-04, -8.7796e+00],\n",
      "        [-8.0923e+00, -1.0392e+01, -3.3659e-04],\n",
      "        [-1.3470e-04, -9.3111e+00, -1.0027e+01],\n",
      "        [-8.8760e+00, -1.7248e-04, -1.0327e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1360e-04, -8.9023e+00, -9.4664e+00],\n",
      "        [-7.7435e+00, -5.8098e-04, -8.8231e+00],\n",
      "        [-8.1462e+00, -1.0088e+01, -3.3147e-04],\n",
      "        [-1.3672e-04, -9.5861e+00, -9.5948e+00],\n",
      "        [-8.7430e+00, -1.8166e-04, -1.0723e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7558e+00, -5.8086e-04, -8.7888e+00],\n",
      "        [-8.0993e+00, -1.0398e+01, -3.3433e-04],\n",
      "        [-1.3386e-04, -9.3159e+00, -1.0035e+01],\n",
      "        [-8.8919e+00, -1.6986e-04, -1.0340e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1229e-04, -8.9078e+00, -9.4732e+00],\n",
      "        [-7.7551e+00, -5.7466e-04, -8.8319e+00],\n",
      "        [-8.1528e+00, -1.0096e+01, -3.2920e-04],\n",
      "        [-1.3577e-04, -9.5926e+00, -9.6021e+00],\n",
      "        [-8.7580e+00, -1.7904e-04, -1.0732e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7676e+00, -5.7442e-04, -8.7980e+00],\n",
      "        [-8.1063e+00, -1.0404e+01, -3.3206e-04],\n",
      "        [-1.3303e-04, -9.3207e+00, -1.0043e+01],\n",
      "        [-8.9076e+00, -1.6736e-04, -1.0353e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.1098e-04, -8.9132e+00, -9.4800e+00],\n",
      "        [-7.7666e+00, -5.6859e-04, -8.8406e+00],\n",
      "        [-8.1594e+00, -1.0105e+01, -3.2694e-04],\n",
      "        [-1.3494e-04, -9.5991e+00, -9.6093e+00],\n",
      "        [-8.7729e+00, -1.7653e-04, -1.0741e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7793e+00, -5.6811e-04, -8.8071e+00],\n",
      "        [-8.1132e+00, -1.0410e+01, -3.2980e-04],\n",
      "        [-1.3231e-04, -9.3254e+00, -1.0050e+01],\n",
      "        [-8.9231e+00, -1.6473e-04, -1.0366e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0967e-04, -8.9186e+00, -9.4868e+00],\n",
      "        [-7.7780e+00, -5.6251e-04, -8.8492e+00],\n",
      "        [-8.1659e+00, -1.0113e+01, -3.2479e-04],\n",
      "        [-1.3398e-04, -9.6055e+00, -9.6164e+00],\n",
      "        [-8.7876e+00, -1.7403e-04, -1.0750e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7909e+00, -5.6191e-04, -8.8161e+00],\n",
      "        [-8.1201e+00, -1.0416e+01, -3.2753e-04],\n",
      "        [-1.3160e-04, -9.3301e+00, -1.0058e+01],\n",
      "        [-8.9384e+00, -1.6235e-04, -1.0378e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0848e-04, -8.9239e+00, -9.4935e+00],\n",
      "        [-7.7892e+00, -5.5655e-04, -8.8578e+00],\n",
      "        [-8.1724e+00, -1.0121e+01, -3.2265e-04],\n",
      "        [-1.3315e-04, -9.6118e+00, -9.6236e+00],\n",
      "        [-8.8023e+00, -1.7165e-04, -1.0759e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8024e+00, -5.5596e-04, -8.8250e+00],\n",
      "        [-8.1270e+00, -1.0421e+01, -3.2527e-04],\n",
      "        [-1.3088e-04, -9.3348e+00, -1.0065e+01],\n",
      "        [-8.9536e+00, -1.6009e-04, -1.0391e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0728e-04, -8.9292e+00, -9.5002e+00],\n",
      "        [-7.8004e+00, -5.5071e-04, -8.8663e+00],\n",
      "        [-8.1790e+00, -1.0129e+01, -3.2038e-04],\n",
      "        [-1.3219e-04, -9.6181e+00, -9.6306e+00],\n",
      "        [-8.8168e+00, -1.6938e-04, -1.0769e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8139e+00, -5.5000e-04, -8.8339e+00],\n",
      "        [-8.1339e+00, -1.0427e+01, -3.2312e-04],\n",
      "        [-1.3005e-04, -9.3395e+00, -1.0072e+01],\n",
      "        [-8.9687e+00, -1.5758e-04, -1.0404e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0609e-04, -8.9346e+00, -9.5069e+00],\n",
      "        [-7.8115e+00, -5.4500e-04, -8.8747e+00],\n",
      "        [-8.1855e+00, -1.0137e+01, -3.1824e-04],\n",
      "        [-1.3136e-04, -9.6244e+00, -9.6377e+00],\n",
      "        [-8.8313e+00, -1.6700e-04, -1.0778e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8252e+00, -5.4404e-04, -8.8427e+00],\n",
      "        [-8.1408e+00, -1.0433e+01, -3.2086e-04],\n",
      "        [-1.2945e-04, -9.3443e+00, -1.0080e+01],\n",
      "        [-8.9836e+00, -1.5544e-04, -1.0416e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0502e-04, -8.9399e+00, -9.5136e+00],\n",
      "        [-7.8226e+00, -5.3940e-04, -8.8831e+00],\n",
      "        [-8.1921e+00, -1.0145e+01, -3.1609e-04],\n",
      "        [-1.3041e-04, -9.6306e+00, -9.6448e+00],\n",
      "        [-8.8456e+00, -1.6461e-04, -1.0787e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8365e+00, -5.3844e-04, -8.8515e+00],\n",
      "        [-8.1477e+00, -1.0438e+01, -3.1871e-04],\n",
      "        [-1.2862e-04, -9.3490e+00, -1.0087e+01],\n",
      "        [-8.9984e+00, -1.5317e-04, -1.0428e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0371e-04, -8.9452e+00, -9.5202e+00],\n",
      "        [-7.8336e+00, -5.3380e-04, -8.8915e+00],\n",
      "        [-8.1986e+00, -1.0153e+01, -3.1407e-04],\n",
      "        [-1.2969e-04, -9.6368e+00, -9.6518e+00],\n",
      "        [-8.8599e+00, -1.6247e-04, -1.0796e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8477e+00, -5.3272e-04, -8.8602e+00],\n",
      "        [-8.1547e+00, -1.0444e+01, -3.1657e-04],\n",
      "        [-1.2802e-04, -9.3537e+00, -1.0094e+01],\n",
      "        [-9.0131e+00, -1.5103e-04, -1.0441e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0252e-04, -8.9505e+00, -9.5269e+00],\n",
      "        [-7.8445e+00, -5.2843e-04, -8.8999e+00],\n",
      "        [-8.2053e+00, -1.0161e+01, -3.1192e-04],\n",
      "        [-1.2874e-04, -9.6430e+00, -9.6589e+00],\n",
      "        [-8.8742e+00, -1.6020e-04, -1.0805e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8588e+00, -5.2712e-04, -8.8689e+00],\n",
      "        [-8.1616e+00, -1.0449e+01, -3.1442e-04],\n",
      "        [-1.2719e-04, -9.3585e+00, -1.0101e+01],\n",
      "        [-9.0276e+00, -1.4888e-04, -1.0453e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0132e-04, -8.9558e+00, -9.5335e+00],\n",
      "        [-7.8553e+00, -5.2307e-04, -8.9082e+00],\n",
      "        [-8.2119e+00, -1.0169e+01, -3.0978e-04],\n",
      "        [-1.2790e-04, -9.6492e+00, -9.6659e+00],\n",
      "        [-8.8883e+00, -1.5818e-04, -1.0814e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8699e+00, -5.2176e-04, -8.8776e+00],\n",
      "        [-8.1686e+00, -1.0455e+01, -3.1228e-04],\n",
      "        [-1.2659e-04, -9.3633e+00, -1.0109e+01],\n",
      "        [-9.0421e+00, -1.4686e-04, -1.0465e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-2.0025e-04, -8.9611e+00, -9.5402e+00],\n",
      "        [-7.8661e+00, -5.1783e-04, -8.9165e+00],\n",
      "        [-8.2185e+00, -1.0176e+01, -3.0775e-04],\n",
      "        [-1.2707e-04, -9.6554e+00, -9.6730e+00],\n",
      "        [-8.9025e+00, -1.5591e-04, -1.0824e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8809e+00, -5.1640e-04, -8.8863e+00],\n",
      "        [-8.1756e+00, -1.0460e+01, -3.1013e-04],\n",
      "        [-1.2576e-04, -9.3682e+00, -1.0116e+01],\n",
      "        [-9.0565e+00, -1.4483e-04, -1.0477e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9906e-04, -8.9664e+00, -9.5469e+00],\n",
      "        [-7.8769e+00, -5.1259e-04, -8.9248e+00],\n",
      "        [-8.2252e+00, -1.0184e+01, -3.0561e-04],\n",
      "        [-1.2612e-04, -9.6616e+00, -9.6801e+00],\n",
      "        [-8.9165e+00, -1.5401e-04, -1.0833e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8919e+00, -5.1104e-04, -8.8949e+00],\n",
      "        [-8.1826e+00, -1.0466e+01, -3.0799e-04],\n",
      "        [-1.2516e-04, -9.3731e+00, -1.0123e+01],\n",
      "        [-9.0708e+00, -1.4292e-04, -1.0489e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9787e-04, -8.9717e+00, -9.5535e+00],\n",
      "        [-7.8876e+00, -5.0746e-04, -8.9330e+00],\n",
      "        [-8.2320e+00, -1.0192e+01, -3.0358e-04],\n",
      "        [-1.2540e-04, -9.6677e+00, -9.6871e+00],\n",
      "        [-8.9305e+00, -1.5186e-04, -1.0842e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9028e+00, -5.0580e-04, -8.9035e+00],\n",
      "        [-8.1897e+00, -1.0472e+01, -3.0584e-04],\n",
      "        [-1.2433e-04, -9.3780e+00, -1.0130e+01],\n",
      "        [-9.0850e+00, -1.4090e-04, -1.0501e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9668e-04, -8.9771e+00, -9.5602e+00],\n",
      "        [-7.8982e+00, -5.0234e-04, -8.9413e+00],\n",
      "        [-8.2387e+00, -1.0199e+01, -3.0143e-04],\n",
      "        [-1.2457e-04, -9.6739e+00, -9.6942e+00],\n",
      "        [-8.9445e+00, -1.4983e-04, -1.0851e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9137e+00, -5.0055e-04, -8.9121e+00],\n",
      "        [-8.1967e+00, -1.0477e+01, -3.0382e-04],\n",
      "        [-1.2373e-04, -9.3830e+00, -1.0137e+01],\n",
      "        [-9.0991e+00, -1.3899e-04, -1.0513e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9560e-04, -8.9824e+00, -9.5669e+00],\n",
      "        [-7.9088e+00, -4.9734e-04, -8.9495e+00],\n",
      "        [-8.2455e+00, -1.0207e+01, -2.9941e-04],\n",
      "        [-1.2361e-04, -9.6801e+00, -9.7013e+00],\n",
      "        [-8.9584e+00, -1.4781e-04, -1.0861e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9245e+00, -4.9543e-04, -8.9207e+00],\n",
      "        [-8.2038e+00, -1.0483e+01, -3.0167e-04],\n",
      "        [-1.2302e-04, -9.3880e+00, -1.0144e+01],\n",
      "        [-9.1132e+00, -1.3708e-04, -1.0525e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9441e-04, -8.9878e+00, -9.5736e+00],\n",
      "        [-7.9194e+00, -4.9245e-04, -8.9578e+00],\n",
      "        [-8.2523e+00, -1.0214e+01, -2.9738e-04],\n",
      "        [-1.2290e-04, -9.6863e+00, -9.7084e+00],\n",
      "        [-8.9722e+00, -1.4602e-04, -1.0870e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9353e+00, -4.9055e-04, -8.9292e+00],\n",
      "        [-8.2110e+00, -1.0488e+01, -2.9953e-04],\n",
      "        [-1.2230e-04, -9.3930e+00, -1.0151e+01],\n",
      "        [-9.1271e+00, -1.3529e-04, -1.0537e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9334e-04, -8.9932e+00, -9.5803e+00],\n",
      "        [-7.9299e+00, -4.8769e-04, -8.9660e+00],\n",
      "        [-8.2591e+00, -1.0222e+01, -2.9536e-04],\n",
      "        [-1.2206e-04, -9.6925e+00, -9.7155e+00],\n",
      "        [-8.9861e+00, -1.4399e-04, -1.0880e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9460e+00, -4.8554e-04, -8.9377e+00],\n",
      "        [-8.2181e+00, -1.0494e+01, -2.9750e-04],\n",
      "        [-1.2159e-04, -9.3981e+00, -1.0158e+01],\n",
      "        [-9.1410e+00, -1.3339e-04, -1.0548e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9227e-04, -8.9986e+00, -9.5870e+00],\n",
      "        [-7.9403e+00, -4.8280e-04, -8.9741e+00],\n",
      "        [-8.2660e+00, -1.0229e+01, -2.9321e-04],\n",
      "        [-1.2135e-04, -9.6987e+00, -9.7226e+00],\n",
      "        [-8.9998e+00, -1.4221e-04, -1.0889e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9567e+00, -4.8066e-04, -8.9462e+00],\n",
      "        [-8.2253e+00, -1.0499e+01, -2.9536e-04],\n",
      "        [-1.2099e-04, -9.4033e+00, -1.0165e+01],\n",
      "        [-9.1548e+00, -1.3172e-04, -1.0560e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9107e-04, -9.0040e+00, -9.5938e+00],\n",
      "        [-7.9508e+00, -4.7803e-04, -8.9823e+00],\n",
      "        [-8.2729e+00, -1.0237e+01, -2.9119e-04],\n",
      "        [-1.2051e-04, -9.7049e+00, -9.7297e+00],\n",
      "        [-9.0135e+00, -1.4018e-04, -1.0899e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9673e+00, -4.7589e-04, -8.9547e+00],\n",
      "        [-8.2325e+00, -1.0505e+01, -2.9333e-04],\n",
      "        [-1.2027e-04, -9.4084e+00, -1.0172e+01],\n",
      "        [-9.1685e+00, -1.2993e-04, -1.0572e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.9000e-04, -9.0095e+00, -9.6005e+00],\n",
      "        [-7.9611e+00, -4.7351e-04, -8.9905e+00],\n",
      "        [-8.2798e+00, -1.0244e+01, -2.8916e-04],\n",
      "        [-1.1968e-04, -9.7112e+00, -9.7369e+00],\n",
      "        [-9.0272e+00, -1.3851e-04, -1.0908e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9779e+00, -4.7112e-04, -8.9632e+00],\n",
      "        [-8.2397e+00, -1.0510e+01, -2.9131e-04],\n",
      "        [-1.1956e-04, -9.4137e+00, -1.0179e+01],\n",
      "        [-9.1821e+00, -1.2826e-04, -1.0583e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8881e-04, -9.0149e+00, -9.6072e+00],\n",
      "        [-7.9715e+00, -4.6886e-04, -8.9986e+00],\n",
      "        [-8.2868e+00, -1.0251e+01, -2.8713e-04],\n",
      "        [-1.1884e-04, -9.7174e+00, -9.7440e+00],\n",
      "        [-9.0408e+00, -1.3660e-04, -1.0918e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9884e+00, -4.6648e-04, -8.9716e+00],\n",
      "        [-8.2470e+00, -1.0516e+01, -2.8916e-04],\n",
      "        [-1.1884e-04, -9.4189e+00, -1.0186e+01],\n",
      "        [-9.1957e+00, -1.2647e-04, -1.0595e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8774e-04, -9.0204e+00, -9.6140e+00],\n",
      "        [-7.9818e+00, -4.6433e-04, -9.0068e+00],\n",
      "        [-8.2937e+00, -1.0259e+01, -2.8523e-04],\n",
      "        [-1.1813e-04, -9.7236e+00, -9.7512e+00],\n",
      "        [-9.0543e+00, -1.3494e-04, -1.0927e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9989e+00, -4.6183e-04, -8.9800e+00],\n",
      "        [-8.2542e+00, -1.0521e+01, -2.8713e-04],\n",
      "        [-1.1813e-04, -9.4242e+00, -1.0193e+01],\n",
      "        [-9.2091e+00, -1.2492e-04, -1.0606e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8666e-04, -9.0259e+00, -9.6208e+00],\n",
      "        [-7.9920e+00, -4.5980e-04, -9.0149e+00],\n",
      "        [-8.3007e+00, -1.0266e+01, -2.8320e-04],\n",
      "        [-1.1730e-04, -9.7299e+00, -9.7583e+00],\n",
      "        [-9.0679e+00, -1.3303e-04, -1.0937e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0094e+00, -4.5730e-04, -8.9884e+00],\n",
      "        [-8.2615e+00, -1.0527e+01, -2.8511e-04],\n",
      "        [-1.1753e-04, -9.4295e+00, -1.0200e+01],\n",
      "        [-9.2225e+00, -1.2325e-04, -1.0618e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8547e-04, -9.0314e+00, -9.6275e+00],\n",
      "        [-8.0022e+00, -4.5539e-04, -9.0230e+00],\n",
      "        [-8.3078e+00, -1.0273e+01, -2.8118e-04],\n",
      "        [-1.1658e-04, -9.7361e+00, -9.7655e+00],\n",
      "        [-9.0813e+00, -1.3148e-04, -1.0946e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0198e+00, -4.5277e-04, -8.9967e+00],\n",
      "        [-8.2688e+00, -1.0533e+01, -2.8308e-04],\n",
      "        [-1.1682e-04, -9.4349e+00, -1.0207e+01],\n",
      "        [-9.2358e+00, -1.2171e-04, -1.0629e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8440e-04, -9.0369e+00, -9.6343e+00],\n",
      "        [-8.0124e+00, -4.5111e-04, -9.0310e+00],\n",
      "        [-8.3148e+00, -1.0281e+01, -2.7915e-04],\n",
      "        [-1.1575e-04, -9.7424e+00, -9.7726e+00],\n",
      "        [-9.0947e+00, -1.2969e-04, -1.0956e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0301e+00, -4.4836e-04, -9.0051e+00],\n",
      "        [-8.2761e+00, -1.0538e+01, -2.8106e-04],\n",
      "        [-1.1622e-04, -9.4403e+00, -1.0214e+01],\n",
      "        [-9.2491e+00, -1.2016e-04, -1.0641e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8321e-04, -9.0424e+00, -9.6411e+00],\n",
      "        [-8.0225e+00, -4.4682e-04, -9.0391e+00],\n",
      "        [-8.3219e+00, -1.0288e+01, -2.7724e-04],\n",
      "        [-1.1503e-04, -9.7486e+00, -9.7798e+00],\n",
      "        [-9.1081e+00, -1.2802e-04, -1.0965e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0404e+00, -4.4408e-04, -9.0134e+00],\n",
      "        [-8.2835e+00, -1.0544e+01, -2.7903e-04],\n",
      "        [-1.1539e-04, -9.4458e+00, -1.0221e+01],\n",
      "        [-9.2623e+00, -1.1861e-04, -1.0652e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8225e-04, -9.0479e+00, -9.6479e+00],\n",
      "        [-8.0326e+00, -4.4253e-04, -9.0471e+00],\n",
      "        [-8.3289e+00, -1.0295e+01, -2.7522e-04],\n",
      "        [-1.1420e-04, -9.7549e+00, -9.7870e+00],\n",
      "        [-9.1214e+00, -1.2647e-04, -1.0975e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0507e+00, -4.3967e-04, -9.0217e+00],\n",
      "        [-8.2908e+00, -1.0549e+01, -2.7700e-04],\n",
      "        [-1.1467e-04, -9.4512e+00, -1.0227e+01],\n",
      "        [-9.2753e+00, -1.1706e-04, -1.0663e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.8118e-04, -9.0534e+00, -9.6547e+00],\n",
      "        [-8.0426e+00, -4.3836e-04, -9.0552e+00],\n",
      "        [-8.3360e+00, -1.0302e+01, -2.7331e-04],\n",
      "        [-1.1348e-04, -9.7612e+00, -9.7941e+00],\n",
      "        [-9.1347e+00, -1.2480e-04, -1.0985e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0609e+00, -4.3550e-04, -9.0300e+00],\n",
      "        [-8.2982e+00, -1.0555e+01, -2.7510e-04],\n",
      "        [-1.1408e-04, -9.4568e+00, -1.0234e+01],\n",
      "        [-9.2884e+00, -1.1563e-04, -1.0674e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7999e-04, -9.0590e+00, -9.6615e+00],\n",
      "        [-8.0526e+00, -4.3419e-04, -9.0632e+00],\n",
      "        [-8.3432e+00, -1.0310e+01, -2.7140e-04],\n",
      "        [-1.1277e-04, -9.7675e+00, -9.8013e+00],\n",
      "        [-9.1479e+00, -1.2325e-04, -1.0994e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0710e+00, -4.3133e-04, -9.0382e+00],\n",
      "        [-8.3056e+00, -1.0560e+01, -2.7307e-04],\n",
      "        [-1.1336e-04, -9.4623e+00, -1.0241e+01],\n",
      "        [-9.3013e+00, -1.1420e-04, -1.0685e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7904e-04, -9.0646e+00, -9.6683e+00],\n",
      "        [-8.0626e+00, -4.3025e-04, -9.0712e+00],\n",
      "        [-8.3503e+00, -1.0317e+01, -2.6938e-04],\n",
      "        [-1.1193e-04, -9.7737e+00, -9.8085e+00],\n",
      "        [-9.1610e+00, -1.2171e-04, -1.1004e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0811e+00, -4.2727e-04, -9.0464e+00],\n",
      "        [-8.3130e+00, -1.0566e+01, -2.7116e-04],\n",
      "        [-1.1265e-04, -9.4679e+00, -1.0248e+01],\n",
      "        [-9.3142e+00, -1.1277e-04, -1.0697e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7784e-04, -9.0701e+00, -9.6751e+00],\n",
      "        [-8.0725e+00, -4.2608e-04, -9.0791e+00],\n",
      "        [-8.3574e+00, -1.0324e+01, -2.6747e-04],\n",
      "        [-1.1122e-04, -9.7800e+00, -9.8157e+00],\n",
      "        [-9.1741e+00, -1.2016e-04, -1.1013e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0912e+00, -4.2322e-04, -9.0546e+00],\n",
      "        [-8.3204e+00, -1.0571e+01, -2.6914e-04],\n",
      "        [-1.1205e-04, -9.4735e+00, -1.0255e+01],\n",
      "        [-9.3270e+00, -1.1145e-04, -1.0708e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7689e-04, -9.0757e+00, -9.6819e+00],\n",
      "        [-8.0823e+00, -4.2215e-04, -9.0871e+00],\n",
      "        [-8.3646e+00, -1.0331e+01, -2.6556e-04],\n",
      "        [-1.1050e-04, -9.7863e+00, -9.8229e+00],\n",
      "        [-9.1872e+00, -1.1873e-04, -1.1023e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1012e+00, -4.1917e-04, -9.0628e+00],\n",
      "        [-8.3279e+00, -1.0577e+01, -2.6723e-04],\n",
      "        [-1.1134e-04, -9.4792e+00, -1.0261e+01],\n",
      "        [-9.3397e+00, -1.1002e-04, -1.0719e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7582e-04, -9.0813e+00, -9.6887e+00],\n",
      "        [-8.0922e+00, -4.1822e-04, -9.0950e+00],\n",
      "        [-8.3718e+00, -1.0339e+01, -2.6366e-04],\n",
      "        [-1.0967e-04, -9.7926e+00, -9.8301e+00],\n",
      "        [-9.2002e+00, -1.1718e-04, -1.1033e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1112e+00, -4.1524e-04, -9.0710e+00],\n",
      "        [-8.3353e+00, -1.0583e+01, -2.6532e-04],\n",
      "        [-1.1074e-04, -9.4848e+00, -1.0268e+01],\n",
      "        [-9.3523e+00, -1.0871e-04, -1.0730e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7475e-04, -9.0869e+00, -9.6955e+00],\n",
      "        [-8.1019e+00, -4.1429e-04, -9.1029e+00],\n",
      "        [-8.3790e+00, -1.0346e+01, -2.6187e-04],\n",
      "        [-1.0895e-04, -9.7989e+00, -9.8372e+00],\n",
      "        [-9.2132e+00, -1.1575e-04, -1.1042e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1211e+00, -4.1131e-04, -9.0791e+00],\n",
      "        [-8.3427e+00, -1.0588e+01, -2.6342e-04],\n",
      "        [-1.1002e-04, -9.4905e+00, -1.0275e+01],\n",
      "        [-9.3649e+00, -1.0740e-04, -1.0740e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7367e-04, -9.0925e+00, -9.7023e+00],\n",
      "        [-8.1117e+00, -4.1059e-04, -9.1108e+00],\n",
      "        [-8.3861e+00, -1.0353e+01, -2.5996e-04],\n",
      "        [-1.0824e-04, -9.8052e+00, -9.8444e+00],\n",
      "        [-9.2261e+00, -1.1432e-04, -1.1052e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1310e+00, -4.0749e-04, -9.0872e+00],\n",
      "        [-8.3502e+00, -1.0594e+01, -2.6151e-04],\n",
      "        [-1.0931e-04, -9.4963e+00, -1.0281e+01],\n",
      "        [-9.3774e+00, -1.0609e-04, -1.0751e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7272e-04, -9.0981e+00, -9.7091e+00],\n",
      "        [-8.1214e+00, -4.0678e-04, -9.1187e+00],\n",
      "        [-8.3933e+00, -1.0360e+01, -2.5805e-04],\n",
      "        [-1.0752e-04, -9.8115e+00, -9.8516e+00],\n",
      "        [-9.2389e+00, -1.1288e-04, -1.1062e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1408e+00, -4.0368e-04, -9.0953e+00],\n",
      "        [-8.3577e+00, -1.0599e+01, -2.5960e-04],\n",
      "        [-1.0883e-04, -9.5020e+00, -1.0288e+01],\n",
      "        [-9.3898e+00, -1.0478e-04, -1.0762e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7153e-04, -9.1037e+00, -9.7159e+00],\n",
      "        [-8.1310e+00, -4.0320e-04, -9.1265e+00],\n",
      "        [-8.4006e+00, -1.0367e+01, -2.5627e-04],\n",
      "        [-1.0681e-04, -9.8178e+00, -9.8588e+00],\n",
      "        [-9.2517e+00, -1.1145e-04, -1.1071e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1506e+00, -3.9999e-04, -9.1033e+00],\n",
      "        [-8.3651e+00, -1.0605e+01, -2.5770e-04],\n",
      "        [-1.0812e-04, -9.5078e+00, -1.0295e+01],\n",
      "        [-9.4022e+00, -1.0347e-04, -1.0773e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.7057e-04, -9.1093e+00, -9.7227e+00],\n",
      "        [-8.1406e+00, -3.9939e-04, -9.1344e+00],\n",
      "        [-8.4078e+00, -1.0374e+01, -2.5436e-04],\n",
      "        [-1.0609e-04, -9.8241e+00, -9.8660e+00],\n",
      "        [-9.2645e+00, -1.1014e-04, -1.1081e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_scores\n",
      "tensor([[-8.1604e+00, -3.9629e-04, -9.1114e+00],\n",
      "        [-8.3726e+00, -1.0610e+01, -2.5579e-04],\n",
      "        [-1.0740e-04, -9.5136e+00, -1.0301e+01],\n",
      "        [-9.4145e+00, -1.0228e-04, -1.0783e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6950e-04, -9.1149e+00, -9.7295e+00],\n",
      "        [-8.1502e+00, -3.9582e-04, -9.1422e+00],\n",
      "        [-8.4150e+00, -1.0381e+01, -2.5257e-04],\n",
      "        [-1.0526e-04, -9.8304e+00, -9.8732e+00],\n",
      "        [-9.2772e+00, -1.0883e-04, -1.1091e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1701e+00, -3.9260e-04, -9.1194e+00],\n",
      "        [-8.3801e+00, -1.0616e+01, -2.5400e-04],\n",
      "        [-1.0681e-04, -9.5195e+00, -1.0308e+01],\n",
      "        [-9.4267e+00, -1.0108e-04, -1.0794e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6855e-04, -9.1206e+00, -9.7363e+00],\n",
      "        [-8.1597e+00, -3.9224e-04, -9.1500e+00],\n",
      "        [-8.4222e+00, -1.0388e+01, -2.5078e-04],\n",
      "        [-1.0454e-04, -9.8367e+00, -9.8803e+00],\n",
      "        [-9.2898e+00, -1.0752e-04, -1.1100e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1797e+00, -3.8902e-04, -9.1273e+00],\n",
      "        [-8.3876e+00, -1.0621e+01, -2.5210e-04],\n",
      "        [-1.0609e-04, -9.5253e+00, -1.0315e+01],\n",
      "        [-9.4389e+00, -9.9892e-05, -1.0805e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6748e-04, -9.1262e+00, -9.7431e+00],\n",
      "        [-8.1691e+00, -3.8879e-04, -9.1577e+00],\n",
      "        [-8.4295e+00, -1.0396e+01, -2.4888e-04],\n",
      "        [-1.0395e-04, -9.8430e+00, -9.8875e+00],\n",
      "        [-9.3024e+00, -1.0621e-04, -1.1110e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1893e+00, -3.8557e-04, -9.1353e+00],\n",
      "        [-8.3951e+00, -1.0627e+01, -2.5031e-04],\n",
      "        [-1.0549e-04, -9.5312e+00, -1.0321e+01],\n",
      "        [-9.4509e+00, -9.8820e-05, -1.0815e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6652e-04, -9.1318e+00, -9.7499e+00],\n",
      "        [-8.1786e+00, -3.8533e-04, -9.1655e+00],\n",
      "        [-8.4367e+00, -1.0403e+01, -2.4709e-04],\n",
      "        [-1.0323e-04, -9.8494e+00, -9.8947e+00],\n",
      "        [-9.3149e+00, -1.0490e-04, -1.1119e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1989e+00, -3.8187e-04, -9.1432e+00],\n",
      "        [-8.4025e+00, -1.0632e+01, -2.4840e-04],\n",
      "        [-1.0478e-04, -9.5371e+00, -1.0328e+01],\n",
      "        [-9.4630e+00, -9.7628e-05, -1.0826e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6545e-04, -9.1375e+00, -9.7567e+00],\n",
      "        [-8.1880e+00, -3.8187e-04, -9.1732e+00],\n",
      "        [-8.4440e+00, -1.0410e+01, -2.4542e-04],\n",
      "        [-1.0251e-04, -9.8557e+00, -9.9018e+00],\n",
      "        [-9.3274e+00, -1.0359e-04, -1.1129e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2084e+00, -3.7854e-04, -9.1511e+00],\n",
      "        [-8.4100e+00, -1.0638e+01, -2.4661e-04],\n",
      "        [-1.0430e-04, -9.5430e+00, -1.0334e+01],\n",
      "        [-9.4749e+00, -9.6436e-05, -1.0836e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6450e-04, -9.1431e+00, -9.7635e+00],\n",
      "        [-8.1973e+00, -3.7842e-04, -9.1809e+00],\n",
      "        [-8.4512e+00, -1.0417e+01, -2.4363e-04],\n",
      "        [-1.0180e-04, -9.8620e+00, -9.9090e+00],\n",
      "        [-9.3398e+00, -1.0240e-04, -1.1139e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2179e+00, -3.7508e-04, -9.1590e+00],\n",
      "        [-8.4175e+00, -1.0643e+01, -2.4483e-04],\n",
      "        [-1.0359e-04, -9.5490e+00, -1.0341e+01],\n",
      "        [-9.4868e+00, -9.5244e-05, -1.0847e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6342e-04, -9.1487e+00, -9.7703e+00],\n",
      "        [-8.2066e+00, -3.7520e-04, -9.1886e+00],\n",
      "        [-8.4585e+00, -1.0424e+01, -2.4185e-04],\n",
      "        [-1.0120e-04, -9.8683e+00, -9.9161e+00],\n",
      "        [-9.3522e+00, -1.0120e-04, -1.1148e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2273e+00, -3.7186e-04, -9.1668e+00],\n",
      "        [-8.4250e+00, -1.0649e+01, -2.4304e-04],\n",
      "        [-1.0287e-04, -9.5550e+00, -1.0347e+01],\n",
      "        [-9.4986e+00, -9.4290e-05, -1.0857e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6247e-04, -9.1544e+00, -9.7770e+00],\n",
      "        [-8.2159e+00, -3.7186e-04, -9.1962e+00],\n",
      "        [-8.4657e+00, -1.0431e+01, -2.4006e-04],\n",
      "        [-1.0049e-04, -9.8746e+00, -9.9233e+00],\n",
      "        [-9.3645e+00, -1.0001e-04, -1.1158e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2367e+00, -3.6853e-04, -9.1746e+00],\n",
      "        [-8.4325e+00, -1.0654e+01, -2.4125e-04],\n",
      "        [-1.0228e-04, -9.5610e+00, -1.0354e+01],\n",
      "        [-9.5103e+00, -9.3217e-05, -1.0867e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6152e-04, -9.1600e+00, -9.7838e+00],\n",
      "        [-8.2251e+00, -3.6865e-04, -9.2039e+00],\n",
      "        [-8.4730e+00, -1.0438e+01, -2.3839e-04],\n",
      "        [-9.9773e-05, -9.8809e+00, -9.9304e+00],\n",
      "        [-9.3768e+00, -9.8820e-05, -1.1167e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2460e+00, -3.6519e-04, -9.1824e+00],\n",
      "        [-8.4400e+00, -1.0660e+01, -2.3958e-04],\n",
      "        [-1.0168e-04, -9.5670e+00, -1.0360e+01],\n",
      "        [-9.5220e+00, -9.2025e-05, -1.0878e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.6056e-04, -9.1657e+00, -9.7906e+00],\n",
      "        [-8.2343e+00, -3.6531e-04, -9.2115e+00],\n",
      "        [-8.4802e+00, -1.0445e+01, -2.3672e-04],\n",
      "        [-9.9058e-05, -9.8872e+00, -9.9376e+00],\n",
      "        [-9.3890e+00, -9.7628e-05, -1.1177e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2553e+00, -3.6197e-04, -9.1902e+00],\n",
      "        [-8.4475e+00, -1.0665e+01, -2.3779e-04],\n",
      "        [-1.0108e-04, -9.5730e+00, -1.0366e+01],\n",
      "        [-9.5336e+00, -9.1072e-05, -1.0888e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5949e-04, -9.1713e+00, -9.7974e+00],\n",
      "        [-8.2434e+00, -3.6221e-04, -9.2190e+00],\n",
      "        [-8.4875e+00, -1.0452e+01, -2.3493e-04],\n",
      "        [-9.8581e-05, -9.8935e+00, -9.9447e+00],\n",
      "        [-9.4012e+00, -9.6436e-05, -1.1186e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2646e+00, -3.5887e-04, -9.1979e+00],\n",
      "        [-8.4550e+00, -1.0671e+01, -2.3613e-04],\n",
      "        [-1.0037e-04, -9.5790e+00, -1.0373e+01],\n",
      "        [-9.5452e+00, -8.9999e-05, -1.0898e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5854e-04, -9.1770e+00, -9.8041e+00],\n",
      "        [-8.2525e+00, -3.5911e-04, -9.2266e+00],\n",
      "        [-8.4947e+00, -1.0458e+01, -2.3327e-04],\n",
      "        [-9.7866e-05, -9.8998e+00, -9.9518e+00],\n",
      "        [-9.4133e+00, -9.5363e-05, -1.1196e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2738e+00, -3.5566e-04, -9.2056e+00],\n",
      "        [-8.4625e+00, -1.0676e+01, -2.3434e-04],\n",
      "        [-9.9892e-05, -9.5851e+00, -1.0379e+01],\n",
      "        [-9.5567e+00, -8.9045e-05, -1.0908e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5770e-04, -9.1826e+00, -9.8109e+00],\n",
      "        [-8.2615e+00, -3.5590e-04, -9.2341e+00],\n",
      "        [-8.5020e+00, -1.0465e+01, -2.3160e-04],\n",
      "        [-9.7151e-05, -9.9061e+00, -9.9589e+00],\n",
      "        [-9.4254e+00, -9.4290e-05, -1.1205e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2830e+00, -3.5256e-04, -9.2133e+00],\n",
      "        [-8.4700e+00, -1.0682e+01, -2.3267e-04],\n",
      "        [-9.9177e-05, -9.5912e+00, -1.0386e+01],\n",
      "        [-9.5681e+00, -8.8092e-05, -1.0918e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5675e-04, -9.1883e+00, -9.8176e+00],\n",
      "        [-8.2706e+00, -3.5292e-04, -9.2417e+00],\n",
      "        [-8.5092e+00, -1.0472e+01, -2.2993e-04],\n",
      "        [-9.6555e-05, -9.9124e+00, -9.9660e+00],\n",
      "        [-9.4374e+00, -9.3217e-05, -1.1215e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2921e+00, -3.4946e-04, -9.2210e+00],\n",
      "        [-8.4774e+00, -1.0687e+01, -2.3100e-04],\n",
      "        [-9.8581e-05, -9.5972e+00, -1.0392e+01],\n",
      "        [-9.5794e+00, -8.7138e-05, -1.0928e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5579e-04, -9.1939e+00, -9.8243e+00],\n",
      "        [-8.2795e+00, -3.4994e-04, -9.2492e+00],\n",
      "        [-8.5164e+00, -1.0479e+01, -2.2826e-04],\n",
      "        [-9.5840e-05, -9.9187e+00, -9.9731e+00],\n",
      "        [-9.4494e+00, -9.2145e-05, -1.1224e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3012e+00, -3.4648e-04, -9.2286e+00],\n",
      "        [-8.4849e+00, -1.0693e+01, -2.2933e-04],\n",
      "        [-9.7985e-05, -9.6034e+00, -1.0398e+01],\n",
      "        [-9.5907e+00, -8.6065e-05, -1.0938e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5484e-04, -9.1995e+00, -9.8311e+00],\n",
      "        [-8.2885e+00, -3.4696e-04, -9.2566e+00],\n",
      "        [-8.5237e+00, -1.0486e+01, -2.2671e-04],\n",
      "        [-9.5363e-05, -9.9249e+00, -9.9802e+00],\n",
      "        [-9.4613e+00, -9.1072e-05, -1.1234e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3102e+00, -3.4350e-04, -9.2362e+00],\n",
      "        [-8.4924e+00, -1.0698e+01, -2.2766e-04],\n",
      "        [-9.7389e-05, -9.6095e+00, -1.0405e+01],\n",
      "        [-9.6020e+00, -8.5231e-05, -1.0948e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5389e-04, -9.2052e+00, -9.8378e+00],\n",
      "        [-8.2974e+00, -3.4398e-04, -9.2641e+00],\n",
      "        [-8.5309e+00, -1.0493e+01, -2.2504e-04],\n",
      "        [-9.4648e-05, -9.9312e+00, -9.9873e+00],\n",
      "        [-9.4731e+00, -8.9999e-05, -1.1243e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3192e+00, -3.4064e-04, -9.2438e+00],\n",
      "        [-8.4999e+00, -1.0703e+01, -2.2600e-04],\n",
      "        [-9.6793e-05, -9.6156e+00, -1.0411e+01],\n",
      "        [-9.6131e+00, -8.4277e-05, -1.0958e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5305e-04, -9.2108e+00, -9.8445e+00],\n",
      "        [-8.3062e+00, -3.4112e-04, -9.2715e+00],\n",
      "        [-8.5381e+00, -1.0500e+01, -2.2337e-04],\n",
      "        [-9.3933e-05, -9.9375e+00, -9.9943e+00],\n",
      "        [-9.4849e+00, -8.9045e-05, -1.1253e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3281e+00, -3.3766e-04, -9.2514e+00],\n",
      "        [-8.5073e+00, -1.0709e+01, -2.2433e-04],\n",
      "        [-9.6197e-05, -9.6217e+00, -1.0417e+01],\n",
      "        [-9.6243e+00, -8.3443e-05, -1.0968e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5210e-04, -9.2164e+00, -9.8512e+00],\n",
      "        [-8.3150e+00, -3.3826e-04, -9.2789e+00],\n",
      "        [-8.5453e+00, -1.0507e+01, -2.2182e-04],\n",
      "        [-9.3337e-05, -9.9438e+00, -1.0001e+01],\n",
      "        [-9.4967e+00, -8.7973e-05, -1.1262e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3371e+00, -3.3480e-04, -9.2589e+00],\n",
      "        [-8.5148e+00, -1.0714e+01, -2.2278e-04],\n",
      "        [-9.5601e-05, -9.6279e+00, -1.0423e+01],\n",
      "        [-9.6353e+00, -8.2370e-05, -1.0978e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5115e-04, -9.2221e+00, -9.8579e+00],\n",
      "        [-8.3238e+00, -3.3540e-04, -9.2863e+00],\n",
      "        [-8.5526e+00, -1.0513e+01, -2.2027e-04],\n",
      "        [-9.2741e-05, -9.9500e+00, -1.0008e+01],\n",
      "        [-9.5084e+00, -8.7019e-05, -1.1271e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3459e+00, -3.3194e-04, -9.2664e+00],\n",
      "        [-8.5222e+00, -1.0720e+01, -2.2111e-04],\n",
      "        [-9.5005e-05, -9.6341e+00, -1.0430e+01],\n",
      "        [-9.6463e+00, -8.1536e-05, -1.0988e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.5031e-04, -9.2277e+00, -9.8646e+00],\n",
      "        [-8.3325e+00, -3.3266e-04, -9.2936e+00],\n",
      "        [-8.5598e+00, -1.0520e+01, -2.1873e-04],\n",
      "        [-9.2145e-05, -9.9563e+00, -1.0015e+01],\n",
      "        [-9.5200e+00, -8.6065e-05, -1.1281e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3548e+00, -3.2908e-04, -9.2739e+00],\n",
      "        [-8.5297e+00, -1.0725e+01, -2.1956e-04],\n",
      "        [-9.4409e-05, -9.6402e+00, -1.0436e+01],\n",
      "        [-9.6572e+00, -8.0701e-05, -1.0997e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4936e-04, -9.2333e+00, -9.8713e+00],\n",
      "        [-8.3412e+00, -3.2980e-04, -9.3010e+00],\n",
      "        [-8.5670e+00, -1.0527e+01, -2.1706e-04],\n",
      "        [-9.1429e-05, -9.9625e+00, -1.0022e+01],\n",
      "        [-9.5316e+00, -8.4993e-05, -1.1290e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3635e+00, -3.2646e-04, -9.2813e+00],\n",
      "        [-8.5371e+00, -1.0730e+01, -2.1801e-04],\n",
      "        [-9.3813e-05, -9.6464e+00, -1.0442e+01],\n",
      "        [-9.6681e+00, -7.9867e-05, -1.1007e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4840e-04, -9.2390e+00, -9.8779e+00],\n",
      "        [-8.3499e+00, -3.2718e-04, -9.3083e+00],\n",
      "        [-8.5742e+00, -1.0534e+01, -2.1563e-04],\n",
      "        [-9.0953e-05, -9.9688e+00, -1.0029e+01],\n",
      "        [-9.5431e+00, -8.4039e-05, -1.1299e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3723e+00, -3.2372e-04, -9.2888e+00],\n",
      "        [-8.5445e+00, -1.0736e+01, -2.1634e-04],\n",
      "        [-9.3217e-05, -9.6526e+00, -1.0448e+01],\n",
      "        [-9.6789e+00, -7.9033e-05, -1.1017e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4757e-04, -9.2446e+00, -9.8846e+00],\n",
      "        [-8.3585e+00, -3.2444e-04, -9.3155e+00],\n",
      "        [-8.5814e+00, -1.0541e+01, -2.1408e-04],\n",
      "        [-9.0357e-05, -9.9750e+00, -1.0036e+01],\n",
      "        [-9.5546e+00, -8.3205e-05, -1.1309e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3810e+00, -3.2098e-04, -9.2962e+00],\n",
      "        [-8.5519e+00, -1.0741e+01, -2.1479e-04],\n",
      "        [-9.2741e-05, -9.6588e+00, -1.0454e+01],\n",
      "        [-9.6897e+00, -7.8079e-05, -1.1026e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4674e-04, -9.2502e+00, -9.8912e+00],\n",
      "        [-8.3670e+00, -3.2181e-04, -9.3228e+00],\n",
      "        [-8.5885e+00, -1.0547e+01, -2.1253e-04],\n",
      "        [-8.9761e-05, -9.9813e+00, -1.0043e+01],\n",
      "        [-9.5661e+00, -8.2251e-05, -1.1318e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3897e+00, -3.1836e-04, -9.3035e+00],\n",
      "        [-8.5593e+00, -1.0747e+01, -2.1324e-04],\n",
      "        [-9.2025e-05, -9.6650e+00, -1.0460e+01],\n",
      "        [-9.7004e+00, -7.7364e-05, -1.1036e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4590e-04, -9.2558e+00, -9.8979e+00],\n",
      "        [-8.3756e+00, -3.1919e-04, -9.3300e+00],\n",
      "        [-8.5957e+00, -1.0554e+01, -2.1098e-04],\n",
      "        [-8.9165e-05, -9.9875e+00, -1.0050e+01],\n",
      "        [-9.5774e+00, -8.1297e-05, -1.1327e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3983e+00, -3.1574e-04, -9.3109e+00],\n",
      "        [-8.5667e+00, -1.0752e+01, -2.1181e-04],\n",
      "        [-9.1549e-05, -9.6712e+00, -1.0466e+01],\n",
      "        [-9.7110e+00, -7.6529e-05, -1.1045e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4495e-04, -9.2614e+00, -9.9045e+00],\n",
      "        [-8.3841e+00, -3.1657e-04, -9.3372e+00],\n",
      "        [-8.6029e+00, -1.0561e+01, -2.0955e-04],\n",
      "        [-8.8569e-05, -9.9937e+00, -1.0057e+01],\n",
      "        [-9.5888e+00, -8.0463e-05, -1.1336e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4069e+00, -3.1311e-04, -9.3182e+00],\n",
      "        [-8.5741e+00, -1.0757e+01, -2.1026e-04],\n",
      "        [-9.0953e-05, -9.6774e+00, -1.0473e+01],\n",
      "        [-9.7216e+00, -7.5814e-05, -1.1055e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4411e-04, -9.2670e+00, -9.9111e+00],\n",
      "        [-8.3925e+00, -3.1407e-04, -9.3444e+00],\n",
      "        [-8.6100e+00, -1.0567e+01, -2.0800e-04],\n",
      "        [-8.7973e-05, -1.0000e+01, -1.0064e+01],\n",
      "        [-9.6001e+00, -7.9509e-05, -1.1346e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4154e+00, -3.1061e-04, -9.3255e+00],\n",
      "        [-8.5815e+00, -1.0763e+01, -2.0871e-04],\n",
      "        [-9.0476e-05, -9.6837e+00, -1.0479e+01],\n",
      "        [-9.7321e+00, -7.4980e-05, -1.1064e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4328e-04, -9.2726e+00, -9.9177e+00],\n",
      "        [-8.4010e+00, -3.1156e-04, -9.3516e+00],\n",
      "        [-8.6172e+00, -1.0574e+01, -2.0657e-04],\n",
      "        [-8.7496e-05, -1.0006e+01, -1.0071e+01],\n",
      "        [-9.6113e+00, -7.8675e-05, -1.1355e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4239e+00, -3.0799e-04, -9.3327e+00],\n",
      "        [-8.5888e+00, -1.0768e+01, -2.0728e-04],\n",
      "        [-8.9880e-05, -9.6899e+00, -1.0485e+01],\n",
      "        [-9.7426e+00, -7.4265e-05, -1.1074e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4244e-04, -9.2782e+00, -9.9243e+00],\n",
      "        [-8.4094e+00, -3.0894e-04, -9.3587e+00],\n",
      "        [-8.6243e+00, -1.0581e+01, -2.0514e-04],\n",
      "        [-8.6781e-05, -1.0012e+01, -1.0078e+01],\n",
      "        [-9.6225e+00, -7.7841e-05, -1.1364e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4324e+00, -3.0561e-04, -9.3400e+00],\n",
      "        [-8.5962e+00, -1.0773e+01, -2.0573e-04],\n",
      "        [-8.9284e-05, -9.6961e+00, -1.0491e+01],\n",
      "        [-9.7530e+00, -7.3549e-05, -1.1083e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4161e-04, -9.2838e+00, -9.9309e+00],\n",
      "        [-8.4177e+00, -3.0656e-04, -9.3659e+00],\n",
      "        [-8.6314e+00, -1.0588e+01, -2.0371e-04],\n",
      "        [-8.6304e-05, -1.0019e+01, -1.0085e+01],\n",
      "        [-9.6336e+00, -7.6887e-05, -1.1373e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4408e+00, -3.0310e-04, -9.3472e+00],\n",
      "        [-8.6035e+00, -1.0778e+01, -2.0430e-04],\n",
      "        [-8.8807e-05, -9.7024e+00, -1.0497e+01],\n",
      "        [-9.7634e+00, -7.2834e-05, -1.1092e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.4066e-04, -9.2893e+00, -9.9375e+00],\n",
      "        [-8.4260e+00, -3.0406e-04, -9.3729e+00],\n",
      "        [-8.6385e+00, -1.0594e+01, -2.0228e-04],\n",
      "        [-8.5708e-05, -1.0025e+01, -1.0092e+01],\n",
      "        [-9.6447e+00, -7.6172e-05, -1.1382e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_scores\n",
      "tensor([[-8.4492e+00, -3.0072e-04, -9.3544e+00],\n",
      "        [-8.6109e+00, -1.0784e+01, -2.0287e-04],\n",
      "        [-8.8211e-05, -9.7086e+00, -1.0503e+01],\n",
      "        [-9.7737e+00, -7.2119e-05, -1.1102e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3994e-04, -9.2949e+00, -9.9440e+00],\n",
      "        [-8.4343e+00, -3.0167e-04, -9.3800e+00],\n",
      "        [-8.6456e+00, -1.0601e+01, -2.0085e-04],\n",
      "        [-8.5112e-05, -1.0031e+01, -1.0099e+01],\n",
      "        [-9.6558e+00, -7.5337e-05, -1.1391e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4576e+00, -2.9822e-04, -9.3616e+00],\n",
      "        [-8.6182e+00, -1.0789e+01, -2.0144e-04],\n",
      "        [-8.7734e-05, -9.7149e+00, -1.0509e+01],\n",
      "        [-9.7840e+00, -7.1285e-05, -1.1111e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3911e-04, -9.3005e+00, -9.9506e+00],\n",
      "        [-8.4425e+00, -2.9929e-04, -9.3871e+00],\n",
      "        [-8.6527e+00, -1.0607e+01, -1.9942e-04],\n",
      "        [-8.4635e-05, -1.0037e+01, -1.0106e+01],\n",
      "        [-9.6667e+00, -7.4622e-05, -1.1400e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4659e+00, -2.9595e-04, -9.3687e+00],\n",
      "        [-8.6255e+00, -1.0794e+01, -2.0001e-04],\n",
      "        [-8.7138e-05, -9.7211e+00, -1.0515e+01],\n",
      "        [-9.7942e+00, -7.0569e-05, -1.1120e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3827e-04, -9.3060e+00, -9.9571e+00],\n",
      "        [-8.4507e+00, -2.9703e-04, -9.3941e+00],\n",
      "        [-8.6598e+00, -1.0614e+01, -1.9799e-04],\n",
      "        [-8.4039e-05, -1.0043e+01, -1.0113e+01],\n",
      "        [-9.6777e+00, -7.3788e-05, -1.1409e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4742e+00, -2.9357e-04, -9.3758e+00],\n",
      "        [-8.6328e+00, -1.0800e+01, -1.9858e-04],\n",
      "        [-8.6542e-05, -9.7274e+00, -1.0520e+01],\n",
      "        [-9.8043e+00, -6.9854e-05, -1.1129e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3744e-04, -9.3116e+00, -9.9636e+00],\n",
      "        [-8.4589e+00, -2.9464e-04, -9.4011e+00],\n",
      "        [-8.6668e+00, -1.0621e+01, -1.9668e-04],\n",
      "        [-8.3562e-05, -1.0049e+01, -1.0119e+01],\n",
      "        [-9.6886e+00, -7.2953e-05, -1.1418e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4824e+00, -2.9131e-04, -9.3829e+00],\n",
      "        [-8.6401e+00, -1.0805e+01, -1.9715e-04],\n",
      "        [-8.6065e-05, -9.7336e+00, -1.0526e+01],\n",
      "        [-9.8144e+00, -6.9258e-05, -1.1138e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3660e-04, -9.3171e+00, -9.9701e+00],\n",
      "        [-8.4670e+00, -2.9250e-04, -9.4081e+00],\n",
      "        [-8.6739e+00, -1.0627e+01, -1.9525e-04],\n",
      "        [-8.2966e-05, -1.0056e+01, -1.0126e+01],\n",
      "        [-9.6994e+00, -7.2119e-05, -1.1427e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4906e+00, -2.8892e-04, -9.3900e+00],\n",
      "        [-8.6473e+00, -1.0810e+01, -1.9584e-04],\n",
      "        [-8.5589e-05, -9.7399e+00, -1.0532e+01],\n",
      "        [-9.8245e+00, -6.8543e-05, -1.1147e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3589e-04, -9.3227e+00, -9.9766e+00],\n",
      "        [-8.4751e+00, -2.9011e-04, -9.4150e+00],\n",
      "        [-8.6809e+00, -1.0634e+01, -1.9393e-04],\n",
      "        [-8.2370e-05, -1.0062e+01, -1.0133e+01],\n",
      "        [-9.7102e+00, -7.1523e-05, -1.1436e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4988e+00, -2.8666e-04, -9.3970e+00],\n",
      "        [-8.6546e+00, -1.0815e+01, -1.9441e-04],\n",
      "        [-8.4993e-05, -9.7462e+00, -1.0538e+01],\n",
      "        [-9.8345e+00, -6.7828e-05, -1.1156e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3506e-04, -9.3282e+00, -9.9831e+00],\n",
      "        [-8.4832e+00, -2.8785e-04, -9.4220e+00],\n",
      "        [-8.6880e+00, -1.0640e+01, -1.9250e-04],\n",
      "        [-8.1893e-05, -1.0068e+01, -1.0140e+01],\n",
      "        [-9.7209e+00, -7.0689e-05, -1.1445e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5069e+00, -2.8451e-04, -9.4040e+00],\n",
      "        [-8.6618e+00, -1.0821e+01, -1.9310e-04],\n",
      "        [-8.4516e-05, -9.7524e+00, -1.0544e+01],\n",
      "        [-9.8444e+00, -6.7232e-05, -1.1165e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3434e-04, -9.3337e+00, -9.9896e+00],\n",
      "        [-8.4912e+00, -2.8558e-04, -9.4289e+00],\n",
      "        [-8.6950e+00, -1.0647e+01, -1.9119e-04],\n",
      "        [-8.1417e-05, -1.0074e+01, -1.0147e+01],\n",
      "        [-9.7316e+00, -6.9973e-05, -1.1454e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5150e+00, -2.8237e-04, -9.4110e+00],\n",
      "        [-8.6691e+00, -1.0826e+01, -1.9167e-04],\n",
      "        [-8.4039e-05, -9.7587e+00, -1.0550e+01],\n",
      "        [-9.8543e+00, -6.6636e-05, -1.1174e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3351e-04, -9.3393e+00, -9.9961e+00],\n",
      "        [-8.4992e+00, -2.8356e-04, -9.4358e+00],\n",
      "        [-8.7020e+00, -1.0653e+01, -1.8988e-04],\n",
      "        [-8.0940e-05, -1.0080e+01, -1.0153e+01],\n",
      "        [-9.7423e+00, -6.9258e-05, -1.1463e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5231e+00, -2.8010e-04, -9.4180e+00],\n",
      "        [-8.6763e+00, -1.0831e+01, -1.9036e-04],\n",
      "        [-8.3562e-05, -9.7649e+00, -1.0556e+01],\n",
      "        [-9.8642e+00, -6.5921e-05, -1.1183e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3267e-04, -9.3448e+00, -1.0003e+01],\n",
      "        [-8.5072e+00, -2.8129e-04, -9.4426e+00],\n",
      "        [-8.7090e+00, -1.0660e+01, -1.8857e-04],\n",
      "        [-8.0344e-05, -1.0086e+01, -1.0160e+01],\n",
      "        [-9.7529e+00, -6.8543e-05, -1.1471e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5311e+00, -2.7796e-04, -9.4249e+00],\n",
      "        [-8.6835e+00, -1.0836e+01, -1.8905e-04],\n",
      "        [-8.2966e-05, -9.7712e+00, -1.0561e+01],\n",
      "        [-9.8740e+00, -6.5325e-05, -1.1192e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3196e-04, -9.3503e+00, -1.0009e+01],\n",
      "        [-8.5151e+00, -2.7927e-04, -9.4495e+00],\n",
      "        [-8.7160e+00, -1.0666e+01, -1.8726e-04],\n",
      "        [-7.9748e-05, -1.0092e+01, -1.0167e+01],\n",
      "        [-9.7634e+00, -6.7947e-05, -1.1480e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5391e+00, -2.7581e-04, -9.4318e+00],\n",
      "        [-8.6907e+00, -1.0841e+01, -1.8774e-04],\n",
      "        [-8.2489e-05, -9.7775e+00, -1.0567e+01],\n",
      "        [-9.8837e+00, -6.4729e-05, -1.1201e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3112e-04, -9.3558e+00, -1.0015e+01],\n",
      "        [-8.5230e+00, -2.7700e-04, -9.4563e+00],\n",
      "        [-8.7229e+00, -1.0673e+01, -1.8595e-04],\n",
      "        [-7.9271e-05, -1.0098e+01, -1.0174e+01],\n",
      "        [-9.7739e+00, -6.7113e-05, -1.1489e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5470e+00, -2.7379e-04, -9.4387e+00],\n",
      "        [-8.6979e+00, -1.0847e+01, -1.8643e-04],\n",
      "        [-8.2013e-05, -9.7837e+00, -1.0573e+01],\n",
      "        [-9.8935e+00, -6.4133e-05, -1.1210e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.3041e-04, -9.3612e+00, -1.0022e+01],\n",
      "        [-8.5309e+00, -2.7498e-04, -9.4631e+00],\n",
      "        [-8.7299e+00, -1.0679e+01, -1.8476e-04],\n",
      "        [-7.8794e-05, -1.0104e+01, -1.0180e+01],\n",
      "        [-9.7844e+00, -6.6517e-05, -1.1497e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5550e+00, -2.7164e-04, -9.4456e+00],\n",
      "        [-8.7050e+00, -1.0852e+01, -1.8511e-04],\n",
      "        [-8.1536e-05, -9.7900e+00, -1.0579e+01],\n",
      "        [-9.9031e+00, -6.3537e-05, -1.1218e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2969e-04, -9.3667e+00, -1.0028e+01],\n",
      "        [-8.5387e+00, -2.7295e-04, -9.4698e+00],\n",
      "        [-8.7368e+00, -1.0685e+01, -1.8345e-04],\n",
      "        [-7.8317e-05, -1.0111e+01, -1.0187e+01],\n",
      "        [-9.7948e+00, -6.5801e-05, -1.1506e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5629e+00, -2.6962e-04, -9.4524e+00],\n",
      "        [-8.7122e+00, -1.0857e+01, -1.8380e-04],\n",
      "        [-8.0940e-05, -9.7962e+00, -1.0584e+01],\n",
      "        [-9.9127e+00, -6.2941e-05, -1.1227e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2898e-04, -9.3722e+00, -1.0035e+01],\n",
      "        [-8.5465e+00, -2.7093e-04, -9.4766e+00],\n",
      "        [-8.7437e+00, -1.0692e+01, -1.8225e-04],\n",
      "        [-7.7841e-05, -1.0117e+01, -1.0194e+01],\n",
      "        [-9.8052e+00, -6.5205e-05, -1.1515e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5707e+00, -2.6759e-04, -9.4592e+00],\n",
      "        [-8.7193e+00, -1.0862e+01, -1.8261e-04],\n",
      "        [-8.0463e-05, -9.8025e+00, -1.0590e+01],\n",
      "        [-9.9223e+00, -6.2345e-05, -1.1236e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2826e-04, -9.3776e+00, -1.0041e+01],\n",
      "        [-8.5542e+00, -2.6890e-04, -9.4833e+00],\n",
      "        [-8.7506e+00, -1.0698e+01, -1.8094e-04],\n",
      "        [-7.7364e-05, -1.0123e+01, -1.0200e+01],\n",
      "        [-9.8155e+00, -6.4490e-05, -1.1523e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5785e+00, -2.6556e-04, -9.4660e+00],\n",
      "        [-8.7264e+00, -1.0867e+01, -1.8130e-04],\n",
      "        [-7.9986e-05, -9.8087e+00, -1.0596e+01],\n",
      "        [-9.9318e+00, -6.1749e-05, -1.1244e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2743e-04, -9.3831e+00, -1.0047e+01],\n",
      "        [-8.5620e+00, -2.6687e-04, -9.4900e+00],\n",
      "        [-8.7575e+00, -1.0705e+01, -1.7975e-04],\n",
      "        [-7.6887e-05, -1.0129e+01, -1.0207e+01],\n",
      "        [-9.8258e+00, -6.3775e-05, -1.1532e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5863e+00, -2.6354e-04, -9.4728e+00],\n",
      "        [-8.7335e+00, -1.0872e+01, -1.8011e-04],\n",
      "        [-7.9509e-05, -9.8150e+00, -1.0602e+01],\n",
      "        [-9.9413e+00, -6.1152e-05, -1.1253e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2671e-04, -9.3885e+00, -1.0054e+01],\n",
      "        [-8.5697e+00, -2.6485e-04, -9.4967e+00],\n",
      "        [-8.7644e+00, -1.0711e+01, -1.7856e-04],\n",
      "        [-7.6410e-05, -1.0135e+01, -1.0214e+01],\n",
      "        [-9.8360e+00, -6.3298e-05, -1.1540e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5941e+00, -2.6163e-04, -9.4795e+00],\n",
      "        [-8.7406e+00, -1.0877e+01, -1.7880e-04],\n",
      "        [-7.9033e-05, -9.8212e+00, -1.0607e+01],\n",
      "        [-9.9507e+00, -6.0556e-05, -1.1262e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2600e-04, -9.3940e+00, -1.0060e+01],\n",
      "        [-8.5773e+00, -2.6294e-04, -9.5034e+00],\n",
      "        [-8.7713e+00, -1.0717e+01, -1.7725e-04],\n",
      "        [-7.5933e-05, -1.0141e+01, -1.0220e+01],\n",
      "        [-9.8462e+00, -6.2583e-05, -1.1549e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6018e+00, -2.5972e-04, -9.4863e+00],\n",
      "        [-8.7477e+00, -1.0882e+01, -1.7761e-04],\n",
      "        [-7.8556e-05, -9.8275e+00, -1.0613e+01],\n",
      "        [-9.9601e+00, -5.9960e-05, -1.1270e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2516e-04, -9.3994e+00, -1.0066e+01],\n",
      "        [-8.5850e+00, -2.6103e-04, -9.5100e+00],\n",
      "        [-8.7781e+00, -1.0724e+01, -1.7606e-04],\n",
      "        [-7.5457e-05, -1.0147e+01, -1.0227e+01],\n",
      "        [-9.8563e+00, -6.1987e-05, -1.1557e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6095e+00, -2.5782e-04, -9.4930e+00],\n",
      "        [-8.7547e+00, -1.0887e+01, -1.7641e-04],\n",
      "        [-7.8079e-05, -9.8337e+00, -1.0618e+01],\n",
      "        [-9.9694e+00, -5.9484e-05, -1.1279e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2457e-04, -9.4048e+00, -1.0073e+01],\n",
      "        [-8.5926e+00, -2.5913e-04, -9.5166e+00],\n",
      "        [-8.7850e+00, -1.0730e+01, -1.7486e-04],\n",
      "        [-7.4980e-05, -1.0153e+01, -1.0233e+01],\n",
      "        [-9.8664e+00, -6.1391e-05, -1.1566e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6171e+00, -2.5591e-04, -9.4996e+00],\n",
      "        [-8.7618e+00, -1.0893e+01, -1.7522e-04],\n",
      "        [-7.7602e-05, -9.8399e+00, -1.0624e+01],\n",
      "        [-9.9787e+00, -5.8888e-05, -1.1287e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2385e-04, -9.4102e+00, -1.0079e+01],\n",
      "        [-8.6001e+00, -2.5734e-04, -9.5232e+00],\n",
      "        [-8.7918e+00, -1.0736e+01, -1.7379e-04],\n",
      "        [-7.4503e-05, -1.0159e+01, -1.0240e+01],\n",
      "        [-9.8765e+00, -6.0795e-05, -1.1574e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6247e+00, -2.5400e-04, -9.5063e+00],\n",
      "        [-8.7688e+00, -1.0898e+01, -1.7403e-04],\n",
      "        [-7.7125e-05, -9.8462e+00, -1.0630e+01],\n",
      "        [-9.9880e+00, -5.8292e-05, -1.1295e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2314e-04, -9.4156e+00, -1.0085e+01],\n",
      "        [-8.6077e+00, -2.5543e-04, -9.5298e+00],\n",
      "        [-8.7986e+00, -1.0742e+01, -1.7260e-04],\n",
      "        [-7.4026e-05, -1.0165e+01, -1.0247e+01],\n",
      "        [-9.8865e+00, -6.0199e-05, -1.1583e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6323e+00, -2.5222e-04, -9.5129e+00],\n",
      "        [-8.7758e+00, -1.0903e+01, -1.7284e-04],\n",
      "        [-7.6649e-05, -9.8524e+00, -1.0635e+01],\n",
      "        [-9.9972e+00, -5.7815e-05, -1.1304e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2254e-04, -9.4210e+00, -1.0091e+01],\n",
      "        [-8.6152e+00, -2.5365e-04, -9.5364e+00],\n",
      "        [-8.8054e+00, -1.0749e+01, -1.7141e-04],\n",
      "        [-7.3549e-05, -1.0171e+01, -1.0253e+01],\n",
      "        [-9.8964e+00, -5.9603e-05, -1.1591e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6399e+00, -2.5031e-04, -9.5195e+00],\n",
      "        [-8.7828e+00, -1.0908e+01, -1.7165e-04],\n",
      "        [-7.6291e-05, -9.8586e+00, -1.0641e+01],\n",
      "        [-1.0006e+01, -5.7338e-05, -1.1312e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2171e-04, -9.4264e+00, -1.0098e+01],\n",
      "        [-8.6226e+00, -2.5174e-04, -9.5429e+00],\n",
      "        [-8.8122e+00, -1.0755e+01, -1.7022e-04],\n",
      "        [-7.3073e-05, -1.0177e+01, -1.0260e+01],\n",
      "        [-9.9063e+00, -5.9007e-05, -1.1599e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6474e+00, -2.4852e-04, -9.5261e+00],\n",
      "        [-8.7898e+00, -1.0913e+01, -1.7057e-04],\n",
      "        [-7.5814e-05, -9.8648e+00, -1.0646e+01],\n",
      "        [-1.0015e+01, -5.6861e-05, -1.1321e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2099e-04, -9.4318e+00, -1.0104e+01],\n",
      "        [-8.6301e+00, -2.4995e-04, -9.5494e+00],\n",
      "        [-8.8189e+00, -1.0761e+01, -1.6914e-04],\n",
      "        [-7.2596e-05, -1.0183e+01, -1.0266e+01],\n",
      "        [-9.9162e+00, -5.8411e-05, -1.1608e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6549e+00, -2.4673e-04, -9.5327e+00],\n",
      "        [-8.7967e+00, -1.0918e+01, -1.6938e-04],\n",
      "        [-7.5218e-05, -9.8710e+00, -1.0652e+01],\n",
      "        [-1.0025e+01, -5.6384e-05, -1.1329e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.2039e-04, -9.4371e+00, -1.0110e+01],\n",
      "        [-8.6375e+00, -2.4816e-04, -9.5559e+00],\n",
      "        [-8.8257e+00, -1.0767e+01, -1.6795e-04],\n",
      "        [-7.2119e-05, -1.0189e+01, -1.0273e+01],\n",
      "        [-9.9260e+00, -5.7934e-05, -1.1616e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6624e+00, -2.4495e-04, -9.5392e+00],\n",
      "        [-8.8037e+00, -1.0923e+01, -1.6819e-04],\n",
      "        [-7.4861e-05, -9.8772e+00, -1.0657e+01],\n",
      "        [-1.0034e+01, -5.5788e-05, -1.1337e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1968e-04, -9.4425e+00, -1.0116e+01],\n",
      "        [-8.6449e+00, -2.4638e-04, -9.5624e+00],\n",
      "        [-8.8324e+00, -1.0774e+01, -1.6688e-04],\n",
      "        [-7.1761e-05, -1.0195e+01, -1.0279e+01],\n",
      "        [-9.9358e+00, -5.7338e-05, -1.1624e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6698e+00, -2.4328e-04, -9.5457e+00],\n",
      "        [-8.8106e+00, -1.0928e+01, -1.6712e-04],\n",
      "        [-7.4384e-05, -9.8834e+00, -1.0663e+01],\n",
      "        [-1.0043e+01, -5.5312e-05, -1.1345e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1908e-04, -9.4478e+00, -1.0122e+01],\n",
      "        [-8.6522e+00, -2.4459e-04, -9.5688e+00],\n",
      "        [-8.8391e+00, -1.0780e+01, -1.6581e-04],\n",
      "        [-7.1285e-05, -1.0200e+01, -1.0285e+01],\n",
      "        [-9.9456e+00, -5.6742e-05, -1.1632e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6772e+00, -2.4149e-04, -9.5522e+00],\n",
      "        [-8.8175e+00, -1.0933e+01, -1.6604e-04],\n",
      "        [-7.3907e-05, -9.8896e+00, -1.0668e+01],\n",
      "        [-1.0052e+01, -5.4835e-05, -1.1354e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1837e-04, -9.4531e+00, -1.0129e+01],\n",
      "        [-8.6596e+00, -2.4292e-04, -9.5752e+00],\n",
      "        [-8.8458e+00, -1.0786e+01, -1.6473e-04],\n",
      "        [-7.0808e-05, -1.0206e+01, -1.0292e+01],\n",
      "        [-9.9553e+00, -5.6265e-05, -1.1640e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6846e+00, -2.3970e-04, -9.5587e+00],\n",
      "        [-8.8244e+00, -1.0938e+01, -1.6485e-04],\n",
      "        [-7.3549e-05, -9.8958e+00, -1.0674e+01],\n",
      "        [-1.0060e+01, -5.4477e-05, -1.1362e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1777e-04, -9.4585e+00, -1.0135e+01],\n",
      "        [-8.6669e+00, -2.4125e-04, -9.5816e+00],\n",
      "        [-8.8525e+00, -1.0792e+01, -1.6354e-04],\n",
      "        [-7.0450e-05, -1.0212e+01, -1.0298e+01],\n",
      "        [-9.9649e+00, -5.5669e-05, -1.1649e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6919e+00, -2.3803e-04, -9.5651e+00],\n",
      "        [-8.8313e+00, -1.0943e+01, -1.6378e-04],\n",
      "        [-7.3073e-05, -9.9020e+00, -1.0679e+01],\n",
      "        [-1.0069e+01, -5.3881e-05, -1.1370e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1706e-04, -9.4638e+00, -1.0141e+01],\n",
      "        [-8.6741e+00, -2.3946e-04, -9.5880e+00],\n",
      "        [-8.8592e+00, -1.0798e+01, -1.6247e-04],\n",
      "        [-6.9973e-05, -1.0218e+01, -1.0305e+01],\n",
      "        [-9.9745e+00, -5.5312e-05, -1.1657e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6992e+00, -2.3648e-04, -9.5715e+00],\n",
      "        [-8.8381e+00, -1.0948e+01, -1.6271e-04],\n",
      "        [-7.2715e-05, -9.9082e+00, -1.0685e+01],\n",
      "        [-1.0078e+01, -5.3404e-05, -1.1378e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1646e-04, -9.4691e+00, -1.0147e+01],\n",
      "        [-8.6814e+00, -2.3779e-04, -9.5944e+00],\n",
      "        [-8.8658e+00, -1.0804e+01, -1.6152e-04],\n",
      "        [-6.9497e-05, -1.0224e+01, -1.0311e+01],\n",
      "        [-9.9841e+00, -5.4716e-05, -1.1665e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7065e+00, -2.3481e-04, -9.5779e+00],\n",
      "        [-8.8450e+00, -1.0953e+01, -1.6163e-04],\n",
      "        [-7.2238e-05, -9.9143e+00, -1.0690e+01],\n",
      "        [-1.0087e+01, -5.2928e-05, -1.1386e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1575e-04, -9.4744e+00, -1.0153e+01],\n",
      "        [-8.6886e+00, -2.3624e-04, -9.6007e+00],\n",
      "        [-8.8725e+00, -1.0810e+01, -1.6044e-04],\n",
      "        [-6.9139e-05, -1.0230e+01, -1.0318e+01],\n",
      "        [-9.9936e+00, -5.4120e-05, -1.1673e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7138e+00, -2.3315e-04, -9.5843e+00],\n",
      "        [-8.8518e+00, -1.0957e+01, -1.6056e-04],\n",
      "        [-7.1761e-05, -9.9205e+00, -1.0696e+01],\n",
      "        [-1.0096e+01, -5.2451e-05, -1.1394e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1515e-04, -9.4796e+00, -1.0159e+01],\n",
      "        [-8.6958e+00, -2.3458e-04, -9.6070e+00],\n",
      "        [-8.8791e+00, -1.0816e+01, -1.5937e-04],\n",
      "        [-6.8781e-05, -1.0236e+01, -1.0324e+01],\n",
      "        [-1.0003e+01, -5.3762e-05, -1.1681e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7210e+00, -2.3160e-04, -9.5907e+00],\n",
      "        [-8.8586e+00, -1.0962e+01, -1.5949e-04],\n",
      "        [-7.1404e-05, -9.9266e+00, -1.0701e+01],\n",
      "        [-1.0104e+01, -5.2093e-05, -1.1402e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1455e-04, -9.4849e+00, -1.0165e+01],\n",
      "        [-8.7029e+00, -2.3303e-04, -9.6133e+00],\n",
      "        [-8.8857e+00, -1.0822e+01, -1.5830e-04],\n",
      "        [-6.8305e-05, -1.0242e+01, -1.0330e+01],\n",
      "        [-1.0013e+01, -5.3166e-05, -1.1689e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7282e+00, -2.2993e-04, -9.5970e+00],\n",
      "        [-8.8654e+00, -1.0967e+01, -1.5842e-04],\n",
      "        [-7.0927e-05, -9.9328e+00, -1.0706e+01],\n",
      "        [-1.0113e+01, -5.1616e-05, -1.1410e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1384e-04, -9.4902e+00, -1.0171e+01],\n",
      "        [-8.7100e+00, -2.3136e-04, -9.6196e+00],\n",
      "        [-8.8923e+00, -1.0829e+01, -1.5734e-04],\n",
      "        [-6.7828e-05, -1.0247e+01, -1.0337e+01],\n",
      "        [-1.0022e+01, -5.2808e-05, -1.1697e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7354e+00, -2.2826e-04, -9.6033e+00],\n",
      "        [-8.8722e+00, -1.0972e+01, -1.5746e-04],\n",
      "        [-7.0569e-05, -9.9389e+00, -1.0712e+01],\n",
      "        [-1.0122e+01, -5.1139e-05, -1.1418e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1324e-04, -9.4954e+00, -1.0178e+01],\n",
      "        [-8.7171e+00, -2.2981e-04, -9.6259e+00],\n",
      "        [-8.8988e+00, -1.0835e+01, -1.5627e-04],\n",
      "        [-6.7470e-05, -1.0253e+01, -1.0343e+01],\n",
      "        [-1.0031e+01, -5.2212e-05, -1.1705e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7425e+00, -2.2683e-04, -9.6096e+00],\n",
      "        [-8.8790e+00, -1.0977e+01, -1.5639e-04],\n",
      "        [-7.0093e-05, -9.9450e+00, -1.0717e+01],\n",
      "        [-1.0130e+01, -5.0782e-05, -1.1426e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1265e-04, -9.5007e+00, -1.0184e+01],\n",
      "        [-8.7242e+00, -2.2814e-04, -9.6321e+00],\n",
      "        [-8.9054e+00, -1.0841e+01, -1.5520e-04],\n",
      "        [-6.7113e-05, -1.0259e+01, -1.0349e+01],\n",
      "        [-1.0041e+01, -5.1855e-05, -1.1712e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7496e+00, -2.2516e-04, -9.6159e+00],\n",
      "        [-8.8857e+00, -1.0982e+01, -1.5532e-04],\n",
      "        [-6.9735e-05, -9.9512e+00, -1.0722e+01],\n",
      "        [-1.0139e+01, -5.0305e-05, -1.1434e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1193e-04, -9.5059e+00, -1.0190e+01],\n",
      "        [-8.7313e+00, -2.2671e-04, -9.6383e+00],\n",
      "        [-8.9119e+00, -1.0847e+01, -1.5424e-04],\n",
      "        [-6.6636e-05, -1.0265e+01, -1.0355e+01],\n",
      "        [-1.0050e+01, -5.1259e-05, -1.1720e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7567e+00, -2.2373e-04, -9.6221e+00],\n",
      "        [-8.8924e+00, -1.0987e+01, -1.5436e-04],\n",
      "        [-6.9258e-05, -9.9573e+00, -1.0728e+01],\n",
      "        [-1.0147e+01, -4.9947e-05, -1.1442e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1134e-04, -9.5111e+00, -1.0196e+01],\n",
      "        [-8.7383e+00, -2.2516e-04, -9.6445e+00],\n",
      "        [-8.9185e+00, -1.0853e+01, -1.5329e-04],\n",
      "        [-6.6278e-05, -1.0271e+01, -1.0362e+01],\n",
      "        [-1.0059e+01, -5.0901e-05, -1.1728e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7637e+00, -2.2206e-04, -9.6284e+00],\n",
      "        [-8.8991e+00, -1.0992e+01, -1.5341e-04],\n",
      "        [-6.8901e-05, -9.9634e+00, -1.0733e+01],\n",
      "        [-1.0156e+01, -4.9471e-05, -1.1449e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1074e-04, -9.5163e+00, -1.0202e+01],\n",
      "        [-8.7453e+00, -2.2361e-04, -9.6507e+00],\n",
      "        [-8.9250e+00, -1.0858e+01, -1.5222e-04],\n",
      "        [-6.5921e-05, -1.0276e+01, -1.0368e+01],\n",
      "        [-1.0068e+01, -5.0424e-05, -1.1736e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7708e+00, -2.2063e-04, -9.6346e+00],\n",
      "        [-8.9058e+00, -1.0997e+01, -1.5234e-04],\n",
      "        [-6.8543e-05, -9.9695e+00, -1.0738e+01],\n",
      "        [-1.0164e+01, -4.9113e-05, -1.1457e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.1014e-04, -9.5215e+00, -1.0208e+01],\n",
      "        [-8.7522e+00, -2.2218e-04, -9.6569e+00],\n",
      "        [-8.9315e+00, -1.0864e+01, -1.5127e-04],\n",
      "        [-6.5444e-05, -1.0282e+01, -1.0374e+01],\n",
      "        [-1.0078e+01, -4.9947e-05, -1.1744e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7778e+00, -2.1920e-04, -9.6408e+00],\n",
      "        [-8.9125e+00, -1.1001e+01, -1.5138e-04],\n",
      "        [-6.8066e-05, -9.9755e+00, -1.0744e+01],\n",
      "        [-1.0173e+01, -4.8636e-05, -1.1465e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0955e-04, -9.5267e+00, -1.0214e+01],\n",
      "        [-8.7592e+00, -2.2063e-04, -9.6630e+00],\n",
      "        [-8.9379e+00, -1.0870e+01, -1.5031e-04],\n",
      "        [-6.5086e-05, -1.0288e+01, -1.0380e+01],\n",
      "        [-1.0087e+01, -4.9471e-05, -1.1751e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7847e+00, -2.1765e-04, -9.6469e+00],\n",
      "        [-8.9192e+00, -1.1006e+01, -1.5043e-04],\n",
      "        [-6.7709e-05, -9.9816e+00, -1.0749e+01],\n",
      "        [-1.0181e+01, -4.8279e-05, -1.1473e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0895e-04, -9.5319e+00, -1.0220e+01],\n",
      "        [-8.7661e+00, -2.1908e-04, -9.6691e+00],\n",
      "        [-8.9444e+00, -1.0876e+01, -1.4936e-04],\n",
      "        [-6.4729e-05, -1.0294e+01, -1.0387e+01],\n",
      "        [-1.0096e+01, -4.9113e-05, -1.1759e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7917e+00, -2.1622e-04, -9.6531e+00],\n",
      "        [-8.9258e+00, -1.1011e+01, -1.4948e-04],\n",
      "        [-6.7351e-05, -9.9877e+00, -1.0754e+01],\n",
      "        [-1.0190e+01, -4.7921e-05, -1.1480e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0836e-04, -9.5370e+00, -1.0226e+01],\n",
      "        [-8.7729e+00, -2.1765e-04, -9.6752e+00],\n",
      "        [-8.9509e+00, -1.0882e+01, -1.4840e-04],\n",
      "        [-6.4252e-05, -1.0299e+01, -1.0393e+01],\n",
      "        [-1.0105e+01, -4.8636e-05, -1.1767e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_scores\n",
      "tensor([[-8.7986e+00, -2.1479e-04, -9.6592e+00],\n",
      "        [-8.9324e+00, -1.1016e+01, -1.4852e-04],\n",
      "        [-6.6874e-05, -9.9937e+00, -1.0759e+01],\n",
      "        [-1.0198e+01, -4.7444e-05, -1.1488e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0776e-04, -9.5422e+00, -1.0231e+01],\n",
      "        [-8.7798e+00, -2.1634e-04, -9.6813e+00],\n",
      "        [-8.9573e+00, -1.0888e+01, -1.4745e-04],\n",
      "        [-6.4013e-05, -1.0305e+01, -1.0399e+01],\n",
      "        [-1.0114e+01, -4.8279e-05, -1.1774e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8055e+00, -2.1336e-04, -9.6653e+00],\n",
      "        [-8.9391e+00, -1.1021e+01, -1.4757e-04],\n",
      "        [-6.6517e-05, -9.9998e+00, -1.0765e+01],\n",
      "        [-1.0206e+01, -4.7087e-05, -1.1496e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0716e-04, -9.5473e+00, -1.0237e+01],\n",
      "        [-8.7866e+00, -2.1491e-04, -9.6874e+00],\n",
      "        [-8.9637e+00, -1.0894e+01, -1.4650e-04],\n",
      "        [-6.3537e-05, -1.0311e+01, -1.0405e+01],\n",
      "        [-1.0123e+01, -4.7802e-05, -1.1782e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8123e+00, -2.1193e-04, -9.6714e+00],\n",
      "        [-8.9456e+00, -1.1025e+01, -1.4662e-04],\n",
      "        [-6.6159e-05, -1.0006e+01, -1.0770e+01],\n",
      "        [-1.0214e+01, -4.6729e-05, -1.1503e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0669e-04, -9.5525e+00, -1.0243e+01],\n",
      "        [-8.7934e+00, -2.1348e-04, -9.6934e+00],\n",
      "        [-8.9701e+00, -1.0900e+01, -1.4566e-04],\n",
      "        [-6.3179e-05, -1.0316e+01, -1.0411e+01],\n",
      "        [-1.0132e+01, -4.7444e-05, -1.1789e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8192e+00, -2.1062e-04, -9.6775e+00],\n",
      "        [-8.9522e+00, -1.1030e+01, -1.4566e-04],\n",
      "        [-6.5682e-05, -1.0012e+01, -1.0775e+01],\n",
      "        [-1.0223e+01, -4.6371e-05, -1.1511e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0609e-04, -9.5576e+00, -1.0249e+01],\n",
      "        [-8.8002e+00, -2.1193e-04, -9.6994e+00],\n",
      "        [-8.9765e+00, -1.0905e+01, -1.4471e-04],\n",
      "        [-6.2821e-05, -1.0322e+01, -1.0417e+01],\n",
      "        [-1.0141e+01, -4.6967e-05, -1.1797e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8260e+00, -2.0919e-04, -9.6835e+00],\n",
      "        [-8.9588e+00, -1.1035e+01, -1.4471e-04],\n",
      "        [-6.5444e-05, -1.0018e+01, -1.0780e+01],\n",
      "        [-1.0231e+01, -4.5895e-05, -1.1518e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0549e-04, -9.5627e+00, -1.0255e+01],\n",
      "        [-8.8070e+00, -2.1062e-04, -9.7054e+00],\n",
      "        [-8.9828e+00, -1.0911e+01, -1.4376e-04],\n",
      "        [-6.2345e-05, -1.0328e+01, -1.0423e+01],\n",
      "        [-1.0150e+01, -4.6610e-05, -1.1804e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8328e+00, -2.0788e-04, -9.6895e+00],\n",
      "        [-8.9653e+00, -1.1040e+01, -1.4388e-04],\n",
      "        [-6.5086e-05, -1.0024e+01, -1.0785e+01],\n",
      "        [-1.0239e+01, -4.5656e-05, -1.1526e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0490e-04, -9.5678e+00, -1.0261e+01],\n",
      "        [-8.8137e+00, -2.0931e-04, -9.7114e+00],\n",
      "        [-8.9892e+00, -1.0917e+01, -1.4292e-04],\n",
      "        [-6.2106e-05, -1.0333e+01, -1.0429e+01],\n",
      "        [-1.0158e+01, -4.6133e-05, -1.1812e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8395e+00, -2.0645e-04, -9.6956e+00],\n",
      "        [-8.9719e+00, -1.1044e+01, -1.4292e-04],\n",
      "        [-6.4729e-05, -1.0030e+01, -1.0791e+01],\n",
      "        [-1.0247e+01, -4.5299e-05, -1.1533e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0442e-04, -9.5729e+00, -1.0267e+01],\n",
      "        [-8.8204e+00, -2.0788e-04, -9.7174e+00],\n",
      "        [-8.9955e+00, -1.0923e+01, -1.4197e-04],\n",
      "        [-6.1629e-05, -1.0339e+01, -1.0435e+01],\n",
      "        [-1.0167e+01, -4.5775e-05, -1.1819e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8463e+00, -2.0514e-04, -9.7015e+00],\n",
      "        [-8.9784e+00, -1.1049e+01, -1.4197e-04],\n",
      "        [-6.4252e-05, -1.0036e+01, -1.0796e+01],\n",
      "        [-1.0255e+01, -4.4941e-05, -1.1541e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0383e-04, -9.5780e+00, -1.0273e+01],\n",
      "        [-8.8271e+00, -2.0657e-04, -9.7233e+00],\n",
      "        [-9.0018e+00, -1.0929e+01, -1.4113e-04],\n",
      "        [-6.1391e-05, -1.0345e+01, -1.0441e+01],\n",
      "        [-1.0176e+01, -4.5299e-05, -1.1827e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8530e+00, -2.0371e-04, -9.7075e+00],\n",
      "        [-8.9848e+00, -1.1054e+01, -1.4113e-04],\n",
      "        [-6.3894e-05, -1.0042e+01, -1.0801e+01],\n",
      "        [-1.0263e+01, -4.4583e-05, -1.1548e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0323e-04, -9.5831e+00, -1.0278e+01],\n",
      "        [-8.8337e+00, -2.0526e-04, -9.7292e+00],\n",
      "        [-9.0081e+00, -1.0934e+01, -1.4030e-04],\n",
      "        [-6.0914e-05, -1.0350e+01, -1.0448e+01],\n",
      "        [-1.0185e+01, -4.5060e-05, -1.1834e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8597e+00, -2.0240e-04, -9.7134e+00],\n",
      "        [-8.9913e+00, -1.1058e+01, -1.4030e-04],\n",
      "        [-6.3537e-05, -1.0048e+01, -1.0806e+01],\n",
      "        [-1.0271e+01, -4.4106e-05, -1.1556e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0275e-04, -9.5881e+00, -1.0284e+01],\n",
      "        [-8.8404e+00, -2.0395e-04, -9.7352e+00],\n",
      "        [-9.0144e+00, -1.0940e+01, -1.3935e-04],\n",
      "        [-6.0676e-05, -1.0356e+01, -1.0454e+01],\n",
      "        [-1.0193e+01, -4.4583e-05, -1.1842e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8663e+00, -2.0121e-04, -9.7194e+00],\n",
      "        [-8.9978e+00, -1.1063e+01, -1.3935e-04],\n",
      "        [-6.3179e-05, -1.0054e+01, -1.0811e+01],\n",
      "        [-1.0279e+01, -4.3868e-05, -1.1563e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0216e-04, -9.5932e+00, -1.0290e+01],\n",
      "        [-8.8470e+00, -2.0275e-04, -9.7410e+00],\n",
      "        [-9.0207e+00, -1.0946e+01, -1.3851e-04],\n",
      "        [-6.0318e-05, -1.0362e+01, -1.0460e+01],\n",
      "        [-1.0202e+01, -4.4226e-05, -1.1849e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8730e+00, -1.9989e-04, -9.7253e+00],\n",
      "        [-9.0042e+00, -1.1068e+01, -1.3851e-04],\n",
      "        [-6.2821e-05, -1.0060e+01, -1.0816e+01],\n",
      "        [-1.0287e+01, -4.3510e-05, -1.1570e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0156e-04, -9.5982e+00, -1.0296e+01],\n",
      "        [-8.8535e+00, -2.0144e-04, -9.7469e+00],\n",
      "        [-9.0269e+00, -1.0951e+01, -1.3768e-04],\n",
      "        [-5.9960e-05, -1.0367e+01, -1.0466e+01],\n",
      "        [-1.0211e+01, -4.3987e-05, -1.1856e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8796e+00, -1.9858e-04, -9.7312e+00],\n",
      "        [-9.0106e+00, -1.1072e+01, -1.3768e-04],\n",
      "        [-6.2583e-05, -1.0066e+01, -1.0821e+01],\n",
      "        [-1.0295e+01, -4.3272e-05, -1.1578e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0108e-04, -9.6032e+00, -1.0301e+01],\n",
      "        [-8.8601e+00, -2.0013e-04, -9.7528e+00],\n",
      "        [-9.0332e+00, -1.0957e+01, -1.3684e-04],\n",
      "        [-5.9603e-05, -1.0373e+01, -1.0471e+01],\n",
      "        [-1.0219e+01, -4.3510e-05, -1.1863e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8861e+00, -1.9727e-04, -9.7370e+00],\n",
      "        [-9.0171e+00, -1.1077e+01, -1.3684e-04],\n",
      "        [-6.2225e-05, -1.0072e+01, -1.0826e+01],\n",
      "        [-1.0303e+01, -4.2795e-05, -1.1585e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0061e-04, -9.6083e+00, -1.0307e+01],\n",
      "        [-8.8666e+00, -1.9882e-04, -9.7586e+00],\n",
      "        [-9.0394e+00, -1.0963e+01, -1.3601e-04],\n",
      "        [-5.9245e-05, -1.0378e+01, -1.0477e+01],\n",
      "        [-1.0228e+01, -4.3153e-05, -1.1871e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8927e+00, -1.9620e-04, -9.7429e+00],\n",
      "        [-9.0234e+00, -1.1082e+01, -1.3601e-04],\n",
      "        [-6.1749e-05, -1.0077e+01, -1.0831e+01],\n",
      "        [-1.0311e+01, -4.2438e-05, -1.1592e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-1.0013e-04, -9.6133e+00, -1.0313e+01],\n",
      "        [-8.8732e+00, -1.9751e-04, -9.7644e+00],\n",
      "        [-9.0456e+00, -1.0968e+01, -1.3517e-04],\n",
      "        [-5.8888e-05, -1.0384e+01, -1.0483e+01],\n",
      "        [-1.0236e+01, -4.2795e-05, -1.1878e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8992e+00, -1.9489e-04, -9.7487e+00],\n",
      "        [-9.0298e+00, -1.1086e+01, -1.3517e-04],\n",
      "        [-6.1391e-05, -1.0083e+01, -1.0836e+01],\n",
      "        [-1.0318e+01, -4.2199e-05, -1.1600e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.9535e-05, -9.6183e+00, -1.0319e+01],\n",
      "        [-8.8796e+00, -1.9632e-04, -9.7702e+00],\n",
      "        [-9.0518e+00, -1.0974e+01, -1.3434e-04],\n",
      "        [-5.8530e-05, -1.0389e+01, -1.0489e+01],\n",
      "        [-1.0245e+01, -4.2438e-05, -1.1885e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9058e+00, -1.9370e-04, -9.7545e+00],\n",
      "        [-9.0362e+00, -1.1091e+01, -1.3434e-04],\n",
      "        [-6.1033e-05, -1.0089e+01, -1.0841e+01],\n",
      "        [-1.0326e+01, -4.1842e-05, -1.1607e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.8939e-05, -9.6233e+00, -1.0324e+01],\n",
      "        [-8.8861e+00, -1.9513e-04, -9.7760e+00],\n",
      "        [-9.0580e+00, -1.0980e+01, -1.3351e-04],\n",
      "        [-5.8292e-05, -1.0395e+01, -1.0495e+01],\n",
      "        [-1.0253e+01, -4.2080e-05, -1.1892e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9122e+00, -1.9239e-04, -9.7603e+00],\n",
      "        [-9.0425e+00, -1.1095e+01, -1.3351e-04],\n",
      "        [-6.0676e-05, -1.0095e+01, -1.0846e+01],\n",
      "        [-1.0334e+01, -4.1603e-05, -1.1614e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.8462e-05, -9.6282e+00, -1.0330e+01],\n",
      "        [-8.8925e+00, -1.9393e-04, -9.7818e+00],\n",
      "        [-9.0641e+00, -1.0985e+01, -1.3267e-04],\n",
      "        [-5.7934e-05, -1.0400e+01, -1.0501e+01],\n",
      "        [-1.0262e+01, -4.1722e-05, -1.1899e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9187e+00, -1.9119e-04, -9.7661e+00],\n",
      "        [-9.0488e+00, -1.1100e+01, -1.3267e-04],\n",
      "        [-6.0437e-05, -1.0101e+01, -1.0851e+01],\n",
      "        [-1.0342e+01, -4.1246e-05, -1.1621e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.7985e-05, -9.6332e+00, -1.0336e+01],\n",
      "        [-8.8990e+00, -1.9274e-04, -9.7875e+00],\n",
      "        [-9.0703e+00, -1.0991e+01, -1.3196e-04],\n",
      "        [-5.7576e-05, -1.0406e+01, -1.0507e+01],\n",
      "        [-1.0270e+01, -4.1484e-05, -1.1906e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_scores\n",
      "tensor([[-8.9252e+00, -1.9012e-04, -9.7719e+00],\n",
      "        [-9.0551e+00, -1.1105e+01, -1.3184e-04],\n",
      "        [-6.0080e-05, -1.0107e+01, -1.0856e+01],\n",
      "        [-1.0349e+01, -4.1007e-05, -1.1628e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.7508e-05, -9.6381e+00, -1.0341e+01],\n",
      "        [-8.9054e+00, -1.9143e-04, -9.7932e+00],\n",
      "        [-9.0764e+00, -1.0996e+01, -1.3112e-04],\n",
      "        [-5.7219e-05, -1.0411e+01, -1.0513e+01],\n",
      "        [-1.0278e+01, -4.1007e-05, -1.1914e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9316e+00, -1.8893e-04, -9.7776e+00],\n",
      "        [-9.0614e+00, -1.1109e+01, -1.3100e-04],\n",
      "        [-5.9722e-05, -1.0113e+01, -1.0861e+01],\n",
      "        [-1.0357e+01, -4.0530e-05, -1.1635e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.6912e-05, -9.6431e+00, -1.0347e+01],\n",
      "        [-8.9117e+00, -1.9036e-04, -9.7990e+00],\n",
      "        [-9.0825e+00, -1.1002e+01, -1.3029e-04],\n",
      "        [-5.6980e-05, -1.0417e+01, -1.0519e+01],\n",
      "        [-1.0287e+01, -4.0769e-05, -1.1921e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9380e+00, -1.8774e-04, -9.7833e+00],\n",
      "        [-9.0677e+00, -1.1114e+01, -1.3029e-04],\n",
      "        [-5.9364e-05, -1.0119e+01, -1.0866e+01],\n",
      "        [-1.0365e+01, -4.0292e-05, -1.1643e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.6555e-05, -9.6480e+00, -1.0353e+01],\n",
      "        [-8.9181e+00, -1.8917e-04, -9.8046e+00],\n",
      "        [-9.0886e+00, -1.1007e+01, -1.2957e-04],\n",
      "        [-5.6623e-05, -1.0422e+01, -1.0524e+01],\n",
      "        [-1.0295e+01, -4.0411e-05, -1.1928e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9443e+00, -1.8655e-04, -9.7890e+00],\n",
      "        [-9.0740e+00, -1.1118e+01, -1.2945e-04],\n",
      "        [-5.9007e-05, -1.0124e+01, -1.0871e+01],\n",
      "        [-1.0372e+01, -3.9934e-05, -1.1650e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5959e-05, -9.6529e+00, -1.0358e+01],\n",
      "        [-8.9244e+00, -1.8798e-04, -9.8103e+00],\n",
      "        [-9.0947e+00, -1.1013e+01, -1.2874e-04],\n",
      "        [-5.6265e-05, -1.0428e+01, -1.0530e+01],\n",
      "        [-1.0303e+01, -4.0054e-05, -1.1935e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9507e+00, -1.8547e-04, -9.7947e+00],\n",
      "        [-9.0802e+00, -1.1123e+01, -1.2862e-04],\n",
      "        [-5.8768e-05, -1.0130e+01, -1.0876e+01],\n",
      "        [-1.0380e+01, -3.9696e-05, -1.1657e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5482e-05, -9.6578e+00, -1.0364e+01],\n",
      "        [-8.9307e+00, -1.8690e-04, -9.8160e+00],\n",
      "        [-9.1007e+00, -1.1018e+01, -1.2802e-04],\n",
      "        [-5.6027e-05, -1.0433e+01, -1.0536e+01],\n",
      "        [-1.0311e+01, -3.9815e-05, -1.1942e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9570e+00, -1.8428e-04, -9.8004e+00],\n",
      "        [-9.0864e+00, -1.1127e+01, -1.2790e-04],\n",
      "        [-5.8411e-05, -1.0136e+01, -1.0881e+01],\n",
      "        [-1.0387e+01, -3.9457e-05, -1.1664e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5005e-05, -9.6627e+00, -1.0370e+01],\n",
      "        [-8.9370e+00, -1.8571e-04, -9.8216e+00],\n",
      "        [-9.1068e+00, -1.1024e+01, -1.2719e-04],\n",
      "        [-5.5788e-05, -1.0439e+01, -1.0542e+01],\n",
      "        [-1.0320e+01, -3.9457e-05, -1.1948e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9633e+00, -1.8309e-04, -9.8060e+00],\n",
      "        [-9.0926e+00, -1.1132e+01, -1.2719e-04],\n",
      "        [-5.8172e-05, -1.0142e+01, -1.0886e+01],\n",
      "        [-1.0395e+01, -3.9219e-05, -1.1671e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4528e-05, -9.6676e+00, -1.0375e+01],\n",
      "        [-8.9433e+00, -1.8464e-04, -9.8272e+00],\n",
      "        [-9.1128e+00, -1.1029e+01, -1.2647e-04],\n",
      "        [-5.5312e-05, -1.0444e+01, -1.0548e+01],\n",
      "        [-1.0328e+01, -3.9100e-05, -1.1955e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9696e+00, -1.8202e-04, -9.8117e+00],\n",
      "        [-9.0988e+00, -1.1136e+01, -1.2635e-04],\n",
      "        [-5.7815e-05, -1.0148e+01, -1.0891e+01],\n",
      "        [-1.0402e+01, -3.8861e-05, -1.1678e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3933e-05, -9.6725e+00, -1.0381e+01],\n",
      "        [-8.9495e+00, -1.8345e-04, -9.8329e+00],\n",
      "        [-9.1188e+00, -1.1035e+01, -1.2576e-04],\n",
      "        [-5.5073e-05, -1.0450e+01, -1.0553e+01],\n",
      "        [-1.0336e+01, -3.8861e-05, -1.1962e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9759e+00, -1.8094e-04, -9.8173e+00],\n",
      "        [-9.1050e+00, -1.1141e+01, -1.2564e-04],\n",
      "        [-5.7576e-05, -1.0153e+01, -1.0896e+01],\n",
      "        [-1.0410e+01, -3.8623e-05, -1.1685e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3575e-05, -9.6774e+00, -1.0386e+01],\n",
      "        [-8.9557e+00, -1.8237e-04, -9.8384e+00],\n",
      "        [-9.1248e+00, -1.1040e+01, -1.2492e-04],\n",
      "        [-5.4835e-05, -1.0455e+01, -1.0559e+01],\n",
      "        [-1.0344e+01, -3.8504e-05, -1.1969e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9821e+00, -1.7987e-04, -9.8229e+00],\n",
      "        [-9.1112e+00, -1.1145e+01, -1.2492e-04],\n",
      "        [-5.7219e-05, -1.0159e+01, -1.0901e+01],\n",
      "        [-1.0417e+01, -3.8265e-05, -1.1692e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2979e-05, -9.6822e+00, -1.0392e+01],\n",
      "        [-8.9619e+00, -1.8130e-04, -9.8440e+00],\n",
      "        [-9.1308e+00, -1.1046e+01, -1.2421e-04],\n",
      "        [-5.4477e-05, -1.0460e+01, -1.0565e+01],\n",
      "        [-1.0352e+01, -3.8265e-05, -1.1976e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9883e+00, -1.7880e-04, -9.8285e+00],\n",
      "        [-9.1173e+00, -1.1150e+01, -1.2409e-04],\n",
      "        [-5.6861e-05, -1.0165e+01, -1.0905e+01],\n",
      "        [-1.0425e+01, -3.8027e-05, -1.1698e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2621e-05, -9.6871e+00, -1.0397e+01],\n",
      "        [-8.9681e+00, -1.8023e-04, -9.8496e+00],\n",
      "        [-9.1368e+00, -1.1051e+01, -1.2349e-04],\n",
      "        [-5.4120e-05, -1.0466e+01, -1.0570e+01],\n",
      "        [-1.0360e+01, -3.7908e-05, -1.1983e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9945e+00, -1.7773e-04, -9.8340e+00],\n",
      "        [-9.1234e+00, -1.1154e+01, -1.2337e-04],\n",
      "        [-5.6504e-05, -1.0171e+01, -1.0910e+01],\n",
      "        [-1.0432e+01, -3.7669e-05, -1.1705e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2145e-05, -9.6919e+00, -1.0403e+01],\n",
      "        [-8.9742e+00, -1.7904e-04, -9.8551e+00],\n",
      "        [-9.1427e+00, -1.1056e+01, -1.2278e-04],\n",
      "        [-5.3881e-05, -1.0471e+01, -1.0576e+01],\n",
      "        [-1.0368e+01, -3.7669e-05, -1.1990e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0007e+00, -1.7665e-04, -9.8396e+00],\n",
      "        [-9.1295e+00, -1.1159e+01, -1.2266e-04],\n",
      "        [-5.6265e-05, -1.0176e+01, -1.0915e+01],\n",
      "        [-1.0440e+01, -3.7431e-05, -1.1712e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1668e-05, -9.6967e+00, -1.0408e+01],\n",
      "        [-8.9804e+00, -1.7808e-04, -9.8606e+00],\n",
      "        [-9.1486e+00, -1.1062e+01, -1.2206e-04],\n",
      "        [-5.3643e-05, -1.0476e+01, -1.0582e+01],\n",
      "        [-1.0376e+01, -3.7312e-05, -1.1996e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0068e+00, -1.7558e-04, -9.8451e+00],\n",
      "        [-9.1356e+00, -1.1163e+01, -1.2194e-04],\n",
      "        [-5.5908e-05, -1.0182e+01, -1.0920e+01],\n",
      "        [-1.0447e+01, -3.7193e-05, -1.1719e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1191e-05, -9.7016e+00, -1.0414e+01],\n",
      "        [-8.9865e+00, -1.7689e-04, -9.8661e+00],\n",
      "        [-9.1546e+00, -1.1067e+01, -1.2135e-04],\n",
      "        [-5.3285e-05, -1.0482e+01, -1.0588e+01],\n",
      "        [-1.0384e+01, -3.6954e-05, -1.2003e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0130e+00, -1.7451e-04, -9.8506e+00],\n",
      "        [-9.1417e+00, -1.1168e+01, -1.2123e-04],\n",
      "        [-5.5669e-05, -1.0188e+01, -1.0925e+01],\n",
      "        [-1.0454e+01, -3.6954e-05, -1.1726e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0714e-05, -9.7064e+00, -1.0419e+01],\n",
      "        [-8.9926e+00, -1.7594e-04, -9.8716e+00],\n",
      "        [-9.1605e+00, -1.1072e+01, -1.2063e-04],\n",
      "        [-5.2928e-05, -1.0487e+01, -1.0593e+01],\n",
      "        [-1.0392e+01, -3.6716e-05, -1.2010e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0191e+00, -1.7355e-04, -9.8561e+00],\n",
      "        [-9.1478e+00, -1.1172e+01, -1.2051e-04],\n",
      "        [-5.5312e-05, -1.0193e+01, -1.0930e+01],\n",
      "        [-1.0461e+01, -3.6597e-05, -1.1733e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0237e-05, -9.7112e+00, -1.0425e+01],\n",
      "        [-8.9987e+00, -1.7498e-04, -9.8771e+00],\n",
      "        [-9.1664e+00, -1.1078e+01, -1.1992e-04],\n",
      "        [-5.2689e-05, -1.0492e+01, -1.0599e+01],\n",
      "        [-1.0400e+01, -3.6477e-05, -1.2016e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0252e+00, -1.7248e-04, -9.8616e+00],\n",
      "        [-9.1538e+00, -1.1176e+01, -1.1980e-04],\n",
      "        [-5.5073e-05, -1.0199e+01, -1.0934e+01],\n",
      "        [-1.0469e+01, -3.6358e-05, -1.1739e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9880e-05, -9.7159e+00, -1.0430e+01],\n",
      "        [-9.0047e+00, -1.7391e-04, -9.8826e+00],\n",
      "        [-9.1722e+00, -1.1083e+01, -1.1932e-04],\n",
      "        [-5.2451e-05, -1.0498e+01, -1.0604e+01],\n",
      "        [-1.0408e+01, -3.6120e-05, -1.2023e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0312e+00, -1.7153e-04, -9.8670e+00],\n",
      "        [-9.1598e+00, -1.1181e+01, -1.1908e-04],\n",
      "        [-5.4716e-05, -1.0205e+01, -1.0939e+01],\n",
      "        [-1.0476e+01, -3.6120e-05, -1.1746e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.9403e-05, -9.7207e+00, -1.0436e+01],\n",
      "        [-9.0107e+00, -1.7284e-04, -9.8880e+00],\n",
      "        [-9.1781e+00, -1.1088e+01, -1.1861e-04],\n",
      "        [-5.2093e-05, -1.0503e+01, -1.0610e+01],\n",
      "        [-1.0415e+01, -3.5881e-05, -1.2030e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0373e+00, -1.7057e-04, -9.8725e+00],\n",
      "        [-9.1658e+00, -1.1185e+01, -1.1849e-04],\n",
      "        [-5.4477e-05, -1.0210e+01, -1.0944e+01],\n",
      "        [-1.0483e+01, -3.5881e-05, -1.1753e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8926e-05, -9.7255e+00, -1.0441e+01],\n",
      "        [-9.0168e+00, -1.7189e-04, -9.8934e+00],\n",
      "        [-9.1839e+00, -1.1093e+01, -1.1789e-04],\n",
      "        [-5.1855e-05, -1.0508e+01, -1.0616e+01],\n",
      "        [-1.0423e+01, -3.5643e-05, -1.2036e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0433e+00, -1.6950e-04, -9.8779e+00],\n",
      "        [-9.1718e+00, -1.1190e+01, -1.1777e-04],\n",
      "        [-5.4120e-05, -1.0216e+01, -1.0949e+01],\n",
      "        [-1.0490e+01, -3.5643e-05, -1.1760e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.8569e-05, -9.7302e+00, -1.0446e+01],\n",
      "        [-9.0227e+00, -1.7081e-04, -9.8988e+00],\n",
      "        [-9.1898e+00, -1.1099e+01, -1.1718e-04],\n",
      "        [-5.1616e-05, -1.0514e+01, -1.0621e+01],\n",
      "        [-1.0431e+01, -3.5405e-05, -1.2043e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0493e+00, -1.6855e-04, -9.8833e+00],\n",
      "        [-9.1778e+00, -1.1194e+01, -1.1706e-04],\n",
      "        [-5.3881e-05, -1.0222e+01, -1.0953e+01],\n",
      "        [-1.0497e+01, -3.5405e-05, -1.1766e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7973e-05, -9.7350e+00, -1.0452e+01],\n",
      "        [-9.0287e+00, -1.6986e-04, -9.9042e+00],\n",
      "        [-9.1956e+00, -1.1104e+01, -1.1658e-04],\n",
      "        [-5.1378e-05, -1.0519e+01, -1.0627e+01],\n",
      "        [-1.0439e+01, -3.5166e-05, -1.2049e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0553e+00, -1.6759e-04, -9.8887e+00],\n",
      "        [-9.1838e+00, -1.1198e+01, -1.1634e-04],\n",
      "        [-5.3524e-05, -1.0227e+01, -1.0958e+01],\n",
      "        [-1.0504e+01, -3.5166e-05, -1.1773e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7615e-05, -9.7397e+00, -1.0457e+01],\n",
      "        [-9.0347e+00, -1.6891e-04, -9.9096e+00],\n",
      "        [-9.2014e+00, -1.1109e+01, -1.1586e-04],\n",
      "        [-5.1020e-05, -1.0524e+01, -1.0632e+01],\n",
      "        [-1.0446e+01, -3.4928e-05, -1.2056e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0613e+00, -1.6652e-04, -9.8941e+00],\n",
      "        [-9.1897e+00, -1.1203e+01, -1.1575e-04],\n",
      "        [-5.3285e-05, -1.0233e+01, -1.0963e+01],\n",
      "        [-1.0512e+01, -3.4809e-05, -1.1779e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.7257e-05, -9.7444e+00, -1.0462e+01],\n",
      "        [-9.0406e+00, -1.6795e-04, -9.9150e+00],\n",
      "        [-9.2072e+00, -1.1114e+01, -1.1527e-04],\n",
      "        [-5.0663e-05, -1.0529e+01, -1.0638e+01],\n",
      "        [-1.0454e+01, -3.4570e-05, -1.2062e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0672e+00, -1.6557e-04, -9.8995e+00],\n",
      "        [-9.1957e+00, -1.1207e+01, -1.1503e-04],\n",
      "        [-5.3047e-05, -1.0239e+01, -1.0968e+01],\n",
      "        [-1.0519e+01, -3.4689e-05, -1.1786e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6781e-05, -9.7491e+00, -1.0468e+01],\n",
      "        [-9.0465e+00, -1.6688e-04, -9.9203e+00],\n",
      "        [-9.2129e+00, -1.1120e+01, -1.1455e-04],\n",
      "        [-5.0424e-05, -1.0535e+01, -1.0643e+01],\n",
      "        [-1.0462e+01, -3.4332e-05, -1.2069e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0732e+00, -1.6461e-04, -9.9048e+00],\n",
      "        [-9.2016e+00, -1.1211e+01, -1.1443e-04],\n",
      "        [-5.2689e-05, -1.0244e+01, -1.0972e+01],\n",
      "        [-1.0526e+01, -3.4332e-05, -1.1793e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.6304e-05, -9.7538e+00, -1.0473e+01],\n",
      "        [-9.0524e+00, -1.6604e-04, -9.9257e+00],\n",
      "        [-9.2187e+00, -1.1125e+01, -1.1396e-04],\n",
      "        [-5.0186e-05, -1.0540e+01, -1.0649e+01],\n",
      "        [-1.0469e+01, -3.4093e-05, -1.2075e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0791e+00, -1.6378e-04, -9.9101e+00],\n",
      "        [-9.2075e+00, -1.1216e+01, -1.1372e-04],\n",
      "        [-5.2451e-05, -1.0250e+01, -1.0977e+01],\n",
      "        [-1.0533e+01, -3.4212e-05, -1.1799e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5946e-05, -9.7585e+00, -1.0478e+01],\n",
      "        [-9.0583e+00, -1.6509e-04, -9.9310e+00],\n",
      "        [-9.2244e+00, -1.1130e+01, -1.1324e-04],\n",
      "        [-4.9947e-05, -1.0545e+01, -1.0654e+01],\n",
      "        [-1.0477e+01, -3.3736e-05, -1.2082e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0850e+00, -1.6283e-04, -9.9155e+00],\n",
      "        [-9.2134e+00, -1.1220e+01, -1.1312e-04],\n",
      "        [-5.2212e-05, -1.0255e+01, -1.0982e+01],\n",
      "        [-1.0540e+01, -3.3974e-05, -1.1806e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5589e-05, -9.7632e+00, -1.0484e+01],\n",
      "        [-9.0641e+00, -1.6414e-04, -9.9363e+00],\n",
      "        [-9.2302e+00, -1.1135e+01, -1.1265e-04],\n",
      "        [-4.9709e-05, -1.0550e+01, -1.0660e+01],\n",
      "        [-1.0485e+01, -3.3616e-05, -1.2088e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0908e+00, -1.6187e-04, -9.9208e+00],\n",
      "        [-9.2192e+00, -1.1224e+01, -1.1253e-04],\n",
      "        [-5.1855e-05, -1.0261e+01, -1.0986e+01],\n",
      "        [-1.0547e+01, -3.3616e-05, -1.1812e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.5112e-05, -9.7678e+00, -1.0489e+01],\n",
      "        [-9.0700e+00, -1.6318e-04, -9.9416e+00],\n",
      "        [-9.2359e+00, -1.1140e+01, -1.1205e-04],\n",
      "        [-4.9471e-05, -1.0555e+01, -1.0665e+01],\n",
      "        [-1.0492e+01, -3.3378e-05, -1.2095e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.0967e+00, -1.6092e-04, -9.9260e+00],\n",
      "        [-9.2251e+00, -1.1228e+01, -1.1181e-04],\n",
      "        [-5.1616e-05, -1.0266e+01, -1.0991e+01],\n",
      "        [-1.0554e+01, -3.3497e-05, -1.1819e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4635e-05, -9.7725e+00, -1.0494e+01],\n",
      "        [-9.0758e+00, -1.6235e-04, -9.9468e+00],\n",
      "        [-9.2416e+00, -1.1145e+01, -1.1134e-04],\n",
      "        [-4.9113e-05, -1.0560e+01, -1.0671e+01],\n",
      "        [-1.0500e+01, -3.3140e-05, -1.2101e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1025e+00, -1.6009e-04, -9.9313e+00],\n",
      "        [-9.2309e+00, -1.1233e+01, -1.1122e-04],\n",
      "        [-5.1378e-05, -1.0272e+01, -1.0996e+01],\n",
      "        [-1.0560e+01, -3.3140e-05, -1.1825e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.4277e-05, -9.7772e+00, -1.0500e+01],\n",
      "        [-9.0816e+00, -1.6140e-04, -9.9521e+00],\n",
      "        [-9.2472e+00, -1.1150e+01, -1.1074e-04],\n",
      "        [-4.8875e-05, -1.0566e+01, -1.0676e+01],\n",
      "        [-1.0507e+01, -3.2782e-05, -1.2107e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1083e+00, -1.5913e-04, -9.9366e+00],\n",
      "        [-9.2367e+00, -1.1237e+01, -1.1062e-04],\n",
      "        [-5.1139e-05, -1.0277e+01, -1.1000e+01],\n",
      "        [-1.0567e+01, -3.3020e-05, -1.1832e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3920e-05, -9.7818e+00, -1.0505e+01],\n",
      "        [-9.0874e+00, -1.6056e-04, -9.9573e+00],\n",
      "        [-9.2529e+00, -1.1155e+01, -1.1014e-04],\n",
      "        [-4.8636e-05, -1.0571e+01, -1.0681e+01],\n",
      "        [-1.0514e+01, -3.2663e-05, -1.2114e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1141e+00, -1.5830e-04, -9.9418e+00],\n",
      "        [-9.2426e+00, -1.1241e+01, -1.0990e-04],\n",
      "        [-5.0782e-05, -1.0283e+01, -1.1005e+01],\n",
      "        [-1.0574e+01, -3.2782e-05, -1.1838e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.3562e-05, -9.7864e+00, -1.0510e+01],\n",
      "        [-9.0931e+00, -1.5949e-04, -9.9625e+00],\n",
      "        [-9.2586e+00, -1.1160e+01, -1.0955e-04],\n",
      "        [-4.8398e-05, -1.0576e+01, -1.0687e+01],\n",
      "        [-1.0522e+01, -3.2424e-05, -1.2120e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.1199e+00, -1.5734e-04, -9.9470e+00],\n",
      "        [-9.2483e+00, -1.1245e+01, -1.0931e-04],\n",
      "        [-5.0543e-05, -1.0288e+01, -1.1010e+01],\n",
      "        [-1.0581e+01, -3.2544e-05, -1.1845e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2966e-05, -9.7910e+00, -1.0515e+01],\n",
      "        [-9.0989e+00, -1.5865e-04, -9.9678e+00],\n",
      "        [-9.2642e+00, -1.1166e+01, -1.0895e-04],\n",
      "        [-4.8159e-05, -1.0581e+01, -1.0692e+01],\n",
      "        [-1.0529e+01, -3.2067e-05, -1.2126e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1257e+00, -1.5651e-04, -9.9522e+00],\n",
      "        [-9.2541e+00, -1.1250e+01, -1.0871e-04],\n",
      "        [-5.0305e-05, -1.0294e+01, -1.1014e+01],\n",
      "        [-1.0588e+01, -3.2424e-05, -1.1851e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2609e-05, -9.7956e+00, -1.0521e+01],\n",
      "        [-9.1046e+00, -1.5782e-04, -9.9729e+00],\n",
      "        [-9.2698e+00, -1.1171e+01, -1.0836e-04],\n",
      "        [-4.7921e-05, -1.0586e+01, -1.0698e+01],\n",
      "        [-1.0537e+01, -3.1948e-05, -1.2132e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1314e+00, -1.5556e-04, -9.9574e+00],\n",
      "        [-9.2599e+00, -1.1254e+01, -1.0812e-04],\n",
      "        [-4.9947e-05, -1.0299e+01, -1.1019e+01],\n",
      "        [-1.0595e+01, -3.2067e-05, -1.1857e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.2251e-05, -9.8002e+00, -1.0526e+01],\n",
      "        [-9.1103e+00, -1.5687e-04, -9.9781e+00],\n",
      "        [-9.2754e+00, -1.1176e+01, -1.0776e-04],\n",
      "        [-4.7683e-05, -1.0591e+01, -1.0703e+01],\n",
      "        [-1.0544e+01, -3.1709e-05, -1.2139e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1371e+00, -1.5472e-04, -9.9626e+00],\n",
      "        [-9.2656e+00, -1.1258e+01, -1.0752e-04],\n",
      "        [-4.9828e-05, -1.0305e+01, -1.1023e+01],\n",
      "        [-1.0601e+01, -3.1948e-05, -1.1864e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1893e-05, -9.8048e+00, -1.0531e+01],\n",
      "        [-9.1160e+00, -1.5603e-04, -9.9833e+00],\n",
      "        [-9.2810e+00, -1.1181e+01, -1.0716e-04],\n",
      "        [-4.7444e-05, -1.0596e+01, -1.0708e+01],\n",
      "        [-1.0551e+01, -3.1471e-05, -1.2145e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1428e+00, -1.5389e-04, -9.9678e+00],\n",
      "        [-9.2714e+00, -1.1262e+01, -1.0693e-04],\n",
      "        [-4.9471e-05, -1.0310e+01, -1.1028e+01],\n",
      "        [-1.0608e+01, -3.1709e-05, -1.1870e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1536e-05, -9.8094e+00, -1.0536e+01],\n",
      "        [-9.1217e+00, -1.5520e-04, -9.9884e+00],\n",
      "        [-9.2866e+00, -1.1186e+01, -1.0657e-04],\n",
      "        [-4.7206e-05, -1.0601e+01, -1.0714e+01],\n",
      "        [-1.0559e+01, -3.1232e-05, -1.2151e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1485e+00, -1.5305e-04, -9.9729e+00],\n",
      "        [-9.2771e+00, -1.1266e+01, -1.0633e-04],\n",
      "        [-4.9351e-05, -1.0316e+01, -1.1033e+01],\n",
      "        [-1.0615e+01, -3.1471e-05, -1.1876e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.1178e-05, -9.8140e+00, -1.0541e+01],\n",
      "        [-9.1273e+00, -1.5436e-04, -9.9936e+00],\n",
      "        [-9.2922e+00, -1.1191e+01, -1.0597e-04],\n",
      "        [-4.6967e-05, -1.0606e+01, -1.0719e+01],\n",
      "        [-1.0566e+01, -3.0994e-05, -1.2157e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1542e+00, -1.5210e-04, -9.9780e+00],\n",
      "        [-9.2828e+00, -1.1271e+01, -1.0573e-04],\n",
      "        [-4.8994e-05, -1.0321e+01, -1.1037e+01],\n",
      "        [-1.0622e+01, -3.1352e-05, -1.1883e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0821e-05, -9.8185e+00, -1.0547e+01],\n",
      "        [-9.1330e+00, -1.5341e-04, -9.9987e+00],\n",
      "        [-9.2977e+00, -1.1196e+01, -1.0538e-04],\n",
      "        [-4.6729e-05, -1.0611e+01, -1.0724e+01],\n",
      "        [-1.0573e+01, -3.0875e-05, -1.2163e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1598e+00, -1.5127e-04, -9.9832e+00],\n",
      "        [-9.2885e+00, -1.1275e+01, -1.0514e-04],\n",
      "        [-4.8755e-05, -1.0326e+01, -1.1042e+01],\n",
      "        [-1.0628e+01, -3.1113e-05, -1.1889e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-8.0344e-05, -9.8231e+00, -1.0552e+01],\n",
      "        [-9.1386e+00, -1.5258e-04, -1.0004e+01],\n",
      "        [-9.3033e+00, -1.1200e+01, -1.0478e-04],\n",
      "        [-4.6491e-05, -1.0617e+01, -1.0729e+01],\n",
      "        [-1.0580e+01, -3.0636e-05, -1.2169e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1654e+00, -1.5055e-04, -9.9883e+00],\n",
      "        [-9.2941e+00, -1.1279e+01, -1.0466e-04],\n",
      "        [-4.8517e-05, -1.0332e+01, -1.1046e+01],\n",
      "        [-1.0635e+01, -3.0875e-05, -1.1895e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9986e-05, -9.8276e+00, -1.0557e+01],\n",
      "        [-9.1442e+00, -1.5186e-04, -1.0009e+01],\n",
      "        [-9.3088e+00, -1.1205e+01, -1.0418e-04],\n",
      "        [-4.6252e-05, -1.0622e+01, -1.0735e+01],\n",
      "        [-1.0588e+01, -3.0398e-05, -1.2175e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1710e+00, -1.4972e-04, -9.9933e+00],\n",
      "        [-9.2998e+00, -1.1283e+01, -1.0406e-04],\n",
      "        [-4.8279e-05, -1.0337e+01, -1.1051e+01],\n",
      "        [-1.0642e+01, -3.0636e-05, -1.1902e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9509e-05, -9.8321e+00, -1.0562e+01],\n",
      "        [-9.1498e+00, -1.5103e-04, -1.0014e+01],\n",
      "        [-9.3143e+00, -1.1210e+01, -1.0371e-04],\n",
      "        [-4.6014e-05, -1.0627e+01, -1.0740e+01],\n",
      "        [-1.0595e+01, -3.0159e-05, -1.2181e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1766e+00, -1.4900e-04, -9.9984e+00],\n",
      "        [-9.3054e+00, -1.1287e+01, -1.0347e-04],\n",
      "        [-4.8040e-05, -1.0343e+01, -1.1055e+01],\n",
      "        [-1.0648e+01, -3.0517e-05, -1.1908e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.9152e-05, -9.8366e+00, -1.0567e+01],\n",
      "        [-9.1553e+00, -1.5019e-04, -1.0019e+01],\n",
      "        [-9.3198e+00, -1.1215e+01, -1.0311e-04],\n",
      "        [-4.5775e-05, -1.0632e+01, -1.0745e+01],\n",
      "        [-1.0602e+01, -3.0040e-05, -1.2188e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1822e+00, -1.4817e-04, -1.0003e+01],\n",
      "        [-9.3111e+00, -1.1291e+01, -1.0287e-04],\n",
      "        [-4.7802e-05, -1.0348e+01, -1.1060e+01],\n",
      "        [-1.0655e+01, -3.0279e-05, -1.1914e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8794e-05, -9.8411e+00, -1.0572e+01],\n",
      "        [-9.1609e+00, -1.4948e-04, -1.0024e+01],\n",
      "        [-9.3253e+00, -1.1220e+01, -1.0251e-04],\n",
      "        [-4.5537e-05, -1.0637e+01, -1.0750e+01],\n",
      "        [-1.0609e+01, -2.9683e-05, -1.2194e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1878e+00, -1.4733e-04, -1.0009e+01],\n",
      "        [-9.3167e+00, -1.1295e+01, -1.0240e-04],\n",
      "        [-4.7563e-05, -1.0353e+01, -1.1064e+01],\n",
      "        [-1.0661e+01, -3.0159e-05, -1.1920e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8437e-05, -9.8456e+00, -1.0577e+01],\n",
      "        [-9.1664e+00, -1.4864e-04, -1.0029e+01],\n",
      "        [-9.3307e+00, -1.1225e+01, -1.0204e-04],\n",
      "        [-4.5299e-05, -1.0642e+01, -1.0756e+01],\n",
      "        [-1.0616e+01, -2.9563e-05, -1.2200e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1933e+00, -1.4650e-04, -1.0014e+01],\n",
      "        [-9.3223e+00, -1.1300e+01, -1.0180e-04],\n",
      "        [-4.7325e-05, -1.0359e+01, -1.1069e+01],\n",
      "        [-1.0668e+01, -2.9802e-05, -1.1926e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.8079e-05, -9.8501e+00, -1.0582e+01],\n",
      "        [-9.1719e+00, -1.4781e-04, -1.0034e+01],\n",
      "        [-9.3362e+00, -1.1230e+01, -1.0144e-04],\n",
      "        [-4.5060e-05, -1.0647e+01, -1.0761e+01],\n",
      "        [-1.0623e+01, -2.9325e-05, -1.2206e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.1988e+00, -1.4578e-04, -1.0019e+01],\n",
      "        [-9.3279e+00, -1.1304e+01, -1.0120e-04],\n",
      "        [-4.7087e-05, -1.0364e+01, -1.1073e+01],\n",
      "        [-1.0675e+01, -2.9683e-05, -1.1932e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7721e-05, -9.8546e+00, -1.0587e+01],\n",
      "        [-9.1774e+00, -1.4697e-04, -1.0039e+01],\n",
      "        [-9.3416e+00, -1.1235e+01, -1.0097e-04],\n",
      "        [-4.4822e-05, -1.0651e+01, -1.0766e+01],\n",
      "        [-1.0630e+01, -2.9206e-05, -1.2212e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2044e+00, -1.4495e-04, -1.0024e+01],\n",
      "        [-9.3334e+00, -1.1308e+01, -1.0073e-04],\n",
      "        [-4.6848e-05, -1.0369e+01, -1.1078e+01],\n",
      "        [-1.0681e+01, -2.9563e-05, -1.1939e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7483e-05, -9.8591e+00, -1.0592e+01],\n",
      "        [-9.1829e+00, -1.4614e-04, -1.0044e+01],\n",
      "        [-9.3470e+00, -1.1240e+01, -1.0037e-04],\n",
      "        [-4.4583e-05, -1.0656e+01, -1.0771e+01],\n",
      "        [-1.0637e+01, -2.8848e-05, -1.2217e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2098e+00, -1.4411e-04, -1.0029e+01],\n",
      "        [-9.3390e+00, -1.1312e+01, -1.0013e-04],\n",
      "        [-4.6610e-05, -1.0375e+01, -1.1082e+01],\n",
      "        [-1.0688e+01, -2.9325e-05, -1.1945e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.7125e-05, -9.8635e+00, -1.0597e+01],\n",
      "        [-9.1884e+00, -1.4554e-04, -1.0049e+01],\n",
      "        [-9.3525e+00, -1.1244e+01, -9.9892e-05],\n",
      "        [-4.4345e-05, -1.0661e+01, -1.0776e+01],\n",
      "        [-1.0644e+01, -2.8729e-05, -1.2223e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2153e+00, -1.4340e-04, -1.0034e+01],\n",
      "        [-9.3445e+00, -1.1316e+01, -9.9654e-05],\n",
      "        [-4.6252e-05, -1.0380e+01, -1.1087e+01],\n",
      "        [-1.0694e+01, -2.9087e-05, -1.1951e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6768e-05, -9.8680e+00, -1.0602e+01],\n",
      "        [-9.1938e+00, -1.4471e-04, -1.0054e+01],\n",
      "        [-9.3579e+00, -1.1249e+01, -9.9296e-05],\n",
      "        [-4.4106e-05, -1.0666e+01, -1.0782e+01],\n",
      "        [-1.0651e+01, -2.8610e-05, -1.2229e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2208e+00, -1.4268e-04, -1.0038e+01],\n",
      "        [-9.3500e+00, -1.1320e+01, -9.9058e-05],\n",
      "        [-4.6133e-05, -1.0385e+01, -1.1091e+01],\n",
      "        [-1.0700e+01, -2.8967e-05, -1.1957e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.6291e-05, -9.8724e+00, -1.0607e+01],\n",
      "        [-9.1993e+00, -1.4388e-04, -1.0059e+01],\n",
      "        [-9.3632e+00, -1.1254e+01, -9.8820e-05],\n",
      "        [-4.3868e-05, -1.0671e+01, -1.0787e+01],\n",
      "        [-1.0658e+01, -2.8371e-05, -1.2235e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2262e+00, -1.4197e-04, -1.0043e+01],\n",
      "        [-9.3556e+00, -1.1324e+01, -9.8581e-05],\n",
      "        [-4.5895e-05, -1.0390e+01, -1.1095e+01],\n",
      "        [-1.0707e+01, -2.8729e-05, -1.1963e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5933e-05, -9.8768e+00, -1.0612e+01],\n",
      "        [-9.2047e+00, -1.4316e-04, -1.0064e+01],\n",
      "        [-9.3686e+00, -1.1259e+01, -9.8224e-05],\n",
      "        [-4.3749e-05, -1.0676e+01, -1.0792e+01],\n",
      "        [-1.0665e+01, -2.8252e-05, -1.2241e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2316e+00, -1.4113e-04, -1.0048e+01],\n",
      "        [-9.3611e+00, -1.1328e+01, -9.7985e-05],\n",
      "        [-4.5656e-05, -1.0396e+01, -1.1100e+01],\n",
      "        [-1.0713e+01, -2.8610e-05, -1.1969e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5576e-05, -9.8812e+00, -1.0617e+01],\n",
      "        [-9.2101e+00, -1.4244e-04, -1.0069e+01],\n",
      "        [-9.3740e+00, -1.1264e+01, -9.7747e-05],\n",
      "        [-4.3510e-05, -1.0681e+01, -1.0797e+01],\n",
      "        [-1.0672e+01, -2.7895e-05, -1.2247e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2371e+00, -1.4042e-04, -1.0053e+01],\n",
      "        [-9.3665e+00, -1.1332e+01, -9.7508e-05],\n",
      "        [-4.5418e-05, -1.0401e+01, -1.1104e+01],\n",
      "        [-1.0720e+01, -2.8371e-05, -1.1975e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.5218e-05, -9.8857e+00, -1.0622e+01],\n",
      "        [-9.2155e+00, -1.4173e-04, -1.0074e+01],\n",
      "        [-9.3793e+00, -1.1268e+01, -9.7270e-05],\n",
      "        [-4.3272e-05, -1.0686e+01, -1.0802e+01],\n",
      "        [-1.0679e+01, -2.7775e-05, -1.2253e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2424e+00, -1.3958e-04, -1.0058e+01],\n",
      "        [-9.3720e+00, -1.1336e+01, -9.7032e-05],\n",
      "        [-4.5299e-05, -1.0406e+01, -1.1109e+01],\n",
      "        [-1.0726e+01, -2.8252e-05, -1.1981e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4861e-05, -9.8901e+00, -1.0627e+01],\n",
      "        [-9.2208e+00, -1.4090e-04, -1.0079e+01],\n",
      "        [-9.3846e+00, -1.1273e+01, -9.6674e-05],\n",
      "        [-4.3034e-05, -1.0691e+01, -1.0807e+01],\n",
      "        [-1.0686e+01, -2.7656e-05, -1.2259e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2478e+00, -1.3899e-04, -1.0063e+01],\n",
      "        [-9.3775e+00, -1.1340e+01, -9.6555e-05],\n",
      "        [-4.4941e-05, -1.0411e+01, -1.1113e+01],\n",
      "        [-1.0732e+01, -2.8014e-05, -1.1987e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4503e-05, -9.8944e+00, -1.0632e+01],\n",
      "        [-9.2262e+00, -1.4018e-04, -1.0084e+01],\n",
      "        [-9.3900e+00, -1.1278e+01, -9.6197e-05],\n",
      "        [-4.2795e-05, -1.0696e+01, -1.0812e+01],\n",
      "        [-1.0693e+01, -2.7537e-05, -1.2264e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2532e+00, -1.3827e-04, -1.0068e+01],\n",
      "        [-9.3829e+00, -1.1344e+01, -9.5959e-05],\n",
      "        [-4.4822e-05, -1.0417e+01, -1.1117e+01],\n",
      "        [-1.0739e+01, -2.7895e-05, -1.1993e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.4145e-05, -9.8988e+00, -1.0637e+01],\n",
      "        [-9.2315e+00, -1.3947e-04, -1.0089e+01],\n",
      "        [-9.3953e+00, -1.1282e+01, -9.5720e-05],\n",
      "        [-4.2557e-05, -1.0701e+01, -1.0817e+01],\n",
      "        [-1.0700e+01, -2.7179e-05, -1.2270e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2585e+00, -1.3756e-04, -1.0073e+01],\n",
      "        [-9.3883e+00, -1.1348e+01, -9.5482e-05],\n",
      "        [-4.4583e-05, -1.0422e+01, -1.1122e+01],\n",
      "        [-1.0745e+01, -2.7775e-05, -1.1999e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3907e-05, -9.9032e+00, -1.0642e+01],\n",
      "        [-9.2369e+00, -1.3875e-04, -1.0093e+01],\n",
      "        [-9.4006e+00, -1.1287e+01, -9.5244e-05],\n",
      "        [-4.2318e-05, -1.0705e+01, -1.0822e+01],\n",
      "        [-1.0706e+01, -2.7060e-05, -1.2276e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2639e+00, -1.3672e-04, -1.0078e+01],\n",
      "        [-9.3937e+00, -1.1352e+01, -9.5005e-05],\n",
      "        [-4.4345e-05, -1.0427e+01, -1.1126e+01],\n",
      "        [-1.0751e+01, -2.7537e-05, -1.2005e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3549e-05, -9.9075e+00, -1.0647e+01],\n",
      "        [-9.2422e+00, -1.3803e-04, -1.0098e+01],\n",
      "        [-9.4058e+00, -1.1292e+01, -9.4767e-05],\n",
      "        [-4.2199e-05, -1.0710e+01, -1.0827e+01],\n",
      "        [-1.0713e+01, -2.6941e-05, -1.2282e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2692e+00, -1.3613e-04, -1.0083e+01],\n",
      "        [-9.3991e+00, -1.1356e+01, -9.4528e-05],\n",
      "        [-4.4106e-05, -1.0432e+01, -1.1131e+01],\n",
      "        [-1.0758e+01, -2.7418e-05, -1.2011e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.3192e-05, -9.9119e+00, -1.0652e+01],\n",
      "        [-9.2474e+00, -1.3732e-04, -1.0103e+01],\n",
      "        [-9.4111e+00, -1.1297e+01, -9.4290e-05],\n",
      "        [-4.1961e-05, -1.0715e+01, -1.0832e+01],\n",
      "        [-1.0720e+01, -2.6703e-05, -1.2287e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2745e+00, -1.3541e-04, -1.0087e+01],\n",
      "        [-9.4045e+00, -1.1360e+01, -9.4052e-05],\n",
      "        [-4.3868e-05, -1.0437e+01, -1.1135e+01],\n",
      "        [-1.0764e+01, -2.7179e-05, -1.2017e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2834e-05, -9.9162e+00, -1.0657e+01],\n",
      "        [-9.2527e+00, -1.3660e-04, -1.0108e+01],\n",
      "        [-9.4163e+00, -1.1301e+01, -9.3694e-05],\n",
      "        [-4.1722e-05, -1.0720e+01, -1.0837e+01],\n",
      "        [-1.0727e+01, -2.6464e-05, -1.2293e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2797e+00, -1.3470e-04, -1.0092e+01],\n",
      "        [-9.4099e+00, -1.1364e+01, -9.3575e-05],\n",
      "        [-4.3749e-05, -1.0442e+01, -1.1139e+01],\n",
      "        [-1.0770e+01, -2.6941e-05, -1.2022e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2596e-05, -9.9206e+00, -1.0662e+01],\n",
      "        [-9.2580e+00, -1.3589e-04, -1.0113e+01],\n",
      "        [-9.4216e+00, -1.1306e+01, -9.3217e-05],\n",
      "        [-4.1603e-05, -1.0725e+01, -1.0842e+01],\n",
      "        [-1.0733e+01, -2.6345e-05, -1.2299e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2850e+00, -1.3410e-04, -1.0097e+01],\n",
      "        [-9.4153e+00, -1.1368e+01, -9.2979e-05],\n",
      "        [-4.3391e-05, -1.0448e+01, -1.1144e+01],\n",
      "        [-1.0776e+01, -2.6822e-05, -1.2028e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2357e-05, -9.9249e+00, -1.0667e+01],\n",
      "        [-9.2632e+00, -1.3529e-04, -1.0117e+01],\n",
      "        [-9.4268e+00, -1.1310e+01, -9.2741e-05],\n",
      "        [-4.1365e-05, -1.0729e+01, -1.0847e+01],\n",
      "        [-1.0740e+01, -2.6226e-05, -1.2304e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2903e+00, -1.3339e-04, -1.0102e+01],\n",
      "        [-9.4206e+00, -1.1372e+01, -9.2502e-05],\n",
      "        [-4.3272e-05, -1.0453e+01, -1.1148e+01],\n",
      "        [-1.0782e+01, -2.6703e-05, -1.2034e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.2000e-05, -9.9292e+00, -1.0671e+01],\n",
      "        [-9.2685e+00, -1.3458e-04, -1.0122e+01],\n",
      "        [-9.4320e+00, -1.1315e+01, -9.2264e-05],\n",
      "        [-4.1126e-05, -1.0734e+01, -1.0852e+01],\n",
      "        [-1.0747e+01, -2.5987e-05, -1.2310e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.2955e+00, -1.3255e-04, -1.0107e+01],\n",
      "        [-9.4259e+00, -1.1376e+01, -9.2025e-05],\n",
      "        [-4.3034e-05, -1.0458e+01, -1.1152e+01],\n",
      "        [-1.0789e+01, -2.6583e-05, -1.2040e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.1642e-05, -9.9335e+00, -1.0676e+01],\n",
      "        [-9.2737e+00, -1.3374e-04, -1.0127e+01],\n",
      "        [-9.4372e+00, -1.1320e+01, -9.1787e-05],\n",
      "        [-4.1007e-05, -1.0739e+01, -1.0857e+01],\n",
      "        [-1.0753e+01, -2.5868e-05, -1.2316e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3007e+00, -1.3196e-04, -1.0111e+01],\n",
      "        [-9.4313e+00, -1.1380e+01, -9.1549e-05],\n",
      "        [-4.2914e-05, -1.0463e+01, -1.1157e+01],\n",
      "        [-1.0795e+01, -2.6345e-05, -1.2046e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.1285e-05, -9.9378e+00, -1.0681e+01],\n",
      "        [-9.2789e+00, -1.3315e-04, -1.0132e+01],\n",
      "        [-9.4424e+00, -1.1324e+01, -9.1310e-05],\n",
      "        [-4.0769e-05, -1.0744e+01, -1.0862e+01],\n",
      "        [-1.0760e+01, -2.5630e-05, -1.2321e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3059e+00, -1.3124e-04, -1.0116e+01],\n",
      "        [-9.4366e+00, -1.1384e+01, -9.1191e-05],\n",
      "        [-4.2676e-05, -1.0468e+01, -1.1161e+01],\n",
      "        [-1.0801e+01, -2.6226e-05, -1.2052e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.1046e-05, -9.9421e+00, -1.0686e+01],\n",
      "        [-9.2840e+00, -1.3243e-04, -1.0137e+01],\n",
      "        [-9.4476e+00, -1.1329e+01, -9.0953e-05],\n",
      "        [-4.0530e-05, -1.0748e+01, -1.0867e+01],\n",
      "        [-1.0767e+01, -2.5510e-05, -1.2327e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3111e+00, -1.3076e-04, -1.0121e+01],\n",
      "        [-9.4418e+00, -1.1388e+01, -9.0714e-05],\n",
      "        [-4.2438e-05, -1.0473e+01, -1.1165e+01],\n",
      "        [-1.0807e+01, -2.6106e-05, -1.2057e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.0689e-05, -9.9463e+00, -1.0691e+01],\n",
      "        [-9.2892e+00, -1.3184e-04, -1.0141e+01],\n",
      "        [-9.4527e+00, -1.1333e+01, -9.0476e-05],\n",
      "        [-4.0292e-05, -1.0753e+01, -1.0872e+01],\n",
      "        [-1.0773e+01, -2.5391e-05, -1.2332e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3163e+00, -1.3005e-04, -1.0125e+01],\n",
      "        [-9.4471e+00, -1.1391e+01, -9.0237e-05],\n",
      "        [-4.2199e-05, -1.0478e+01, -1.1169e+01],\n",
      "        [-1.0813e+01, -2.5868e-05, -1.2063e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-7.0331e-05, -9.9506e+00, -1.0696e+01],\n",
      "        [-9.2944e+00, -1.3112e-04, -1.0146e+01],\n",
      "        [-9.4579e+00, -1.1338e+01, -8.9999e-05],\n",
      "        [-4.0054e-05, -1.0758e+01, -1.0877e+01],\n",
      "        [-1.0780e+01, -2.5272e-05, -1.2338e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3215e+00, -1.2933e-04, -1.0130e+01],\n",
      "        [-9.4524e+00, -1.1395e+01, -8.9761e-05],\n",
      "        [-4.2080e-05, -1.0483e+01, -1.1174e+01],\n",
      "        [-1.0819e+01, -2.5749e-05, -1.2069e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.9973e-05, -9.9549e+00, -1.0700e+01],\n",
      "        [-9.2995e+00, -1.3053e-04, -1.0151e+01],\n",
      "        [-9.4630e+00, -1.1342e+01, -8.9522e-05],\n",
      "        [-4.0054e-05, -1.0763e+01, -1.0882e+01],\n",
      "        [-1.0786e+01, -2.5034e-05, -1.2343e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3266e+00, -1.2874e-04, -1.0135e+01],\n",
      "        [-9.4576e+00, -1.1399e+01, -8.9284e-05],\n",
      "        [-4.1842e-05, -1.0488e+01, -1.1178e+01],\n",
      "        [-1.0825e+01, -2.5630e-05, -1.2075e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.9735e-05, -9.9591e+00, -1.0705e+01],\n",
      "        [-9.3046e+00, -1.2981e-04, -1.0155e+01],\n",
      "        [-9.4682e+00, -1.1347e+01, -8.9045e-05],\n",
      "        [-3.9815e-05, -1.0767e+01, -1.0887e+01],\n",
      "        [-1.0793e+01, -2.4795e-05, -1.2349e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3317e+00, -1.2802e-04, -1.0140e+01],\n",
      "        [-9.4629e+00, -1.1403e+01, -8.8807e-05],\n",
      "        [-4.1722e-05, -1.0493e+01, -1.1182e+01],\n",
      "        [-1.0831e+01, -2.5510e-05, -1.2080e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.9377e-05, -9.9634e+00, -1.0710e+01],\n",
      "        [-9.3098e+00, -1.2933e-04, -1.0160e+01],\n",
      "        [-9.4733e+00, -1.1352e+01, -8.8688e-05],\n",
      "        [-3.9577e-05, -1.0772e+01, -1.0892e+01],\n",
      "        [-1.0799e+01, -2.4676e-05, -1.2354e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3368e+00, -1.2743e-04, -1.0144e+01],\n",
      "        [-9.4681e+00, -1.1407e+01, -8.8449e-05],\n",
      "        [-4.1365e-05, -1.0498e+01, -1.1186e+01],\n",
      "        [-1.0837e+01, -2.5272e-05, -1.2086e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.9020e-05, -9.9676e+00, -1.0715e+01],\n",
      "        [-9.3148e+00, -1.2862e-04, -1.0165e+01],\n",
      "        [-9.4784e+00, -1.1356e+01, -8.8211e-05],\n",
      "        [-3.9338e-05, -1.0777e+01, -1.0897e+01],\n",
      "        [-1.0806e+01, -2.4557e-05, -1.2360e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3419e+00, -1.2683e-04, -1.0149e+01],\n",
      "        [-9.4733e+00, -1.1411e+01, -8.7973e-05],\n",
      "        [-4.1246e-05, -1.0503e+01, -1.1191e+01],\n",
      "        [-1.0843e+01, -2.5153e-05, -1.2092e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.8781e-05, -9.9718e+00, -1.0719e+01],\n",
      "        [-9.3199e+00, -1.2802e-04, -1.0169e+01],\n",
      "        [-9.4834e+00, -1.1361e+01, -8.7734e-05],\n",
      "        [-3.9219e-05, -1.0781e+01, -1.0901e+01],\n",
      "        [-1.0812e+01, -2.4438e-05, -1.2365e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3470e+00, -1.2623e-04, -1.0154e+01],\n",
      "        [-9.4785e+00, -1.1415e+01, -8.7496e-05],\n",
      "        [-4.1007e-05, -1.0508e+01, -1.1195e+01],\n",
      "        [-1.0849e+01, -2.5034e-05, -1.2097e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.8543e-05, -9.9760e+00, -1.0724e+01],\n",
      "        [-9.3250e+00, -1.2731e-04, -1.0174e+01],\n",
      "        [-9.4885e+00, -1.1365e+01, -8.7257e-05],\n",
      "        [-3.9100e-05, -1.0786e+01, -1.0906e+01],\n",
      "        [-1.0819e+01, -2.4318e-05, -1.2371e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3521e+00, -1.2552e-04, -1.0158e+01],\n",
      "        [-9.4837e+00, -1.1418e+01, -8.7019e-05],\n",
      "        [-4.0888e-05, -1.0513e+01, -1.1199e+01],\n",
      "        [-1.0855e+01, -2.4795e-05, -1.2103e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.8185e-05, -9.9802e+00, -1.0729e+01],\n",
      "        [-9.3301e+00, -1.2671e-04, -1.0179e+01],\n",
      "        [-9.4936e+00, -1.1369e+01, -8.6900e-05],\n",
      "        [-3.8861e-05, -1.0791e+01, -1.0911e+01],\n",
      "        [-1.0825e+01, -2.4080e-05, -1.2376e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3572e+00, -1.2492e-04, -1.0163e+01],\n",
      "        [-9.4889e+00, -1.1422e+01, -8.6661e-05],\n",
      "        [-4.0650e-05, -1.0518e+01, -1.1203e+01],\n",
      "        [-1.0861e+01, -2.4676e-05, -1.2109e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.7947e-05, -9.9844e+00, -1.0734e+01],\n",
      "        [-9.3351e+00, -1.2612e-04, -1.0183e+01],\n",
      "        [-9.4986e+00, -1.1374e+01, -8.6423e-05],\n",
      "        [-3.8623e-05, -1.0795e+01, -1.0916e+01],\n",
      "        [-1.0832e+01, -2.3961e-05, -1.2382e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3622e+00, -1.2433e-04, -1.0167e+01],\n",
      "        [-9.4940e+00, -1.1426e+01, -8.6185e-05],\n",
      "        [-4.0530e-05, -1.0523e+01, -1.1207e+01],\n",
      "        [-1.0867e+01, -2.4557e-05, -1.2114e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.7589e-05, -9.9886e+00, -1.0738e+01],\n",
      "        [-9.3401e+00, -1.2552e-04, -1.0188e+01],\n",
      "        [-9.5037e+00, -1.1378e+01, -8.6065e-05],\n",
      "        [-3.8504e-05, -1.0800e+01, -1.0921e+01],\n",
      "        [-1.0838e+01, -2.3842e-05, -1.2387e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3672e+00, -1.2373e-04, -1.0172e+01],\n",
      "        [-9.4992e+00, -1.1430e+01, -8.5827e-05],\n",
      "        [-4.0292e-05, -1.0528e+01, -1.1212e+01],\n",
      "        [-1.0873e+01, -2.4438e-05, -1.2120e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.7351e-05, -9.9928e+00, -1.0743e+01],\n",
      "        [-9.3451e+00, -1.2480e-04, -1.0193e+01],\n",
      "        [-9.5087e+00, -1.1383e+01, -8.5589e-05],\n",
      "        [-3.8265e-05, -1.0805e+01, -1.0925e+01],\n",
      "        [-1.0844e+01, -2.3722e-05, -1.2392e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3723e+00, -1.2314e-04, -1.0177e+01],\n",
      "        [-9.5043e+00, -1.1434e+01, -8.5350e-05],\n",
      "        [-4.0054e-05, -1.0533e+01, -1.1216e+01],\n",
      "        [-1.0879e+01, -2.4199e-05, -1.2125e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.6993e-05, -9.9969e+00, -1.0748e+01],\n",
      "        [-9.3501e+00, -1.2433e-04, -1.0197e+01],\n",
      "        [-9.5137e+00, -1.1387e+01, -8.5231e-05],\n",
      "        [-3.8146e-05, -1.0809e+01, -1.0930e+01],\n",
      "        [-1.0851e+01, -2.3603e-05, -1.2398e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3773e+00, -1.2254e-04, -1.0181e+01],\n",
      "        [-9.5094e+00, -1.1437e+01, -8.4993e-05],\n",
      "        [-3.9815e-05, -1.0538e+01, -1.1220e+01],\n",
      "        [-1.0885e+01, -2.4080e-05, -1.2131e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.6636e-05, -1.0001e+01, -1.0752e+01],\n",
      "        [-9.3551e+00, -1.2361e-04, -1.0202e+01],\n",
      "        [-9.5187e+00, -1.1392e+01, -8.4754e-05],\n",
      "        [-3.8027e-05, -1.0814e+01, -1.0935e+01],\n",
      "        [-1.0857e+01, -2.3365e-05, -1.2403e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3822e+00, -1.2182e-04, -1.0186e+01],\n",
      "        [-9.5145e+00, -1.1441e+01, -8.4516e-05],\n",
      "        [-3.9696e-05, -1.0543e+01, -1.1224e+01],\n",
      "        [-1.0891e+01, -2.3961e-05, -1.2137e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.6517e-05, -1.0005e+01, -1.0757e+01],\n",
      "        [-9.3601e+00, -1.2302e-04, -1.0206e+01],\n",
      "        [-9.5237e+00, -1.1396e+01, -8.4397e-05],\n",
      "        [-3.7789e-05, -1.0818e+01, -1.0940e+01],\n",
      "        [-1.0863e+01, -2.3246e-05, -1.2408e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3872e+00, -1.2135e-04, -1.0190e+01],\n",
      "        [-9.5196e+00, -1.1445e+01, -8.4158e-05],\n",
      "        [-3.9577e-05, -1.0548e+01, -1.1228e+01],\n",
      "        [-1.0897e+01, -2.3842e-05, -1.2142e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.6159e-05, -1.0009e+01, -1.0762e+01],\n",
      "        [-9.3650e+00, -1.2242e-04, -1.0211e+01],\n",
      "        [-9.5287e+00, -1.1400e+01, -8.3920e-05],\n",
      "        [-3.7550e-05, -1.0823e+01, -1.0945e+01],\n",
      "        [-1.0870e+01, -2.3126e-05, -1.2414e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3922e+00, -1.2063e-04, -1.0195e+01],\n",
      "        [-9.5247e+00, -1.1449e+01, -8.3681e-05],\n",
      "        [-3.9338e-05, -1.0553e+01, -1.1232e+01],\n",
      "        [-1.0902e+01, -2.3603e-05, -1.2148e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.5921e-05, -1.0013e+01, -1.0766e+01],\n",
      "        [-9.3700e+00, -1.2182e-04, -1.0215e+01],\n",
      "        [-9.5336e+00, -1.1405e+01, -8.3562e-05],\n",
      "        [-3.7312e-05, -1.0828e+01, -1.0949e+01],\n",
      "        [-1.0876e+01, -2.3007e-05, -1.2419e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.3971e+00, -1.2016e-04, -1.0199e+01],\n",
      "        [-9.5298e+00, -1.1452e+01, -8.3324e-05],\n",
      "        [-3.9219e-05, -1.0558e+01, -1.1236e+01],\n",
      "        [-1.0908e+01, -2.3603e-05, -1.2153e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.5563e-05, -1.0018e+01, -1.0771e+01],\n",
      "        [-9.3749e+00, -1.2135e-04, -1.0220e+01],\n",
      "        [-9.5386e+00, -1.1409e+01, -8.3085e-05],\n",
      "        [-3.7312e-05, -1.0832e+01, -1.0954e+01],\n",
      "        [-1.0882e+01, -2.2888e-05, -1.2424e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4021e+00, -1.1968e-04, -1.0204e+01],\n",
      "        [-9.5348e+00, -1.1456e+01, -8.2847e-05],\n",
      "        [-3.8981e-05, -1.0563e+01, -1.1241e+01],\n",
      "        [-1.0914e+01, -2.3484e-05, -1.2159e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.5325e-05, -1.0022e+01, -1.0776e+01],\n",
      "        [-9.3798e+00, -1.2063e-04, -1.0224e+01],\n",
      "        [-9.5435e+00, -1.1413e+01, -8.2728e-05],\n",
      "        [-3.7073e-05, -1.0837e+01, -1.0959e+01],\n",
      "        [-1.0888e+01, -2.2769e-05, -1.2430e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4070e+00, -1.1896e-04, -1.0208e+01],\n",
      "        [-9.5399e+00, -1.1460e+01, -8.2489e-05],\n",
      "        [-3.8861e-05, -1.0567e+01, -1.1245e+01],\n",
      "        [-1.0920e+01, -2.3365e-05, -1.2164e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.5086e-05, -1.0026e+01, -1.0780e+01],\n",
      "        [-9.3847e+00, -1.2016e-04, -1.0229e+01],\n",
      "        [-9.5485e+00, -1.1418e+01, -8.2370e-05],\n",
      "        [-3.6835e-05, -1.0841e+01, -1.0963e+01],\n",
      "        [-1.0895e+01, -2.2530e-05, -1.2435e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4119e+00, -1.1849e-04, -1.0213e+01],\n",
      "        [-9.5449e+00, -1.1464e+01, -8.2013e-05],\n",
      "        [-3.8623e-05, -1.0572e+01, -1.1249e+01],\n",
      "        [-1.0926e+01, -2.3126e-05, -1.2170e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.4848e-05, -1.0030e+01, -1.0785e+01],\n",
      "        [-9.3896e+00, -1.1956e-04, -1.0233e+01],\n",
      "        [-9.5534e+00, -1.1422e+01, -8.1893e-05],\n",
      "        [-3.6716e-05, -1.0846e+01, -1.0968e+01],\n",
      "        [-1.0901e+01, -2.2411e-05, -1.2440e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4168e+00, -1.1777e-04, -1.0217e+01],\n",
      "        [-9.5500e+00, -1.1467e+01, -8.1655e-05],\n",
      "        [-3.8504e-05, -1.0577e+01, -1.1253e+01],\n",
      "        [-1.0931e+01, -2.3007e-05, -1.2175e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.4490e-05, -1.0034e+01, -1.0789e+01],\n",
      "        [-9.3945e+00, -1.1896e-04, -1.0238e+01],\n",
      "        [-9.5583e+00, -1.1426e+01, -8.1536e-05],\n",
      "        [-3.6597e-05, -1.0850e+01, -1.0973e+01],\n",
      "        [-1.0907e+01, -2.2292e-05, -1.2445e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4217e+00, -1.1730e-04, -1.0222e+01],\n",
      "        [-9.5550e+00, -1.1471e+01, -8.1297e-05],\n",
      "        [-3.8265e-05, -1.0582e+01, -1.1257e+01],\n",
      "        [-1.0937e+01, -2.2888e-05, -1.2181e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.4252e-05, -1.0038e+01, -1.0794e+01],\n",
      "        [-9.3994e+00, -1.1837e-04, -1.0242e+01],\n",
      "        [-9.5632e+00, -1.1431e+01, -8.1178e-05],\n",
      "        [-3.6358e-05, -1.0855e+01, -1.0977e+01],\n",
      "        [-1.0913e+01, -2.2173e-05, -1.2451e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4265e+00, -1.1682e-04, -1.0226e+01],\n",
      "        [-9.5600e+00, -1.1475e+01, -8.0940e-05],\n",
      "        [-3.8146e-05, -1.0587e+01, -1.1261e+01],\n",
      "        [-1.0943e+01, -2.2769e-05, -1.2186e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.3894e-05, -1.0042e+01, -1.0798e+01],\n",
      "        [-9.4042e+00, -1.1789e-04, -1.0247e+01],\n",
      "        [-9.5681e+00, -1.1435e+01, -8.0701e-05],\n",
      "        [-3.6239e-05, -1.0859e+01, -1.0982e+01],\n",
      "        [-1.0919e+01, -2.2053e-05, -1.2456e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4314e+00, -1.1622e-04, -1.0231e+01],\n",
      "        [-9.5649e+00, -1.1479e+01, -8.0463e-05],\n",
      "        [-3.7908e-05, -1.0592e+01, -1.1265e+01],\n",
      "        [-1.0948e+01, -2.2769e-05, -1.2191e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.3775e-05, -1.0046e+01, -1.0803e+01],\n",
      "        [-9.4091e+00, -1.1730e-04, -1.0251e+01],\n",
      "        [-9.5729e+00, -1.1439e+01, -8.0344e-05],\n",
      "        [-3.6120e-05, -1.0864e+01, -1.0987e+01],\n",
      "        [-1.0925e+01, -2.1934e-05, -1.2461e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4362e+00, -1.1563e-04, -1.0235e+01],\n",
      "        [-9.5699e+00, -1.1482e+01, -8.0105e-05],\n",
      "        [-3.7789e-05, -1.0596e+01, -1.1269e+01],\n",
      "        [-1.0954e+01, -2.2530e-05, -1.2197e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.3417e-05, -1.0050e+01, -1.0808e+01],\n",
      "        [-9.4139e+00, -1.1670e-04, -1.0256e+01],\n",
      "        [-9.5778e+00, -1.1444e+01, -7.9986e-05],\n",
      "        [-3.5881e-05, -1.0868e+01, -1.0991e+01],\n",
      "        [-1.0931e+01, -2.1696e-05, -1.2466e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4411e+00, -1.1515e-04, -1.0240e+01],\n",
      "        [-9.5749e+00, -1.1486e+01, -7.9748e-05],\n",
      "        [-3.7669e-05, -1.0601e+01, -1.1273e+01],\n",
      "        [-1.0960e+01, -2.2411e-05, -1.2202e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.3179e-05, -1.0054e+01, -1.0812e+01],\n",
      "        [-9.4187e+00, -1.1622e-04, -1.0260e+01],\n",
      "        [-9.5826e+00, -1.1448e+01, -7.9629e-05],\n",
      "        [-3.5762e-05, -1.0873e+01, -1.0996e+01],\n",
      "        [-1.0938e+01, -2.1577e-05, -1.2471e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4459e+00, -1.1455e-04, -1.0244e+01],\n",
      "        [-9.5798e+00, -1.1490e+01, -7.9390e-05],\n",
      "        [-3.7431e-05, -1.0606e+01, -1.1277e+01],\n",
      "        [-1.0965e+01, -2.2292e-05, -1.2208e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.2821e-05, -1.0058e+01, -1.0817e+01],\n",
      "        [-9.4235e+00, -1.1563e-04, -1.0265e+01],\n",
      "        [-9.5875e+00, -1.1452e+01, -7.9271e-05],\n",
      "        [-3.5524e-05, -1.0877e+01, -1.1001e+01],\n",
      "        [-1.0944e+01, -2.1457e-05, -1.2476e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4507e+00, -1.1408e-04, -1.0249e+01],\n",
      "        [-9.5848e+00, -1.1493e+01, -7.8913e-05],\n",
      "        [-3.7312e-05, -1.0611e+01, -1.1281e+01],\n",
      "        [-1.0971e+01, -2.2173e-05, -1.2213e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.2702e-05, -1.0062e+01, -1.0821e+01],\n",
      "        [-9.4283e+00, -1.1515e-04, -1.0269e+01],\n",
      "        [-9.5923e+00, -1.1456e+01, -7.8794e-05],\n",
      "        [-3.5405e-05, -1.0882e+01, -1.1005e+01],\n",
      "        [-1.0950e+01, -2.1338e-05, -1.2481e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4555e+00, -1.1360e-04, -1.0253e+01],\n",
      "        [-9.5897e+00, -1.1497e+01, -7.8556e-05],\n",
      "        [-3.7073e-05, -1.0616e+01, -1.1285e+01],\n",
      "        [-1.0977e+01, -2.1934e-05, -1.2218e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.2345e-05, -1.0066e+01, -1.0826e+01],\n",
      "        [-9.4331e+00, -1.1455e-04, -1.0273e+01],\n",
      "        [-9.5971e+00, -1.1461e+01, -7.8437e-05],\n",
      "        [-3.5285e-05, -1.0886e+01, -1.1010e+01],\n",
      "        [-1.0956e+01, -2.1219e-05, -1.2487e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4602e+00, -1.1288e-04, -1.0257e+01],\n",
      "        [-9.5946e+00, -1.1501e+01, -7.8198e-05],\n",
      "        [-3.6954e-05, -1.0620e+01, -1.1289e+01],\n",
      "        [-1.0982e+01, -2.1934e-05, -1.2224e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.2106e-05, -1.0070e+01, -1.0830e+01],\n",
      "        [-9.4378e+00, -1.1396e-04, -1.0278e+01],\n",
      "        [-9.6019e+00, -1.1465e+01, -7.8079e-05],\n",
      "        [-3.5047e-05, -1.0891e+01, -1.1014e+01],\n",
      "        [-1.0962e+01, -2.1219e-05, -1.2492e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4650e+00, -1.1241e-04, -1.0262e+01],\n",
      "        [-9.5995e+00, -1.1504e+01, -7.7841e-05],\n",
      "        [-3.6716e-05, -1.0625e+01, -1.1294e+01],\n",
      "        [-1.0988e+01, -2.1815e-05, -1.2229e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.1868e-05, -1.0074e+01, -1.0835e+01],\n",
      "        [-9.4426e+00, -1.1348e-04, -1.0282e+01],\n",
      "        [-9.6067e+00, -1.1469e+01, -7.7721e-05],\n",
      "        [-3.4928e-05, -1.0895e+01, -1.1019e+01],\n",
      "        [-1.0968e+01, -2.0981e-05, -1.2497e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4698e+00, -1.1193e-04, -1.0266e+01],\n",
      "        [-9.6044e+00, -1.1508e+01, -7.7483e-05],\n",
      "        [-3.6597e-05, -1.0630e+01, -1.1298e+01],\n",
      "        [-1.0994e+01, -2.1696e-05, -1.2234e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.1629e-05, -1.0078e+01, -1.0839e+01],\n",
      "        [-9.4473e+00, -1.1300e-04, -1.0287e+01],\n",
      "        [-9.6115e+00, -1.1473e+01, -7.7364e-05],\n",
      "        [-3.4809e-05, -1.0899e+01, -1.1024e+01],\n",
      "        [-1.0974e+01, -2.0861e-05, -1.2502e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4745e+00, -1.1145e-04, -1.0270e+01],\n",
      "        [-9.6093e+00, -1.1511e+01, -7.7125e-05],\n",
      "        [-3.6477e-05, -1.0634e+01, -1.1302e+01],\n",
      "        [-1.0999e+01, -2.1577e-05, -1.2239e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.1391e-05, -1.0082e+01, -1.0844e+01],\n",
      "        [-9.4520e+00, -1.1253e-04, -1.0291e+01],\n",
      "        [-9.6163e+00, -1.1477e+01, -7.7006e-05],\n",
      "        [-3.4570e-05, -1.0904e+01, -1.1028e+01],\n",
      "        [-1.0980e+01, -2.0742e-05, -1.2507e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4792e+00, -1.1086e-04, -1.0275e+01],\n",
      "        [-9.6141e+00, -1.1515e+01, -7.6768e-05],\n",
      "        [-3.6239e-05, -1.0639e+01, -1.1306e+01],\n",
      "        [-1.1005e+01, -2.1338e-05, -1.2245e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.1033e-05, -1.0086e+01, -1.0848e+01],\n",
      "        [-9.4568e+00, -1.1205e-04, -1.0295e+01],\n",
      "        [-9.6210e+00, -1.1481e+01, -7.6649e-05],\n",
      "        [-3.4570e-05, -1.0908e+01, -1.1033e+01],\n",
      "        [-1.0986e+01, -2.0623e-05, -1.2512e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4840e+00, -1.1038e-04, -1.0279e+01],\n",
      "        [-9.6190e+00, -1.1519e+01, -7.6410e-05],\n",
      "        [-3.6120e-05, -1.0644e+01, -1.1310e+01],\n",
      "        [-1.1010e+01, -2.1338e-05, -1.2250e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.0795e-05, -1.0090e+01, -1.0852e+01],\n",
      "        [-9.4615e+00, -1.1145e-04, -1.0300e+01],\n",
      "        [-9.6258e+00, -1.1486e+01, -7.6291e-05],\n",
      "        [-3.4332e-05, -1.0913e+01, -1.1037e+01],\n",
      "        [-1.0992e+01, -2.0504e-05, -1.2517e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4887e+00, -1.0990e-04, -1.0283e+01],\n",
      "        [-9.6238e+00, -1.1522e+01, -7.6053e-05],\n",
      "        [-3.5881e-05, -1.0649e+01, -1.1313e+01],\n",
      "        [-1.1016e+01, -2.1219e-05, -1.2255e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.0676e-05, -1.0094e+01, -1.0857e+01],\n",
      "        [-9.4661e+00, -1.1098e-04, -1.0304e+01],\n",
      "        [-9.6305e+00, -1.1490e+01, -7.5933e-05],\n",
      "        [-3.4093e-05, -1.0917e+01, -1.1042e+01],\n",
      "        [-1.0998e+01, -2.0385e-05, -1.2522e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4933e+00, -1.0943e-04, -1.0288e+01],\n",
      "        [-9.6287e+00, -1.1526e+01, -7.5695e-05],\n",
      "        [-3.5762e-05, -1.0653e+01, -1.1317e+01],\n",
      "        [-1.1021e+01, -2.1100e-05, -1.2260e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.0318e-05, -1.0098e+01, -1.0861e+01],\n",
      "        [-9.4708e+00, -1.1050e-04, -1.0308e+01],\n",
      "        [-9.6352e+00, -1.1494e+01, -7.5576e-05],\n",
      "        [-3.4093e-05, -1.0921e+01, -1.1046e+01],\n",
      "        [-1.1003e+01, -2.0265e-05, -1.2527e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.4980e+00, -1.0883e-04, -1.0292e+01],\n",
      "        [-9.6335e+00, -1.1529e+01, -7.5337e-05],\n",
      "        [-3.5643e-05, -1.0658e+01, -1.1321e+01],\n",
      "        [-1.1027e+01, -2.0981e-05, -1.2266e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-6.0080e-05, -1.0102e+01, -1.0866e+01],\n",
      "        [-9.4755e+00, -1.1002e-04, -1.0313e+01],\n",
      "        [-9.6399e+00, -1.1498e+01, -7.5218e-05],\n",
      "        [-3.3855e-05, -1.0926e+01, -1.1051e+01],\n",
      "        [-1.1009e+01, -2.0146e-05, -1.2532e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5027e+00, -1.0836e-04, -1.0296e+01],\n",
      "        [-9.6383e+00, -1.1533e+01, -7.4980e-05],\n",
      "        [-3.5405e-05, -1.0663e+01, -1.1325e+01],\n",
      "        [-1.1032e+01, -2.0861e-05, -1.2271e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.9960e-05, -1.0106e+01, -1.0870e+01],\n",
      "        [-9.4801e+00, -1.0943e-04, -1.0317e+01],\n",
      "        [-9.6447e+00, -1.1502e+01, -7.4861e-05],\n",
      "        [-3.3736e-05, -1.0930e+01, -1.1055e+01],\n",
      "        [-1.1015e+01, -2.0027e-05, -1.2537e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5073e+00, -1.0788e-04, -1.0301e+01],\n",
      "        [-9.6431e+00, -1.1537e+01, -7.4622e-05],\n",
      "        [-3.5285e-05, -1.0667e+01, -1.1329e+01],\n",
      "        [-1.1038e+01, -2.0742e-05, -1.2276e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.9603e-05, -1.0110e+01, -1.0875e+01],\n",
      "        [-9.4848e+00, -1.0895e-04, -1.0321e+01],\n",
      "        [-9.6493e+00, -1.1506e+01, -7.4503e-05],\n",
      "        [-3.3616e-05, -1.0935e+01, -1.1060e+01],\n",
      "        [-1.1021e+01, -1.9908e-05, -1.2542e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5120e+00, -1.0740e-04, -1.0305e+01],\n",
      "        [-9.6479e+00, -1.1540e+01, -7.4265e-05],\n",
      "        [-3.5166e-05, -1.0672e+01, -1.1333e+01],\n",
      "        [-1.1043e+01, -2.0623e-05, -1.2281e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.9364e-05, -1.0114e+01, -1.0879e+01],\n",
      "        [-9.4894e+00, -1.0847e-04, -1.0325e+01],\n",
      "        [-9.6540e+00, -1.1510e+01, -7.4145e-05],\n",
      "        [-3.3378e-05, -1.0939e+01, -1.1064e+01],\n",
      "        [-1.1027e+01, -1.9789e-05, -1.2547e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5166e+00, -1.0704e-04, -1.0309e+01],\n",
      "        [-9.6527e+00, -1.1544e+01, -7.3907e-05],\n",
      "        [-3.5047e-05, -1.0677e+01, -1.1337e+01],\n",
      "        [-1.1048e+01, -2.0504e-05, -1.2286e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.9007e-05, -1.0118e+01, -1.0883e+01],\n",
      "        [-9.4940e+00, -1.0800e-04, -1.0330e+01],\n",
      "        [-9.6587e+00, -1.1514e+01, -7.3907e-05],\n",
      "        [-3.3259e-05, -1.0943e+01, -1.1069e+01],\n",
      "        [-1.1033e+01, -1.9789e-05, -1.2552e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5212e+00, -1.0645e-04, -1.0313e+01],\n",
      "        [-9.6574e+00, -1.1547e+01, -7.3669e-05],\n",
      "        [-3.4928e-05, -1.0681e+01, -1.1341e+01],\n",
      "        [-1.1054e+01, -2.0504e-05, -1.2292e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.8888e-05, -1.0122e+01, -1.0888e+01],\n",
      "        [-9.4986e+00, -1.0752e-04, -1.0334e+01],\n",
      "        [-9.6634e+00, -1.1518e+01, -7.3549e-05],\n",
      "        [-3.3140e-05, -1.0948e+01, -1.1073e+01],\n",
      "        [-1.1039e+01, -1.9669e-05, -1.2556e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5259e+00, -1.0597e-04, -1.0318e+01],\n",
      "        [-9.6622e+00, -1.1551e+01, -7.3311e-05],\n",
      "        [-3.4689e-05, -1.0686e+01, -1.1345e+01],\n",
      "        [-1.1059e+01, -2.0265e-05, -1.2297e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.8649e-05, -1.0126e+01, -1.0892e+01],\n",
      "        [-9.5032e+00, -1.0704e-04, -1.0338e+01],\n",
      "        [-9.6680e+00, -1.1522e+01, -7.3192e-05],\n",
      "        [-3.3020e-05, -1.0952e+01, -1.1078e+01],\n",
      "        [-1.1044e+01, -1.9431e-05, -1.2561e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5304e+00, -1.0549e-04, -1.0322e+01],\n",
      "        [-9.6669e+00, -1.1554e+01, -7.2953e-05],\n",
      "        [-3.4570e-05, -1.0690e+01, -1.1349e+01],\n",
      "        [-1.1065e+01, -2.0146e-05, -1.2302e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.8411e-05, -1.0130e+01, -1.0896e+01],\n",
      "        [-9.5078e+00, -1.0645e-04, -1.0342e+01],\n",
      "        [-9.6727e+00, -1.1527e+01, -7.2834e-05],\n",
      "        [-3.2782e-05, -1.0956e+01, -1.1082e+01],\n",
      "        [-1.1050e+01, -1.9312e-05, -1.2566e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5350e+00, -1.0502e-04, -1.0326e+01],\n",
      "        [-9.6717e+00, -1.1558e+01, -7.2596e-05],\n",
      "        [-3.4332e-05, -1.0695e+01, -1.1353e+01],\n",
      "        [-1.1070e+01, -2.0146e-05, -1.2307e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.8172e-05, -1.0133e+01, -1.0901e+01],\n",
      "        [-9.5124e+00, -1.0597e-04, -1.0347e+01],\n",
      "        [-9.6773e+00, -1.1531e+01, -7.2477e-05],\n",
      "        [-3.2782e-05, -1.0960e+01, -1.1086e+01],\n",
      "        [-1.1056e+01, -1.9193e-05, -1.2571e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5396e+00, -1.0466e-04, -1.0330e+01],\n",
      "        [-9.6764e+00, -1.1561e+01, -7.2238e-05],\n",
      "        [-3.4212e-05, -1.0700e+01, -1.1357e+01],\n",
      "        [-1.1075e+01, -2.0027e-05, -1.2312e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.7934e-05, -1.0137e+01, -1.0905e+01],\n",
      "        [-9.5169e+00, -1.0549e-04, -1.0351e+01],\n",
      "        [-9.6819e+00, -1.1535e+01, -7.2238e-05],\n",
      "        [-3.2544e-05, -1.0965e+01, -1.1091e+01],\n",
      "        [-1.1062e+01, -1.9193e-05, -1.2576e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5442e+00, -1.0418e-04, -1.0334e+01],\n",
      "        [-9.6811e+00, -1.1565e+01, -7.2000e-05],\n",
      "        [-3.4093e-05, -1.0704e+01, -1.1361e+01],\n",
      "        [-1.1081e+01, -1.9908e-05, -1.2317e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.7696e-05, -1.0141e+01, -1.0909e+01],\n",
      "        [-9.5215e+00, -1.0514e-04, -1.0355e+01],\n",
      "        [-9.6865e+00, -1.1539e+01, -7.1881e-05],\n",
      "        [-3.2424e-05, -1.0969e+01, -1.1095e+01],\n",
      "        [-1.1067e+01, -1.9073e-05, -1.2581e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5487e+00, -1.0359e-04, -1.0339e+01],\n",
      "        [-9.6858e+00, -1.1568e+01, -7.1642e-05],\n",
      "        [-3.3855e-05, -1.0709e+01, -1.1365e+01],\n",
      "        [-1.1086e+01, -1.9789e-05, -1.2322e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.7457e-05, -1.0145e+01, -1.0914e+01],\n",
      "        [-9.5260e+00, -1.0466e-04, -1.0359e+01],\n",
      "        [-9.6911e+00, -1.1543e+01, -7.1523e-05],\n",
      "        [-3.2305e-05, -1.0973e+01, -1.1100e+01],\n",
      "        [-1.1073e+01, -1.8954e-05, -1.2586e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5533e+00, -1.0311e-04, -1.0343e+01],\n",
      "        [-9.6905e+00, -1.1572e+01, -7.1285e-05],\n",
      "        [-3.3855e-05, -1.0713e+01, -1.1368e+01],\n",
      "        [-1.1091e+01, -1.9669e-05, -1.2327e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.7219e-05, -1.0149e+01, -1.0918e+01],\n",
      "        [-9.5306e+00, -1.0418e-04, -1.0363e+01],\n",
      "        [-9.6957e+00, -1.1547e+01, -7.1165e-05],\n",
      "        [-3.2067e-05, -1.0978e+01, -1.1104e+01],\n",
      "        [-1.1079e+01, -1.8835e-05, -1.2590e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5578e+00, -1.0275e-04, -1.0347e+01],\n",
      "        [-9.6952e+00, -1.1575e+01, -7.0927e-05],\n",
      "        [-3.3736e-05, -1.0718e+01, -1.1372e+01],\n",
      "        [-1.1097e+01, -1.9550e-05, -1.2332e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "targets\n",
      "tensor([0, 1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-5.6980e-05, -1.0153e+01, -1.0922e+01],\n",
      "        [-9.5351e+00, -1.0371e-04, -1.0368e+01],\n",
      "        [-9.7003e+00, -1.1551e+01, -7.0927e-05],\n",
      "        [-3.2067e-05, -1.0982e+01, -1.1108e+01],\n",
      "        [-1.1084e+01, -1.8716e-05, -1.2595e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "sentence_in\n",
      "tensor([5, 6, 7, 8])\n",
      "targets\n",
      "tensor([1, 2, 0, 1])\n",
      "tag_scores\n",
      "tensor([[-9.5623e+00, -1.0228e-04, -1.0351e+01],\n",
      "        [-9.6998e+00, -1.1579e+01, -7.0689e-05],\n",
      "        [-3.3497e-05, -1.0722e+01, -1.1376e+01],\n",
      "        [-1.1102e+01, -1.9550e-05, -1.2337e+01]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training\n",
      "tensor([0, 1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(\"before training\")\n",
    "    print(tag_scores.argmax(axis = 1))\n",
    "\n",
    "losses = []\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        print(\"sentence_in\")\n",
    "        print(sentence_in)\n",
    "        print(\"targets\")\n",
    "        print(targets)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "        print(\"tag_scores\")\n",
    "        print(tag_scores)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(\"after training\")\n",
    "    print(tag_scores.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Augmenting the LSTM part-of-speech tagger with character-level features\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "In the example above, each word had an embedding, which served as the\n",
    "inputs to our sequence model. Let's augment the word embeddings with a\n",
    "representation derived from the characters of the word. We expect that\n",
    "this should help significantly, since character-level information like\n",
    "affixes have a large bearing on part-of-speech. For example, words with\n",
    "the affix *-ly* are almost always tagged as adverbs in English.\n",
    "\n",
    "To do this, let $c_w$ be the character-level representation of\n",
    "word $w$. Let $x_w$ be the word embedding as before. Then\n",
    "the input to our sequence model is the concatenation of $x_w$ and\n",
    "$c_w$. So if $x_w$ has dimension 5, and $c_w$\n",
    "dimension 3, then our LSTM should accept an input of dimension 8.\n",
    "\n",
    "To get the character level representation, do an LSTM over the\n",
    "characters of a word, and let $c_w$ be the final hidden state of\n",
    "this LSTM. Hints:\n",
    "\n",
    "* There are going to be two LSTM's in your new model.\n",
    "  The original one that outputs POS tag scores, and the new one that\n",
    "  outputs a character-level representation of each word.\n",
    "* To do a sequence model over characters, you will have to embed characters.\n",
    "  The character embeddings will be the input to the character LSTM.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 0,\n",
       " 'h': 1,\n",
       " 'e': 2,\n",
       " ' ': 3,\n",
       " 'd': 4,\n",
       " 'o': 5,\n",
       " 'g': 6,\n",
       " 'a': 7,\n",
       " 't': 8,\n",
       " 'p': 9,\n",
       " 'l': 10,\n",
       " 'E': 11,\n",
       " 'v': 12,\n",
       " 'r': 13,\n",
       " 'y': 14,\n",
       " 'b': 15,\n",
       " 'k': 16}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(reduce(lambda x, y: x + y, [s for s,t, in training_data]))\n",
    "char_vocabulary = {c:0 for c in text}\n",
    "for c in text:\n",
    "    char_vocabulary[c] += 1\n",
    "char_to_ix = {k:i for i, k in enumerate(char_vocabulary.keys())}\n",
    "char_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([0, 1, 2]),\n",
       "  tensor([4, 5, 6]),\n",
       "  tensor([7, 8, 2]),\n",
       "  tensor([8, 1, 2]),\n",
       "  tensor([ 7,  9,  9, 10,  2])],\n",
       " [tensor([11, 12,  2, 13, 14, 15,  5,  4, 14]),\n",
       "  tensor([13,  2,  7,  4]),\n",
       "  tensor([8, 1, 7, 8]),\n",
       "  tensor([15,  5,  5, 16])]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_train = [[prepare_sequence(w, char_to_ix) for w in s] for s, t in training_data]\n",
    "char_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DET', 'NN', 'V', 'DET', 'NN'], ['NN', 'V', 'DET', 'NN']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagset = [t for s,t in training_data]\n",
    "tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2868, -0.7686, -0.4394]],\n",
      "\n",
      "        [[ 0.4495, -2.0128,  3.0877]],\n",
      "\n",
      "        [[ 2.9216, -1.5525,  1.0192]],\n",
      "\n",
      "        [[ 0.0603, -0.9397,  0.1999]],\n",
      "\n",
      "        [[-0.3976,  2.0582,  0.2820]],\n",
      "\n",
      "        [[ 0.9745,  0.1880, -0.9599]],\n",
      "\n",
      "        [[-0.4766, -2.0444, -0.1861]],\n",
      "\n",
      "        [[ 2.2573, -0.3721, -0.9388]],\n",
      "\n",
      "        [[-0.5784, -0.8541,  0.0736]],\n",
      "\n",
      "        [[ 0.1026,  0.5591,  0.5857]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0079,  0.2972]],\n",
       " \n",
       "         [[-0.0715,  0.1995]],\n",
       " \n",
       "         [[-0.5036,  0.2217]],\n",
       " \n",
       "         [[-0.2950,  0.3378]],\n",
       " \n",
       "         [[-0.6098, -0.0758]],\n",
       " \n",
       "         [[-0.5305, -0.0153]],\n",
       " \n",
       "         [[-0.0978,  0.2802]],\n",
       " \n",
       "         [[-0.5875, -0.0208]],\n",
       " \n",
       "         [[-0.1931,  0.2333]],\n",
       " \n",
       "         [[-0.4311,  0.0477]]], grad_fn=<StackBackward>),\n",
       " (tensor([[[-0.4311,  0.0477]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[-0.8257,  0.1124]]], grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 1, 3)\n",
    "print(x)\n",
    "net = nn.LSTM(3, 2)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8440, -0.7747, -2.2148],\n",
       "        [-0.6476, -0.9759, -2.3044],\n",
       "        [-0.8294, -0.7851, -2.2292],\n",
       "        [-0.8389, -0.7783, -2.2198],\n",
       "        [-0.9330, -0.7245, -2.1034]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CharNet(nn.Module):\n",
    "    def __init__(self, embeddings_dim, lstm_hidden_dim, vocabulary_size, tagset_size):\n",
    "        super(CharNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocabulary_size, embeddings_dim)\n",
    "        self.char_lstm = nn.RNN(embeddings_dim, lstm_hidden_dim)\n",
    "        self.char_emb_to_tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "        self.final_layer = nn.LogSoftmax(1)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        X = [self.embeddings(w) for w in sentence]\n",
    "        X = torch.cat([self.char_lstm(w.unsqueeze(1))[0][-1] for w in X]).squeeze()\n",
    "        X = self.char_emb_to_tag(X)\n",
    "        X = self.final_layer(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "char_net = CharNet(3, 2, len(char_to_ix), len(tag_to_ix))\n",
    "#char_net.embeddings.weight.shape\n",
    "#char_net.embeddings(torch.tensor([0]))\n",
    "char_net(char_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 125.62it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training\n",
      "tensor([0, 1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "model = CharNet(2, 2, len(char_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = char_train[0]\n",
    "    #print(inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    print(\"before training\")\n",
    "    print(tag_scores.argmax(axis = 1))\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(200)):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in zip(char_train, tagset):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "#         sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        #print(targets)\n",
    "#         print(\"sentence_in\")\n",
    "#         print(sentence_in)\n",
    "#         print(\"targets\")\n",
    "#         print(targets)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence)\n",
    "        #print(tag_scores)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = char_train[0]\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(\"after training\")\n",
    "    print(tag_scores.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:00<00:16, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:14<00:00, 20.42it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training\n",
      "tensor([0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "class CharNet2(nn.Module):\n",
    "    def __init__(self, embeddings_dim, lstm_hidden_dim, vocabulary_size, tagset_size):\n",
    "        super(CharNet2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocabulary_size, embeddings_dim)\n",
    "        self.char_lstm = nn.RNN(embeddings_dim, tagset_size, 10)\n",
    "        #self.char_emb_to_tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "        self.final_layer = nn.LogSoftmax(1)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        X = [self.embeddings(w) for w in sentence]\n",
    "        X = torch.cat([self.char_lstm(w.unsqueeze(1))[0][-1] for w in X]).squeeze()\n",
    "        #X = self.char_emb_to_tag(X)\n",
    "        X = self.final_layer(X)\n",
    "        \n",
    "        return X\n",
    "\n",
    "model = CharNet2(6, 6, len(char_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = char_train[0]\n",
    "    #print(inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    print(\"before training\")\n",
    "    print(tag_scores.argmax(axis = 1))\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(300)):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in zip(char_train, tagset):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "#         sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        #print(targets)\n",
    "#         print(\"sentence_in\")\n",
    "#         print(sentence_in)\n",
    "#         print(\"targets\")\n",
    "#         print(targets)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence)\n",
    "        #print(tag_scores)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.axhline(0)\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = char_train[0]\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(\"after training\")\n",
    "    print(tag_scores.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
